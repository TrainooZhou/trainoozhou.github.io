{"pages":[{"title":"","text":"404UH OH! 页面丢失您所寻找的页面不存在。你可以点击下面的按钮，返回主页。返回首页","link":"/404.html"},{"title":"","text":".about{font-size:1.2em;font-weight:700;color:#4a4a4a}.about hr{background-color:#4a4a4a;margin-top:0;box-shadow:1px 2px 8px #000}关于我90后一枚计算机软件专业目前从事Java后端开发工作关于本博客本博客初始定位就不是一个技术博客，所以也会记录一些生活琐事。PS: 也就是看心情更新的意思！！！如果您恰巧来到了本博客，并且博客中的内容对您有些许帮助的话，我也是不胜荣幸呢。大事件：● 2017-12-14：入坑Hexo，主题选用的是yilia● 2019-05-17：更换主题为icarus ，并做了些小小的改动● 2020-05-30：升级icarus主题到3.0版本，并做了些小小的改动","link":"/about/index.html"},{"title":"友情链接","text":"排名不分先后，大概就是按顺序一直往后加吧~加载中，稍等几秒...如您希望交换友情链接，可以发邮件[trainoo@163.com]给我~或者您可以在哔哩哔哩私信我，我会在看到的第一时间回复的~本博客暂未开通留言功能，也不打算开通（因为比较懒，很少看留言~），感谢理解！本站友链信息如下：网站名称：Trainoo网站地址：https://trainoo.gitee.io/头像地址：https://trainoo.gitee.io/img/header.png网站简介：A simple man living a simple life","link":"/friend/index.html"}],"posts":[{"title":"IDEA-常用快捷键","text":"IntelliJ IDEA作为一个近几年来特别火热的一个Java IDE我使用这个IDE已经有一两年了就个人使用感觉来看，IntelliJ确实是非常的好用如果要跟eclipse等进行比较的话自认为IntelliJ要略胜一筹当然，好用的前提是你能够掌握好IntelliJ的快捷键所以在此整理了一些Java开发常用的快捷键方便更好的掌握IntelliJ的使用让开发变的更加轻松、愉快功能键12345678F2 定位到下一个错误或警告处 F3 查找下一个 F4 进入源文件或进入方法内部 F5 拷贝文件 F7 调试时，进入方法内部(step into) F8 调试时，下一步(step over) F9 选择一个项目，开始Debug F11 添加书签(bookmark)Ctrl12345678910111213141516Ctrl + X 剪切 Ctrl + D 复制行 Ctrl + Y 删除行 Ctrl + E 悬浮窗显示最近打开的文件 Ctrl + B 查看引用情况 Ctrl + W 选中整个单词 Ctrl + U 定位到父类或父类方法(Goto Super) Ctrl + F 查找当前文件 Ctrl + R 查找并替换 Ctrl + T 更新项目（适用于托管的代码） Ctrl + G 跳转到第X行(Goto Line) Ctrl + O 重写基类方法 Ctrl + I 实现基类或接口中的方法 Ctrl + / 使用//注释或反注释代码 Ctrl + -/+ 收起/展开当前方法 Ctrl + Space 自动代码提示Alt1234567891011121314Alt + 1 打开/关闭项目工程面板(project)Alt + 2 打开/关闭收藏栏面板(favorite)Alt + 3 打开/关闭查找结果面板(find)Alt + 5 打开/关闭Debug调试面板(debug)Alt + F3 快速查找当前文件Alt + F7 查看使用情况Alt + Enter 快速修复问题Alt + Insert 自动生成(构造函数、get/set、toString等)Alt + Up/Dn 在方法之间移动(向上/下一个方法)Alt + Lf/Rt 在文件之间移动(向左/右一个方法)Alt + Shift + Up/Dn 代码行上下移动Shift12Shift + Shift 快速查找文件Shift + Enter 在当前行的下方开始新行Ctrl + Alt123456789Ctrl + Alt + L 代码格式化Ctrl + Alt + O 移除未使用的Import内容Ctrl + Alt + V 自动补全变量名和变量属性Ctrl + Alt + M 根据选中内容抽出一个方法Ctrl + Alt + T Surround with (if、try、etc.)Ctrl + Alt + {/} 两个打开的idea窗口之间的切换Ctrl + Alt + -/+ 收起/展开当前方法Ctrl + Alt + Lf/Rt 导航到上/下一个浏览记录Ctrl + Alt + Enter 在当前行上方插入新行Ctrl + Shift123456789101112131415161718Ctrl + Shift + E 悬浮窗显示最近编辑过的文件Ctrl + Shift + F 根据关键字查找Ctrl + Shift + R 根据关键字查找文件并替换内容Ctrl + Shift + V 打开剪切版记录 Ctrl + Shift + J 把下一行缩进到当前行尾(多行变一行)Ctrl + Shift + Z 是Ctrl+Z的相反操作Ctrl + Shift + U 大小写变换Ctrl + Shift + I 悬浮窗显示变量的定义Ctrl + Shift + B 导航到类的定义Ctrl + Shift + M 在一个开闭括号的开闭范围首尾跳动Ctrl + Shift + K 推送代码到远程服务器Ctrl + Shift + T 创建一个单元测试方法Ctrl + Shift + / 使用/**/注释或反注释代码Ctrl + Shift + -/+ 收起/展开当前文件中所有方法Ctrl + Shift + Up/Dn 整个方法上下移动Ctrl + Shift + Lf/Rt 选中(以单词或特殊符号为最小移动范围)Ctrl + Shift + Enter 将输入的if、for、函数等等补上{}或者;使代码语句完整重磅：最能提高工作效率的5个快捷键12345Ctrl + E 查看最近打开的文件Ctrl + Shift + E 查看最近编辑过的文件Ctrl + N 查找类名Ctrl + Shift + N 查找文件名Ctrl + Shift + F 查找关键字好了以上即为今天的全部内容我们下次再见~","link":"/2018/05/22/IDEA-keymap-introduce/"},{"title":"Java设计模式之单例模式","text":"最近公司项目封版，有了很多的闲暇时间。“无聊”之余，发现很久没有整理一下有道云笔记了。虽然偶尔会往里面记录一些内容，但是长时间没回顾，也容易忘记。趁着这段时间，刚好整理一下笔记，还可以放在博客上发布出来，何乐而不为？那么接下来这段时间就逐步把笔记整理成博客吧。首先，就从单例模式开始！本文主要目的是举例几个单例模式的实现方式。废话不多说，直接上代码懒汉/恶汉记忆方法懒汉：太懒，直到获取对象时getInstance()才创建对象new MySingleton()。恶汉：太饿了，必须先创建对象new MySingleton(),才让别人获取getInstance()1. 懒汉模式1234567891011121314public class MySingleton { private static MySingleton instance = null; private MySingleton(){} public static MySingleton getInstance() { if(instance == null){ //懒汉式，别人获取它时才创建对象 instance = new MySingleton(); } return instance; } }2. 恶汉模式123456789101112public class MySingleton { //饿汉，先创建对象 private static MySingleton instance = new MySingleton(); private MySingleton(){} public static MySingleton getInstance() { return instance; } }3. 枚举方式123456789101112131415public enum EnumFactory{ singletonFactory; private MySingleton instance; //枚举类的构造方法在类加载是被实例化 private EnumFactory(){ instance = new MySingleton(); } public MySingleton getInstance(){ return instance; } }4. 内部类实现方式Java机制规定，内部类SingletonHolder只有在getInstance()方法第一次调用的时候才会被加载（实现了延迟加载效果），而且其加载过程是线程安全的（实现线程安全）。内部类加载的时候实例化一次instance123456789101112131415161718192021222324252627public class Singleton{ //构造器私有化 private Singleton(){ } /** * 获取对象实例的静态方法 * @return */ public static Singleton getInstance() { return SingletonHolder.instance; } //静态内部类，在第一次被引用时被加载,私有 private static class SingletonHolder { private static Singleton instance = new Singleton(); } public static void main(String args[]) { Singleton instance1 = Singleton.getInstance(); Singleton instance2 = Singleton.getInstance(); System.out.println(instance1 == instance2); }}5.参考文章高并发下线程安全的单例模式","link":"/2018/06/24/Java-design-pattern-singleton/"},{"title":"谈谈Java面试中“陷阱题”","text":"前面整理了一些Java的基础知识这里最后整理了一些笔试面试中经常会犯错的陷阱题Java中创建实例化对象有哪些方式？123451，最常见的方式是使用new语句创建一个对象2，通过工厂方法返回对象（工厂方法涉及到框架）3，动用反射机制创建实例化对象，Class类的三种方法或者通过类类型的newInstance()实例方法4，调用对象的clone方法（俗称克隆法）5，通过IO留的反序列化手段，调用ObjectInputStream对象的readObject方法关于 a++ 跟 ++a12345678// 加号在前，先做加法再使用；加号再后，先使用再做加法int a = 2; System.out.println(a++ +&quot;,&quot;+ ++a); // 2.4System.out.println(a); // 4System.out.println(a++); // 4System.out.println(a); // 5System.out.println(++a); // 6System.out.println(a); // 6switch case 语句陷阱12345678910StringBuilder sb = new StringBuilder();switch(1){ case 1: sb.append(&quot;hello&quot;); case 2: sb.append(&quot;3&quot;); case 3: sb.append(&quot;6&quot;); default : sb.append(&quot;9&quot;);}System.out.println(sb.toString());// 打印结果：hello369// 因为没有break所以会继续往下执行Java中的锁12345678910111213141516171819// 1，普通同步方法，锁是当前实例对象// 2，静态同步方法，锁是当前类的class对象// 3，同步方法块，锁是括号里面的对象public class SynchronizedTest{ public synchronized void method1(){} public synchronized void method2(){} public static synchronized void method3(){} public static synchronized void method4(){}}// 那么，有SynchronizedTest的两个实例a和b，对于一下的几个选项有哪些能被一个以上的线程同时访问呢？ A. a.method1() vs a.method2() [x] B. a.method1() vs b.method1() [√] C. a.method3() vs b.method4() [x] D. a.method3() vs b.method3() [x] E. a.method1() vs a.method3() [√] // 正确答案是：B,E对于“try-catch-finally”，若try语句块中包含“return”语句，finally语句块会执行吗12345答案是会执行。只有两种情况finally块中的语句不会被执行：调用了System.exit()方法；JVM“崩溃”了。能否编译通过，输出结果是什么1234567891011121314151617181920212223242526272829class A{ public static int X; static{ System.out.println(Test.B); X = Test.B + 1; }}class C{ public static int Z; static{ System.out.println(&quot;C&quot;); Z = Test.B + 1; }}public class Test{ public static int B = A.X + 1; static{System.out.println(A.X);} public static void main(String[] args) { System.out.println(A.X+ &quot;,&quot; +Test.B); int a = C.Z; }}//输出结果,解释见下面类加载的时机。011,2C类加载的时机12345第一：生成该类对象的时候，会加载该类及该类的所有父类；第二：访问该类的静态成员的时候；第三：class．forName(&quot;类名&quot;)；java中各成员的执行顺序123456789101112131415161718192021222324252627282930313233343536373839404142434445//（1）父类静态成员和静态初始化块，按在代码中出现的顺序依次执行。//（2）子类静态成员和静态初始化块，按在代码中出现的顺序依次执行。//（3）父类实例成员和实例初始化块，按在代码中出现的顺序依次执行。//（4）执行父类构造方法。//（5）子类实例成员和实例初始化块，按在代码中出现的顺序依次执行。//（6）执行子类构造方法。public class Parent{ { System.out.println(&quot;Parent block&quot;); } static{ System.out.println(&quot;Parent static block&quot;); } public Parent(){ System.out.println(&quot;Parent construct method&quot;); }}public class Son extends Parent{ { System.out.println(&quot;son block&quot;); } static{ System.out.println(&quot;son static block&quot;); } public Son(){ System.out.println(&quot;son construct method&quot;); }}public class Test{ public static void main(String[] args) { new Son(); }}//输出结果Parent static blockson static blockParent blockParent construct methodson blockson construct method关于字符串的总结123456引号(&quot;&quot;)创建的字符串在字符串池中new创建字符串时首先查看池中是否有相同值的字符串如果有，则拷贝一份到堆中，然后返回堆中地址；如果池中没有，则在堆中创建一份，然后返回堆中地址注意：此时不需要从堆中复制到池中，否则，堆中字符串奖永远是池中的子集，浪费池的空间关于Integer对象12345678910111213141516171819202122232425262728Integer int1 = 88;Integer int2 = Integer.valueOf(88);Integer int3 = new Integer(88);System.out.println(int1 == int2);System.out.println(int1 == int3);System.out.println(int2 == int3);Integer int4 = 188;Integer int5 = Integer.valueOf(188);Integer int6 = new Integer(188);System.out.println(int4 == int5);System.out.println(int4 == int6);System.out.println(int5 == int6);// 输出结果：truefalsefalsefalsefalsefalse// 解析：// Integer类中维护了一个内部类IntegerCache,它会缓存[-128, 127]之间的数据// 所以在调用value或者自动装箱时候，会直接返回缓存中的数据，而不会创建新的对象// Long、Short、Byte也有类似缓存，Float、Double没有IntegerCache源码如下(jdk1.8)123456789101112131415161718192021222324252627282930313233private static class IntegerCache { static final int low = -128; static final int high; static final Integer cache[]; static { // high value may be configured by property int h = 127; String integerCacheHighPropValue = sun.misc.VM.getSavedProperty(&quot;java.lang.Integer.IntegerCache.high&quot;); if (integerCacheHighPropValue != null) { try { int i = parseInt(integerCacheHighPropValue); i = Math.max(i, 127); // Maximum array size is Integer.MAX_VALUE h = Math.min(i, Integer.MAX_VALUE - (-low) -1); } catch( NumberFormatException nfe) { // If the property cannot be parsed into an int, ignore it. } } high = h; cache = new Integer[(high - low) + 1]; int j = low; for(int k = 0; k &lt; cache.length; k++) cache[k] = new Integer(j++); // range [-128, 127] must be interned (JLS7 5.1.7) assert IntegerCache.high &gt;= 127; } private IntegerCache() {}}","link":"/2018/06/27/Java-error-prone-problem/"},{"title":"Java源码分析之ArrayList","text":"之前整理了HashMap的源码分析接下来，这里整理的是ArrayList的源码分析对于ArrayList，我们需要知道以下几点：1234567ArrayList实现了List接口，是顺序容器，元素存取的顺序相同。允许放入null元素，底层通过数组实现。除该类未实现同步外，其余跟Vector大致相同。每个ArrayList都有一个容量（capacity），表示底层数组的实际大小。容器内存储元素的个数不能多于当前容量。当向容器中添加元素时，如果容量不足，容器会自动增大底层数组的大小。所以这里的数组是一个Object数组，以便能够容纳任何类型的对象。12345ArrayList初始化时候是一个空的Object数组 private transient Object[] elementData; 当添加第一个元素的时候，数组的大小变成10（也就是数组的默认大小） private static final int DEFAULT_CAPACITY = 10;Add方法12345678每次add的时候都会进行剩余空间检查。 minCapacity = size + 1; 如果是第一次，则空间大小（minCapacity）直接变成10，再执行如下步骤： 1.判断minCapacity是否大于elementData.length 即：if (minCapacity - elementData.length &gt; 0) 2.条件成立：grow(minCapacity); 3.grow内部调用Arrays.copyOf进行数组复制 4.Arrays.copyOf调用System.arrayCopy进行数组复制123456789101112131415161718192021private void grow(int minCapacity) { // 新数组增长为之前的1.5倍 int oldCapacity = elementData.length; int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); // 如果还是小与minCapacity，那么变成minCapacity if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; // 判断是否超过数组最大的容量 if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: elementData = Arrays.copyOf(elementData, newCapacity);}//最大容量变成Integer.MAX_VALUE,或者超出MAX_VALUE范围，跑出OutOfMenory异常private static int hugeCapacity(int minCapacity) { if (minCapacity &lt; 0) // overflow throw new OutOfMemoryError(); return (minCapacity &gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE;}12System.arraycopy(源数组, 源数组起始位置, 目标数组, 目标起始位置, 复制长度);System.arraycopy(elementData, index+1, elementData, index, numMoved);检查是否越界1234private void rangeCheck(int index) { if (index &gt;= size) throw new IndexOutOfBoundsException(outOfBoundsMsg(index));}Set方法12345678既然底层是一个数组ArrayList的set()方法也就变得非常简单，直接对数组的指定位置赋值即可。public E set(int index, E element) { rangeCheck(index); // 下标越界检查 E oldValue = elementData(index); elementData[index] = element; // 赋值到指定位置，复制的仅仅是引用 return oldValue; // 返回之前的元素}Get方法123456get()方法同样很简单，唯一要注意的是由于底层数组是Object[]，得到元素后需要进行类型转换。public E get(int index) { rangeCheck(index); return (E) elementData[index];//注意类型转换}Remove()方法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647remove()方法也有两个版本，一个是remove(int index)删除指定位置的元素，另一个是remove(Object o)删除第一个满足o.equals(elementData[index])的元素。删除操作是add()操作的逆过程，需要将删除点之后的元素向前移动一个位置。需要注意的是为了让GC起作用，必须显式的为最后一个位置赋null值。public E remove(int index) { rangeCheck(index); modCount++; E oldValue = elementData(index); int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work return oldValue;}public boolean remove(Object o) { if (o == null) { for (int index = 0; index &lt; size; index++) if (elementData[index] == null) { fastRemove(index); return true; } } else { for (int index = 0; index &lt; size; index++) if (o.equals(elementData[index])) { fastRemove(index); return true; } } return false;}// 此方法跟remove基本一样，只不过不需要返回值，也不用检查是否越界private void fastRemove(int index) { modCount++; int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work}AddAll方法123456789101112131415161718192021222324252627//把指定的集合元素添加到list后面，先进行容量检查，然后复制public boolean addAll(Collection&lt;? extends E&gt; c) { Object[] a = c.toArray(); int numNew = a.length; ensureCapacityInternal(size + numNew); // Increments modCount System.arraycopy(a, 0, elementData, size, numNew); size += numNew; return numNew != 0;}//在指定位置插入指定的集合元素public boolean addAll(int index, Collection&lt;? extends E&gt; c) { rangeCheckForAdd(index); // 原数组：头部 + 尾部 Object[] a = c.toArray(); int numNew = a.length; ensureCapacityInternal(size + numNew); // Increments modCount // 新数组：头部 + 空 + 尾部 int numMoved = size - index; if (numMoved &gt; 0) System.arraycopy(elementData, index, elementData, index + numNew, numMoved); // 新数组：头部 + 新增 + 尾部 System.arraycopy(a, 0, elementData, index, numNew); size += numNew; return numNew != 0;}","link":"/2018/06/25/Java-source-code-ArrayList/"},{"title":"Java源码分析之HashMap","text":"之前整理了单例模式的源码分析接下来，整理一下HashMap的源码分析首先理解概念：1234567891011121314151. 数组数组存储区间是连续的，占用内存严重，故空间复杂的很大。但数组的二分查找时间复杂度小，为O(1)；数组的特点是：寻址容易，插入和删除困难；2. 链表链表存储区间离散，占用内存比较宽松，故空间复杂度很小，但时间复杂度很大，达O（N）。链表的特点是：寻址困难，插入和删除容易。3. 哈希表哈希表（(Hash table）既满足了数据的查找方便，同时不占用太多的内容空间，使用也十分方便。哈希表有多种不同的实现方法，最常用的一种方法—— 拉链法，我们可以理解为“链表的数组” 哈希表是由 **数组+链表** 组成的123456789101112131415161718192021222324252627282930313233HashMap是数组+链表+红黑树（JDK1.8增加了红黑树部分）实现的HashMap其实也是一个线性的数组实现的,所以可以理解为其存储数据的容器就是一个线性数组。首先HashMap里面实现一个静态内部类Entry(1.8里面是是Node)，其重要的属性有 key , value, next static class Entry&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; { final K key; V value; Entry&lt;K,V&gt; next; ...... } // jdk1.8实现 static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; { final int hash; //用来定位数组索引位置 final K key; V value; Node&lt;K,V&gt; next; //链表的下一个node Node(int hash, K key, V value, Node&lt;K,V&gt; next) { ... } public final K getKey(){ ... } public final V getValue() { ... } public final String toString() { ... } public final int hashCode() { ... } public final V setValue(V newValue) { ... } public final boolean equals(Object o) { ... } } 说到HashMap的基础就是一个线性数组，这个数组就是Entry[]，Map里面的内容都保存在Entry[]里面。 /** * The table, resized as necessary. Length MUST Always be a power of two. */ transient Entry[] table;1234567891011121314HashMap：它根据键的hashCode值存储数据，大多数情况下可以直接定位到它的值，因而具有很快的访问速度。HashMap最多只允许一条记录的键为null，允许多条记录的值为null。非线程安全。如果需要满足线程安全，可以用 Collections的synchronizedMap方法使HashMap具有线程安全的能力，或者使用ConcurrentHashMapHashtable：Hashtable是遗留类，很多映射的常用功能与HashMap类似，不同的是它承自Dictionary类。线程安全。并发性不如ConcurrentHashMap，因为ConcurrentHashMap引入了分段锁。LinkedHashMap：LinkedHashMap是HashMap的一个子类，保存了记录的插入顺序，在用Iterator遍历LinkedHashMap时，先得到的记录肯定是先插入的，也可以在构造时带参数，按照访问次序排序。TreeMap：TreeMap实现SortedMap接口，能够把它保存的记录根据键排序，默认是按键值的升序排序，也可以指定排序的比较器，当用Iterator遍历TreeMap时，得到的记录是排过序的。在使用TreeMap时，key必须实现Comparable接口或者在构造TreeMap传入自定义的Comparator，否则会在运行时抛出java.lang.ClassCastException类型的异常。初始大小、增长12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061621. hashMap的大小始终是2的n次幂2. 每扩充一次，HashMap 的容量就增大一倍。3. hashMap的构造方法; * HashMap()：构建一个初始容量为 16，负载因子为 0.75 的 HashMap。 * HashMap(int initialCapacity)：构建一个初始容量为 initialCapacity，负载因子为 0.75 的 HashMap。 * HashMap(int initialCapacity, float loadFactor)：以指定初始容量、指定的负载因子创建一个 HashMap。// 以指定初始化容量、负载因子创建 HashMap public HashMap(int initialCapacity, float loadFactor) { if (initialCapacity &lt; 0) throw new IllegalArgumentException(&quot;Illegal initial capacity: &quot; + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(&quot;Illegal load factor: &quot; + loadFactor); this.loadFactor = loadFactor; threshold = initialCapacity; init();}注意：此处用的java1.7源码，这里并没有在构造函数里面就把容量扩展到比initialCapacity小的，最小的2的n次方值。而是在put第一个元素的时候才执行这个操作,保证上述条件1 public V put(K key, V value) { if (table == EMPTY_TABLE) { inflateTable(threshold); //扩容到最2的n方 } ... } private void inflateTable(int toSize) { // Find a power of 2 &gt;= toSize int capacity = roundUpToPowerOf2(toSize); threshold = (int) Math.min(capacity * loadFactor, MAXIMUM_CAPACITY + 1); table = new Entry[capacity]; initHashSeedAsNeeded(capacity); } 增长：// 将 key、value 添加到 i 索引处 addEntry(hash, key, value, i); void addEntry(int hash, K key, V value, int bucketIndex) { // 如果大小超过临界值，容量翻倍 if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) { resize(2 * table.length); hash = (null != key) ? hash(key) : 0; bucketIndex = indexFor(hash, table.length); } createEntry(hash, key, value, bucketIndex);}void createEntry(int hash, K key, V value, int bucketIndex) { Entry&lt;K,V&gt; e = table[bucketIndex]; table[bucketIndex] = new Entry&lt;&gt;(hash, key, value, e); size++;}Put方法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283当向 HashMap 中添加 key-value 对，由其 key 的 hashCode() 返回值决定该 key-value 对（就是 Entry 对象）的存储位置。当两个 Entry 对象的 key 的 hashCode() 返回值相同时，将由 key 通过 eqauls() 比较值决定是采用覆盖行为（返回 true），还是产生 Entry 链（返回 false）。 public V put(K key, V value) { if (table == EMPTY_TABLE) { //第一次添加，把大小扩展到2的幂放 inflateTable(threshold); } // 如果 key 为 null，调用 putForNullKey 方法进行处理 if (key == null) return putForNullKey(value); //null总是放在数组的第一个链表中 // 根据 key 的 keyCode 计算 Hash 值 int hash = hash(key.hashCode()); // 搜索指定 hash 值在对应 table 中的索引 int i = indexFor(hash, table.length); // //遍历链表 如果 i 索引处的 Entry 不为 null，通过循环不断遍历 e 元素的下一个元素 for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) { Object k; // 找到指定 key 与需要放入的 key 相等（hash 值相同 // 通过 equals 比较放回 true） if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) { V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; } } // 如果 i 索引处的 Entry 为 null，表明此处还没有 Entry modCount++; // 将 key、value 添加到 i 索引处 addEntry(hash, key, value, i); return null; } void addEntry(int hash, K key, V value, int bucketIndex) { Entry&lt;K,V&gt; e = table[bucketIndex]; table[bucketIndex] = new Entry&lt;K,V&gt;(hash, key, value, e); //参数e, 是Entry.next //如果size超过threshold(临界值)，则扩充table大小。再散列 if (size++ &gt;= threshold) resize(2 * table.length);}当哈希表的容量超过默认容量时，必须调整table的大小。当容量已经达到最大可能值时，那么该方法就将容量调整到Integer.MAX_VALUE返回，这时，需要创建一张新表，将原表的映射到新表中。void resize(int newCapacity) { Entry[] oldTable = table; int oldCapacity = oldTable.length; if (oldCapacity == MAXIMUM_CAPACITY) { threshold = Integer.MAX_VALUE; return; } Entry[] newTable = new Entry[newCapacity]; transfer(newTable); table = newTable; threshold = (int)(newCapacity * loadFactor);}void transfer(Entry[] newTable) { Entry[] src = table; int newCapacity = newTable.length; for (int j = 0; j &lt; src.length; j++) { Entry&lt;K,V&gt; e = src[j]; if (e != null) { src[j] = null; do { Entry&lt;K,V&gt; next = e.next; //重新计算index int i = indexFor(e.hash, newCapacity); e.next = newTable[i]; newTable[i] = e; e = next; } while (e != null); } }}Get方法123456789101112131415161718192021222324252627282930313233343536373839404142434445public V get(Object key) { if (key == null) return getForNullKey(); int hash = hash(key.hashCode()); //先定位到数组元素，再遍历该元素处的链表 for (Entry&lt;K,V&gt; e = table[indexFor(hash, table.length)]; e != null; e = e.next) { Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) return e.value; } return null;}/*按位取并，作用上相当于取模mod或者取余%。这意味着数组下标相同，并不表示hashCode相同。*/static int indexFor(int h, int length) { return h &amp; (length-1);}// null key总是存放在Entry[]数组的第一个元素。private V putForNullKey(V value) { for (Entry&lt;K,V&gt; e = table[0]; e != null; e = e.next) { if (e.key == null) { V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; } } modCount++; addEntry(0, null, value, 0); return null;}private V getForNullKey() { for (Entry&lt;K,V&gt; e = table[0]; e != null; e = e.next) { if (e.key == null) return e.value; } return null;}参考资料Java 8系列之重新认识HashMapHashMap实现原理分析HashMap详解红黑树深入剖析及Java实现","link":"/2018/06/25/Java-source-code-HashMap/"},{"title":"Java之线程池的成长之路","text":"本文转载自公众号： 猿天地1、背景相信大家在面试过程中遇到面试官问线程的很多，线程过后就是线程池了。从易到难，都是这么个过程，还有就是确实很多人在工作中接触线程池比较少，最多的也就是创建一个然后往里面提交线程，对于一些经验很丰富的面试官来说，一下就可以问出很多线程池相关的问题，与其被问的晕头转向，还不如好好学习。此时不努力更待何时。2、什么是线程池？线程池是一种多线程处理形式，处理过程中将任务提交到线程池，任务的执行交由线程池来管理。如果每个请求都创建一个线程去处理，那么服务器的资源很快就会被耗尽，使用线程池可以减少创建和销毁线程的次数，每个工作线程都可以被重复利用，可执行多个任务。如果用生活中的列子来说明，我们可以把线程池当做一个客服团队，如果同时有1000个人打电话进行咨询，按照正常的逻辑那就是需要1000个客服接听电话，服务客户。现实往往需要考虑到很多层面的东西，比如：资源够不够，招这么多人需要费用比较多。正常的做法就是招100个人成立一个客服中心，当有电话进来后分配没有接听的客服进行服务，如果超出了100个人同时咨询的话，提示客户等待，稍后处理，等有客服空出来就可以继续服务下一个客户，这样才能达到一个资源的合理利用，实现效益的最大化。3、Java中的线程池种类newSingleThreadExecutor创建方式：1ExecutorService pool = Executors.newSingleThreadExecutor();一个单线程的线程池。这个线程池只有一个线程在工作，也就是相当于单线程串行执行所有任务。如果这个唯一的线程因为异常结束，那么会有一个新的线程来替代它。此线程池保证所有任务的执行顺序按照任务的提交顺序执行。使用方式：123456789101112import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; public class ThreadPool { public static void main(String[] args) { ExecutorService pool = Executors.newSingleThreadExecutor(); for (int i = 0; i &lt; 10; i++) { pool.execute(() -&gt; { System.out.println(Thread.currentThread().getName() + &quot;\\t开始发车啦....&quot;); }); } } }输出结果如下：12345678910pool-1-thread-1 开始发车啦....pool-1-thread-1 开始发车啦....pool-1-thread-1 开始发车啦....pool-1-thread-1 开始发车啦....pool-1-thread-1 开始发车啦....pool-1-thread-1 开始发车啦....pool-1-thread-1 开始发车啦....pool-1-thread-1 开始发车啦....pool-1-thread-1 开始发车啦....pool-1-thread-1 开始发车啦....从输出的结果我们可以看出，一直只有一个线程在运行。newFixedThreadPool创建方式：1ExecutorService pool = Executors.newFixedThreadPool(10);创建固定大小的线程池。每次提交一个任务就创建一个线程，直到线程达到线程池的最大大小。线程池的大小一旦达到最大值就会保持不变，如果某个线程因为执行异常而结束，那么线程池会补充一个新线程。使用方式：123456789101112import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;public class ThreadPool { public static void main(String[] args) { ExecutorService pool = Executors.newFixedThreadPool(10); for (int i = 0; i &lt; 10; i++) { pool.execute(() -&gt; { System.out.println(Thread.currentThread().getName() + &quot;\\t开始发车啦....&quot;); }); } }}输出结果如下：12345678910pool-1-thread-1 开始发车啦....pool-1-thread-4 开始发车啦....pool-1-thread-3 开始发车啦....pool-1-thread-2 开始发车啦....pool-1-thread-6 开始发车啦....pool-1-thread-7 开始发车啦....pool-1-thread-5 开始发车啦....pool-1-thread-8 开始发车啦....pool-1-thread-9 开始发车啦....pool-1-thread-10 开始发车啦....newCachedThreadPool创建方式：1ExecutorService pool = Executors.newCachedThreadPool();创建一个可缓存的线程池。如果线程池的大小超过了处理任务所需要的线程，那么就会回收部分空闲的线程，当任务数增加时，此线程池又添加新线程来处理任务。使用方式如上2所示。newScheduledThreadPool创建方式：1ScheduledExecutorService pool = Executors.newScheduledThreadPool(10);此线程池支持定时以及周期性执行任务的需求。使用方式：12345678910111213import java.util.concurrent.Executors;import java.util.concurrent.ScheduledExecutorService;import java.util.concurrent.TimeUnit;public class ThreadPool { public static void main(String[] args) { ScheduledExecutorService pool = Executors.newScheduledThreadPool(10); for (int i = 0; i &lt; 10; i++) { pool.schedule(() -&gt; { System.out.println(Thread.currentThread().getName() + &quot;\\t开始发车啦....&quot;); }, 10, TimeUnit.SECONDS); } }}上面演示的是延迟10秒执行任务,如果想要执行周期性的任务可以用下面的方式，每秒执行一次。1234//pool.scheduleWithFixedDelay也可以pool.scheduleAtFixedRate(() -&gt; { System.out.println(Thread.currentThread().getName() + &quot;\\t开始发车啦....&quot;);}, 1, 1, TimeUnit.SECONDS);newWorkStealingPoolnewWorkStealingPool是jdk1.8才有的，会根据所需的并行层次来动态创建和关闭线程，通过使用多个队列减少竞争，底层用的ForkJoinPool来实现的。ForkJoinPool的优势在于，可以充分利用多cpu，多核cpu的优势，把一个任务拆分成多个“小任务”，把多个“小任务”放到多个处理器核心上并行执行；当多个“小任务”执行完成之后，再将这些执行结果合并起来即可。4、说说线程池的拒绝策略当请求任务不断的过来，而系统此时又处理不过来的时候，我们需要采取的策略是拒绝服务。RejectedExecutionHandler接口提供了拒绝任务处理的自定义方法的机会。在ThreadPoolExecutor中已经包含四种处理策略。AbortPolicy策略：该策略会直接抛出异常，阻止系统正常工作。12345678public static class AbortPolicy implements RejectedExecutionHandler { public AbortPolicy() { } public void rejectedExecution(Runnable r, ThreadPoolExecutor e) { throw new RejectedExecutionException(&quot;Task &quot; + r.toString() + &quot; rejected from &quot; + e.toString()); }}CallerRunsPolicy 策略：只要线程池未关闭，该策略直接在调用者线程中，运行当前的被丢弃的任务。12345678public static class CallerRunsPolicy implements RejectedExecutionHandler { public CallerRunsPolicy() { } public void rejectedExecution(Runnable r, ThreadPoolExecutor e) { if (!e.isShutdown()) { r.run(); } }}DiscardOleddestPolicy策略： 该策略将丢弃最老的一个请求，也就是即将被执行的任务，并尝试再次提交当前任务。123456789public static class DiscardOldestPolicy implements RejectedExecutionHandler { public DiscardOldestPolicy() { } public void rejectedExecution(Runnable r, ThreadPoolExecutor e) { if (!e.isShutdown()) { e.getQueue().poll(); e.execute(r); } }}DiscardPolicy策略：该策略默默的丢弃无法处理的任务，不予任何处理。12345public static class DiscardPolicy implements RejectedExecutionHandler { public DiscardPolicy() { } public void rejectedExecution(Runnable r, ThreadPoolExecutor e) { }}除了JDK默认为什么提供的四种拒绝策略，我们可以根据自己的业务需求去自定义拒绝策略，自定义的方式很简单，直接实现RejectedExecutionHandler接口即可。比如Spring integration中就有一个自定义的拒绝策略CallerBlocksPolicy，将任务插入到队列中，直到队列中有空闲并插入成功的时候，否则将根据最大等待时间一直阻塞，直到超时。12345678910111213141516171819202122232425262728293031323334353637383940414243package org.springframework.integration.util;import java.util.concurrent.BlockingQueue;import java.util.concurrent.RejectedExecutionException;import java.util.concurrent.RejectedExecutionHandler;import java.util.concurrent.ThreadPoolExecutor;import java.util.concurrent.TimeUnit;import org.apache.commons.logging.Log;import org.apache.commons.logging.LogFactory;public class CallerBlocksPolicy implements RejectedExecutionHandler { private static final Log logger = LogFactory.getLog(CallerBlocksPolicy.class); private final long maxWait; /** * @param maxWait The maximum time to wait for a queue slot to be * available, in milliseconds. */ public CallerBlocksPolicy(long maxWait) { this.maxWait = maxWait; } @Override public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) { if (!executor.isShutdown()) { try { BlockingQueue&lt;Runnable&gt; queue = executor.getQueue(); if (logger.isDebugEnabled()) { logger.debug(&quot;Attempting to queue task execution for &quot; + this.maxWait + &quot; milliseconds&quot;); } if (!queue.offer(r, this.maxWait, TimeUnit.MILLISECONDS)) { throw new RejectedExecutionException(&quot;Max wait time expired to queue task&quot;); } if (logger.isDebugEnabled()) { logger.debug(&quot;Task execution queued&quot;); } } catch (InterruptedException e) { Thread.currentThread().interrupt(); throw new RejectedExecutionException(&quot;Interrupted&quot;, e); } } else { throw new RejectedExecutionException(&quot;Executor has been shut down&quot;); } }}定义好之后如何使用呢？光定义没用的呀，一定要用到线程池中呀，可以通过下面的方式自定义线程池，指定拒绝策略。123BlockingQueue&lt;Runnable&gt; workQueue = new ArrayBlockingQueue&lt;&gt;(100);ThreadPoolExecutor executor = new ThreadPoolExecutor( 10, 100, 10, TimeUnit.SECONDS, workQueue, new CallerBlocksPolicy());5、execute和submit的区别？在前面的讲解中，我们执行任务是用的execute方法，除了execute方法，还有一个submit方法也可以执行我们提交的任务。这两个方法有什么区别呢？分别适用于在什么场景下呢？我们来做一个简单的分析。execute适用于不需要关注返回值的场景，只需要将线程丢到线程池中去执行就可以了。12345678public class ThreadPool { public static void main(String[] args) { ExecutorService pool = Executors.newFixedThreadPool(10); pool.execute(() -&gt; { System.out.println(Thread.currentThread().getName() + &quot;\\t开始发车啦....&quot;); }); }}submit方法适用于需要关注返回值的场景，submit方法的定义如下：1234567public interface ExecutorService extends Executor { ... &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task); &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result); Future&lt;?&gt; submit(Runnable task); ...}其子类AbstractExecutorService实现了submit方法,可以看到无论参数是Callable还是Runnable，最终都会被封装成RunnableFuture，然后再调用execute执行。123456789101112131415161718192021222324252627282930/** * @throws RejectedExecutionException {@inheritDoc} * @throws NullPointerException {@inheritDoc} */public Future&lt;?&gt; submit(Runnable task) { if (task == null) throw new NullPointerException(); RunnableFuture&lt;Void&gt; ftask = newTaskFor(task, null); execute(ftask); return ftask;}/** * @throws RejectedExecutionException {@inheritDoc} * @throws NullPointerException {@inheritDoc} */public &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result) { if (task == null) throw new NullPointerException(); RunnableFuture&lt;T&gt; ftask = newTaskFor(task, result); execute(ftask); return ftask;}/** * @throws RejectedExecutionException {@inheritDoc} * @throws NullPointerException {@inheritDoc} */public &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) { if (task == null) throw new NullPointerException(); RunnableFuture&lt;T&gt; ftask = newTaskFor(task); execute(ftask); return ftask;}下面我们来看看这三个方法分别如何去使用：submit(Callable task);12345678910111213public class ThreadPool { public static void main(String[] args) throws Exception { ExecutorService pool = Executors.newFixedThreadPool(10); Future&lt;String&gt; future = pool.submit(new Callable&lt;String&gt;() { @Override public String call() throws Exception { return &quot;Hello&quot;; } }); String result = future.get(); System.out.println(result); }}submit(Runnable task, T result);12345678910111213141516171819202122232425262728public class ThreadPool { public static void main(String[] args) throws Exception { ExecutorService pool = Executors.newFixedThreadPool(10); Data data = new Data(); Future&lt;Data&gt; future = pool.submit(new MyRunnable(data), data); String result = future.get().getName(); System.out.println(result); }}class Data { String name; public String getName() { return name; } public void setName(String name) { this.name = name; }}class MyRunnable implements Runnable { private Data data; public MyRunnable(Data data) { this.data = data; } @Override public void run() { data.setName(&quot;yinjihuan&quot;); }}Future submit(Runnable task);1直接submit一个Runnable是拿不到返回值的，返回值就是null.6、五种线程池的使用场景newSingleThreadExecutor：一个单线程的线程池，可以用于需要保证顺序执行的场景，并且只有一个线程在执行。newFixedThreadPool：一个固定大小的线程池，可以用于已知并发压力的情况下，对线程数做限制。newCachedThreadPool：一个可以无限扩大的线程池，比较适合处理执行时间比较小的任务。newScheduledThreadPool：可以延时启动，定时启动的线程池，适用于需要多个后台线程执行周期任务的场景。newWorkStealingPool：一个拥有多个任务队列的线程池，可以减少连接数，创建当前可用cpu数量的线程来并行执行。7、线程池的关闭关闭线程池可以调用shutdownNow和shutdown两个方法来实现shutdownNow：对正在执行的任务全部发出interrupt()，停止执行，对还未开始执行的任务全部取消，并且返回还没开始的任务列表。123456789101112131415161718public class ThreadPool { public static void main(String[] args) throws Exception { ExecutorService pool = Executors.newFixedThreadPool(1); for (int i = 0; i &lt; 5; i++) { System.err.println(i); pool.execute(() -&gt; { try { Thread.sleep(30000); System.out.println(&quot;--&quot;); } catch (Exception e) { e.printStackTrace(); } }); } Thread.sleep(1000); List&lt;Runnable&gt; runs = pool.shutdownNow(); }}上面的代码模拟了立即取消的场景，往线程池里添加5个线程任务，然后sleep一段时间，线程池只有一个线程，如果此时调用shutdownNow后应该需要中断一个正在执行的任务和返回4个还未执行的任务，控制台输出下面的内容：1234567891011121314151601234[fs.ThreadPool$$Lambda$1/990368553@682a0b20, fs.ThreadPool$$Lambda$1/990368553@682a0b20, fs.ThreadPool$$Lambda$1/990368553@682a0b20, fs.ThreadPool$$Lambda$1/990368553@682a0b20]java.lang.InterruptedException: sleep interrupted at java.lang.Thread.sleep(Native Method) at fs.ThreadPool.lambda$0(ThreadPool.java:15) at fs.ThreadPool$$Lambda$1/990368553.run(Unknown Source) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at java.lang.Thread.run(Thread.java:745)shutdown：当我们调用shutdown后，线程池将不再接受新的任务，但也不会去强制终止已经提交或者正在执行中的任务。1234567891011121314151617181920212223242526public class ThreadPool { public static void main(String[] args) throws Exception { ExecutorService pool = Executors.newFixedThreadPool(1); for (int i = 0; i &lt; 5; i++) { System.err.println(i); pool.execute(() -&gt; { try { Thread.sleep(30000); System.out.println(&quot;--&quot;); } catch (Exception e) { e.printStackTrace(); } }); } Thread.sleep(1000); pool.shutdown(); pool.execute(() -&gt; { try { Thread.sleep(30000); System.out.println(&quot;--&quot;); } catch (Exception e) { e.printStackTrace(); } }); }}上面的代码模拟了正在运行的状态，然后调用shutdown，接着再往里面添加任务，肯定是拒绝添加的，请看输出结果：1234567891001234Exception in thread &quot;main&quot; java.util.concurrent.RejectedExecutionException: Task fs.ThreadPool$$Lambda$2/1747585824@3d075dc0 rejected from java.util.concurrent.ThreadPoolExecutor@214c265e[Shutting down, pool size = 1, active threads = 1, queued tasks = 4, completed tasks = 0] at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047) at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823) at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1369) at fs.ThreadPool.main(ThreadPool.java:24)还有一些业务场景下需要知道线程池中的任务是否全部执行完成，当我们关闭线程池之后，可以用isTerminated来判断所有的线程是否执行完成，千万不要用isShutdown，isShutdown只是返回你是否调用过shutdown的结果。12345678910111213141516171819202122232425public class ThreadPool { public static void main(String[] args) throws Exception { ExecutorService pool = Executors.newFixedThreadPool(1); for (int i = 0; i &lt; 5; i++) { System.err.println(i); pool.execute(() -&gt; { try { Thread.sleep(3000); System.out.println(&quot;--&quot;); } catch (Exception e) { e.printStackTrace(); } }); } Thread.sleep(1000); pool.shutdown(); while(true){ if(pool.isTerminated()){ System.out.println(&quot;所有的子线程都结束了！&quot;); break; } Thread.sleep(1000); } }}8、自定义线程池在实际的使用过程中，大部分我们都是用Executors去创建线程池直接使用，如果有一些其他的需求，比如指定线程池的拒绝策略，阻塞队列的类型，线程名称的前缀等等，我们可以采用自定义线程池的方式来解决。如果只是简单的想要改变线程名称的前缀的话可以自定义ThreadFactory来实现，在Executors.new…中有一个ThreadFactory的参数，如果没有指定则用的是DefaultThreadFactory。自定义线程池核心在于创建一个ThreadPoolExecutor对象，指定参数下面我们看下ThreadPoolExecutor构造函数的定义：1234567public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) ;corePoolSize线程池大小，决定着新提交的任务是新开线程去执行还是放到任务队列中，也是线程池的最最核心的参数。一般线程池开始时是没有线程的，只有当任务来了并且线程数量小于corePoolSize才会创建线程。maximumPoolSize最大线程数，线程池能创建的最大线程数量。keepAliveTime在线程数量超过corePoolSize后，多余空闲线程的最大存活时间。unit时间单位workQueue存放来不及处理的任务的队列，是一个BlockingQueue。threadFactory生产线程的工厂类，可以定义线程名，优先级等。handler拒绝策略，当任务来不及处理的时候，如何处理, 前面有讲解。了解上面的参数信息后我们就可以定义自己的线程池了，我这边用ArrayBlockingQueue替换了LinkedBlockingQueue，指定了队列的大小，当任务超出队列大小之后使用CallerRunsPolicy拒绝策略处理。这样做的好处是严格控制了队列的大小，不会出现一直往里面添加任务的情况，有的时候任务处理的比较慢，任务数量过多会占用大量内存，导致内存溢出。当然你也可以在提交到线程池的入口进行控制，比如用CountDownLatch, Semaphore等。1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * 自定义线程池&lt;br&gt; * 默认的newFixedThreadPool里的LinkedBlockingQueue是一个无边界队列，如果不断的往里加任务，最终会导致内存的不可控&lt;br&gt; * 增加了有边界的队列，使用了CallerRunsPolicy拒绝策略 * @author yinjihuan * */public class FangjiaThreadPoolExecutor { private static ExecutorService executorService = newFixedThreadPool(50); private static ExecutorService newFixedThreadPool(int nThreads) { return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new ArrayBlockingQueue&lt;Runnable&gt;(10000), new DefaultThreadFactory(), new CallerRunsPolicy()); } public static void execute(Runnable command) { executorService.execute(command); } public static void shutdown() { executorService.shutdown(); } static class DefaultThreadFactory implements ThreadFactory { private static final AtomicInteger poolNumber = new AtomicInteger(1); private final ThreadGroup group; private final AtomicInteger threadNumber = new AtomicInteger(1); private final String namePrefix; DefaultThreadFactory() { SecurityManager s = System.getSecurityManager(); group = (s != null) ? s.getThreadGroup() : Thread.currentThread().getThreadGroup(); namePrefix = &quot;FSH-pool-&quot; + poolNumber.getAndIncrement() + &quot;-thread-&quot;; } public Thread newThread(Runnable r) { Thread t = new Thread(group, r, namePrefix + threadNumber.getAndIncrement(), 0); if (t.isDaemon()) t.setDaemon(false); if (t.getPriority() != Thread.NORM_PRIORITY) t.setPriority(Thread.NORM_PRIORITY); return t; } }}END","link":"/2018/06/21/Java-thread-pool/"},{"title":"Jenkins使用说明Ⅱ- 新建一个maven任务","text":"前文中描述了如何安装jenkins以及对jenkins的配置接下来这篇文章将会具体的描述怎么创建一个任务详情请看本文详细内容Jenkins &gt;&gt; 新建任务对任务的具体配置，图中有对各个配置的介绍 配置完成，立即构建吧","link":"/2018/12/01/Jenkins-create-maven-task/"},{"title":"Jenkins使用说明Ⅰ- 安装以及基本配置","text":"jenkins作为一个自动化部署的强力工具还是很值的去使用和了解其中的配置的在此简单记录一下Jenkins的安装配置过程系统环境 ：Centos 6.10Jdk版本：1.8.0_191假设本机IP : 10.0.0.1Jenkins的安装访问Jenkins官网下载war包1wget http://mirrors.tuna.tsinghua.edu.cn/jenkins/war-stable/2.138.3/jenkins.war使用命令行的形式启动Jenkins12/usr/local/java/jdk1.8.0_191-x64/bin/java -jar jenkins.war --httpPort=9001// --httpPort=9001 指定访问端口访问http://10.0.0.1:9001，根据提示安装即可Jenkins &gt;&gt; 系统管理 &gt;&gt; 插件管理，安装需要的插件，需要但不限于：1234567891011Dashboard ViewEmail Extension PluginGit Parameter Plug-InGit pluginGitlab Authentication pluginGitlab Hook PluginGitlab Merge Request BuilderGitLab PluginMaven Integration pluginPublish Over SSHWorkspace Cleanup Plugin基本配置Jenkins &gt;&gt; 系统管理 &gt;&gt; 全局工具配置，配置jdk、maven等信息mavne部分配置文件设置如下123456789101112131415161718192021222324252627282930// 省略开头...&lt;localRepository&gt;/data/local/repository&lt;/localRepository&gt;&lt;servers&gt; &lt;server&gt; &lt;id&gt;maven-thirdparty&lt;/id&gt; &lt;username&gt;nexus登录名&lt;/username&gt; &lt;password&gt;nexus密码&lt;/password&gt; &lt;/server&gt; &lt;server&gt; &lt;id&gt;maven-releases&lt;/id&gt; &lt;username&gt;nexus登录名&lt;/username&gt; &lt;password&gt;nexus密码&lt;/password&gt; &lt;/server&gt; &lt;server&gt; &lt;id&gt;maven-snapshots&lt;/id&gt; &lt;username&gt;nexus登录名&lt;/username&gt; &lt;password&gt;nexus密码&lt;/password&gt; &lt;/server&gt;&lt;/servers&gt;&lt;mirrors&gt; &lt;mirror&gt; &lt;id&gt;nexus-center&lt;/id&gt; &lt;mirrorOf&gt;nexus&lt;/mirrorOf&gt; &lt;name&gt;Nexus local&lt;/name&gt; &lt;url&gt;此处填写nexus私服地址&lt;/url&gt; &lt;/mirror&gt;&lt;/mirrors&gt;// 省略结尾...Jenkins &gt;&gt; 系统管理 &gt;&gt; 全局安全配置，配置用户权限等信息Jenkins &gt;&gt; 系统管理 &gt;&gt; 系统设置，配置gitlab、ssh相关信息 附上上图中的命令123[root@]# cd /root/.ssh/[root@]# cat id_rsa.pub &gt;&gt; authorized_keys[root@]# scp authorized_keys root@10.13.0.93:/root/.ssh/","link":"/2018/11/30/Jenkins-install-and-setting/"},{"title":"Jenkins的权限管理","text":"本文接上篇内容。之前解决了一个因为权限插件导致的启动报错问题。这里将会介绍如何对权限做管理。也许犯错真的能让人成长，在前面对启动错误进行处理的时候，我发现config.xml中有这么一段内容：1234567&lt;authorizationStrategy class=&quot;com.michelin.cio.hudson.plugins.rolestrategy.RoleBasedAuthorizationStrategy&quot;&gt; &lt;roleMap type=&quot;globalRoles&quot;&gt; &lt;此处省略部分内容/&gt; &lt;/roleMap&gt; &lt;roleMap type=&quot;slaveRoles&quot;/&gt; &lt;roleMap type=&quot;projectRoles&quot;/&gt;&lt;/authorizationStrategy&gt;projectRoles!!! 我不就是因为找不到projectRoles才准备卸载重装插件的吗（大写的黑人问号脸）？？PS： 这里用我自己的理解解答一下为什么Item roles就是project roles。以前jenkins新建任务好像是New job，最近貌似改成了New item。所以你懂了吧？正文内容安装插件Role-base Authorization StrategyJenkins &gt; Manage Jenkin &gt; Configure Global Security &gt; Authorization &gt; 选中Role-Based StrategyJenkins &gt; Manage Jenkin &gt; Manage and Assign RolesManage RoleAssign Roles关于权限配置就聊到这里了，验证是否有效这里就省略了哈（当然我是亲测有效的，这里懒的写了）~","link":"/2019/12/28/Jenkins-role-base-authorization-strategy-plugin/"},{"title":"Jenkins启动报错解决","text":"误删Jenkins权限管理插件，导致Jenkins重启直接报错！如何恢复？且看本篇内容。前情提要为了对jenkins任务做权限管理，百度了网上各种教程，说是要安装Role-based Authorization Strategy插件，使用插件管理中project roles可以实现。于是乎下载安装、鼓捣一阵。发现没有project roles这部分内容！难道插件版本有问题？卸载之…接着出大问题，jenkins启不来了！！！报错内容如下(有部分删减)：123456789101112131415161718192021222324252627282930313233com.thoughtworks.xstream.mapper.CannotResolveClassException: com.michelin.cio.hudson.plugins.rolestrategy.RoleBasedAuthorizationStrategy at com.thoughtworks.xstream.mapper.DefaultMapper.realClass(DefaultMapper.java:79) at com.thoughtworks.xstream.mapper.MapperWrapper.realClass(MapperWrapper.java:30) at com.thoughtworks.xstream.mapper.DynamicProxyMapper.realClass(DynamicProxyMapper.java:55) at com.thoughtworks.xstream.mapper.MapperWrapper.realClass(MapperWrapper.java:30) ......Caused: jenkins.util.xstream.CriticalXStreamException: com.michelin.cio.hudson.plugins.rolestrategy.RoleBasedAuthorizationStrategy : com.michelin.cio.hudson.plugins.rolestrategy.RoleBasedAuthorizationStrategy---- Debugging information ----message : com.michelin.cio.hudson.plugins.rolestrategy.RoleBasedAuthorizationStrategycause-exception : com.thoughtworks.xstream.mapper.CannotResolveClassExceptioncause-message : com.michelin.cio.hudson.plugins.rolestrategy.RoleBasedAuthorizationStrategyclass : hudson.model.Hudsonrequired-type : hudson.model.Hudsonconverter-type : hudson.util.RobustReflectionConverterpath : /hudson/authorizationStrategyline number : 9version : not available------------------------------- ...... at hudson.util.XStream2.unmarshal(XStream2.java:162) at hudson.util.XStream2.unmarshal(XStream2.java:133) at com.thoughtworks.xstream.XStream.unmarshal(XStream.java:1173) at hudson.XmlFile.unmarshal(XmlFile.java:180)Caused: java.io.IOException: Unable to read C:\\Users\\Administrator\\.jenkins\\config.xml at hudson.XmlFile.unmarshal(XmlFile.java:183) at hudson.XmlFile.unmarshal(XmlFile.java:163) ......Caused: org.jvnet.hudson.reactor.ReactorException at org.jvnet.hudson.reactor.Reactor.execute(Reactor.java:282) at jenkins.InitReactorRunner.run(InitReactorRunner.java:48) ......Caused: hudson.util.HudsonFailedToLoad at hudson.WebAppMain$3.run(WebAppMain.java:250)解决方案（此处省略一万字的因为Jenkins启动失败导致的心理活动描写）内心平静下后，仔细观察报错内容，进行分析：CannotResolveClassException: 无法对这个类com.michelin.cio.hudson.plugins.rolestrategy.RoleBasedAuthorizationStrategy做正确的处理CriticalXStreamException: XStream？？ 这是在解析什么？？ 解析文件？？Unable to read C:\\Users\\Administrator\\.jenkins\\config.xml： XStream在解析[config.xml]时遇到了无法处理的类[RoleBasedAuthorizationStrategy]此时你可能不会想到一个问题，就是config.xml里面有什么内容？不好意思，我就打开了这个文件观察了一下，结果恍然大悟。config.xml文件的内容是下面这个样子的，你有没有发现什么呢？1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980&lt;?xml version='1.1' encoding='UTF-8'?&gt;&lt;hudson&gt; &lt;disabledAdministrativeMonitors/&gt; &lt;version&gt;2.204.1&lt;/version&gt; &lt;installStateName&gt;RUNNING&lt;/installStateName&gt; &lt;numExecutors&gt;2&lt;/numExecutors&gt; &lt;mode&gt;NORMAL&lt;/mode&gt; &lt;useSecurity&gt;true&lt;/useSecurity&gt; &lt;authorizationStrategy class=&quot;com.michelin.cio.hudson.plugins.rolestrategy.RoleBasedAuthorizationStrategy&quot;&gt; &lt;roleMap type=&quot;globalRoles&quot;&gt; &lt;role name=&quot;admin&quot; pattern=&quot;.*&quot;&gt; &lt;permissions&gt; &lt;permission&gt;hudson.model.Hudson.Read&lt;/permission&gt; &lt;permission&gt;hudson.model.View.Delete&lt;/permission&gt; &lt;permission&gt;hudson.model.Computer.Connect&lt;/permission&gt; &lt;permission&gt;hudson.model.Item.Create&lt;/permission&gt; &lt;permission&gt;hudson.model.Item.Workspace&lt;/permission&gt; &lt;permission&gt;hudson.model.Computer.Create&lt;/permission&gt; &lt;permission&gt;hudson.model.View.Configure&lt;/permission&gt; &lt;permission&gt;hudson.model.Computer.Provision&lt;/permission&gt; &lt;permission&gt;hudson.model.Computer.Build&lt;/permission&gt; &lt;permission&gt;hudson.model.Item.Configure&lt;/permission&gt; &lt;permission&gt;hudson.model.View.Read&lt;/permission&gt; &lt;permission&gt;hudson.model.View.Create&lt;/permission&gt; &lt;permission&gt;hudson.model.Hudson.Administer&lt;/permission&gt; &lt;permission&gt;hudson.model.Item.Cancel&lt;/permission&gt; &lt;permission&gt;hudson.model.Item.Delete&lt;/permission&gt; &lt;permission&gt;hudson.model.Item.Read&lt;/permission&gt; &lt;permission&gt;hudson.model.Computer.Configure&lt;/permission&gt; &lt;permission&gt;hudson.model.Computer.Delete&lt;/permission&gt; &lt;permission&gt;hudson.model.Item.Build&lt;/permission&gt; &lt;permission&gt;hudson.model.Computer.Disconnect&lt;/permission&gt; &lt;permission&gt;hudson.model.Item.Discover&lt;/permission&gt; &lt;/permissions&gt; &lt;assignedSIDs&gt; &lt;sid&gt;admin&lt;/sid&gt; &lt;/assignedSIDs&gt; &lt;/role&gt; &lt;role name=&quot;tester&quot; pattern=&quot;.*&quot;&gt; &lt;permissions&gt; &lt;permission&gt;hudson.model.Hudson.Read&lt;/permission&gt; &lt;/permissions&gt; &lt;assignedSIDs/&gt; &lt;/role&gt; &lt;/roleMap&gt; &lt;roleMap type=&quot;slaveRoles&quot;/&gt; &lt;roleMap type=&quot;projectRoles&quot;/&gt; &lt;/authorizationStrategy&gt; &lt;securityRealm class=&quot;hudson.security.HudsonPrivateSecurityRealm&quot;&gt; &lt;disableSignup&gt;true&lt;/disableSignup&gt; &lt;enableCaptcha&gt;false&lt;/enableCaptcha&gt; &lt;/securityRealm&gt; &lt;disableRememberMe&gt;false&lt;/disableRememberMe&gt; &lt;projectNamingStrategy class=&quot;jenkins.model.ProjectNamingStrategy$DefaultProjectNamingStrategy&quot;/&gt; &lt;workspaceDir&gt;${JENKINS_HOME}/workspace/${ITEM_FULL_NAME}&lt;/workspaceDir&gt; &lt;buildsDir&gt;${ITEM_ROOTDIR}/builds&lt;/buildsDir&gt; &lt;markupFormatter class=&quot;hudson.markup.EscapedMarkupFormatter&quot;/&gt; &lt;jdks/&gt; &lt;viewsTabBar class=&quot;hudson.views.DefaultViewsTabBar&quot;/&gt; &lt;myViewsTabBar class=&quot;hudson.views.DefaultMyViewsTabBar&quot;/&gt; &lt;clouds/&gt; &lt;scmCheckoutRetryCount&gt;0&lt;/scmCheckoutRetryCount&gt; &lt;views&gt; &lt;hudson.model.AllView&gt; &lt;owner class=&quot;hudson&quot; reference=&quot;../../..&quot;/&gt; &lt;name&gt;all&lt;/name&gt; &lt;filterExecutors&gt;false&lt;/filterExecutors&gt; &lt;filterQueue&gt;false&lt;/filterQueue&gt; &lt;properties class=&quot;hudson.model.View$PropertyList&quot;/&gt; &lt;/hudson.model.AllView&gt; &lt;/views&gt; &lt;primaryView&gt;all&lt;/primaryView&gt; &lt;slaveAgentPort&gt;-1&lt;/slaveAgentPort&gt; &lt;label&gt;&lt;/label&gt; &lt;crumbIssuer class=&quot;hudson.security.csrf.DefaultCrumbIssuer&quot;&gt; &lt;excludeClientIPFromCrumb&gt;false&lt;/excludeClientIPFromCrumb&gt; &lt;/crumbIssuer&gt; &lt;nodeProperties/&gt; &lt;globalNodeProperties/&gt;&lt;/hudson&gt;从文件内容可以看出，这里面有权限插件模块的部分定义，你会发现报错的类就在xml定义了。因为插件被卸载，这部分定义内容还在，所以启动也就出大问题。只需要删除&lt;authorizationStrategy&gt;...&lt;/authorizationStrategy&gt;这部分内容，jenkins就可以重新启动起来啦。问题解决了，继续权限管理的设置，详情请看下篇文章~","link":"/2019/12/28/Jenkins-startup-error/"},{"title":"Python图形化界面Tkinter(二)-Button&amp;Label","text":"在上一篇里面简单的介绍了Tkinter怎么去创建一个窗体接下来一起看看Button&amp;Label这两个控件的使用代码以及注释如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#!/usr/bin/python# -*- coding: UTF-8 -*-import tkinter as tk# 创建窗体window = tk.Tk()window.title('Tk Demo')window.geometry('350x500')# 创建了一个字符串类型的变量l_str = tk.StringVar()l = tk.Label( window, # Label是创建在window上的 textvariable=l_str, # 可变的值，label中的text是l_str的内容 bg='green', # 给Label初始化背景颜色 font=('console', 12), # Label字体样式 width=15, # 宽 height=2 # 高)l.pack()# 创建一个布尔类型的值，用于记录点击on_click = False# 创建一个点击事件方法def click_me(): global on_click if not on_click: on_click = True l_str.set('click') # 给l_str赋值，即label中显示的内容 else: on_click = False l_str.set('')# 创建一个按钮b = tk.Button( window, text='click me', # 按钮显示内容 width=15, height=2, command=click_me, # 绑定一个点击事件)b.pack()# 进入消息循环window.mainloop()执行代码，具体效果如下：","link":"/2018/06/09/Python-tkinter-Button-and-Label/"},{"title":"Python图形化界面Tkinter(三)-CheckButton","text":"在上一篇里面简单的介绍了Tkinter中Label以及Button的使用接下来一起看看CheckButton的用法代码以及注释如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152#!/usr/bin/python# -*- coding: UTF-8 -*-import tkinter as tk# 创建窗体window = tk.Tk()window.title('Tk Demo')window.geometry('350x200')l = tk.Label( window, bg='yellow', width=20, text='empty')l.pack()# 定义了一个函数，根据checkbutton选择做出相应的变化def print_selection(): if (val1.get() == 0) &amp; (val2.get() == 0): l.config(text='both un-like') elif (val1.get() == 1) &amp; (val2.get() == 0): l.config(text='like python') elif (val1.get() == 0) &amp; (val2.get() == 1): l.config(text='like java') else: l.config(text='both like')# 定义一个int类型变量，记录checkbutton的值val1 = tk.IntVar()c1 = tk.Checkbutton( window, text='python', variable=val1, onvalue=1, offvalue=0, command=print_selection)val2 = tk.IntVar()c2 = tk.Checkbutton( window, text='java', variable=val2, onvalue=1, offvalue=0, command=print_selection)c1.pack()c2.pack()window.mainloop()执行代码，具体效果如下：","link":"/2018/06/11/Python-tkinter-Checkbutton/"},{"title":"Python图形化界面Tkinter(六)-ComboBox","text":"在上一篇里面简单的介绍了Tkinter中ListBox的使用接下来一起看看ComboBox(下拉列表框)的用法代码以及注释如下：1234567891011121314151617181920212223242526272829#!/usr/bin/python# -*- coding: UTF-8 -*-import tkinter as tk# 创建窗体from tkinter import ttkwindow = tk.Tk()window.title('Tk Demo')window.geometry('350x500')# 用来显示下拉框值的Labelvar = tk.StringVar()la = tk.Label(window, textvariable=var)la.grid(column=1, row=1)def click(): var.set(number.get())number = tk.StringVar()numberChosen = ttk.Combobox(window, width=12, textvariable=number)numberChosen['values'] = (1, 2, 4, 42, 100) # 设置下拉列表的值numberChosen.grid(column=1, row=1) # 设置其在界面中出现的位置 column代表列 row 代表行numberChosen.current(0) # 设置下拉列表默认显示的值，0为 numberChosen['values'] 的下标值b1 = tk.Button(window, text='click', command=click)b1.place(x=50, y=50, anchor=tk.NW)window.mainloop()扩展下面展示Label的另一种赋值方式具体代码如下：1234567891011# 用来显示下拉框值的Labelvar = tk.StringVar()la = tk.Label(window, text=&quot;&quot;)la.grid(column=1, row=1)def click(): la.config(text=number.get()) # 这里使用的是label的config方法，将值赋给text# 需要注意的一点是，label里面不要出现textvariable# 如果有textvariable属性，那么这个赋值不会成功执行代码，具体效果如下：","link":"/2018/06/16/Python-tkinter-ComboBox/"},{"title":"Python图形化界面Tkinter(八)-Entry&amp;Text","text":"在上一篇里面简单的介绍了Tkinter中MenuBar的使用接下来一起看看文本输出框Entry&amp;Text的用法值得一提的是Tkinter中的Entry控件相当于Html里面的inputText控件相当于Html中的textarea接下来直接上源代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#!/usr/bin/python# -*- coding: UTF-8 -*-import tkinter as tk# 创建窗体window = tk.Tk()window.title('Tk Demo')window.geometry('350x500')e = tk.Entry( window, show='*' # 里面文本内容全部显示为*，密码输入框的效果)e.pack()t = tk.Text( window, height=2, width=15)t.pack()def insert_point(): var = e.get() t.insert(tk.INSERT, var) # 插入到光标位置 # t.insert(1.2, var) # 插入到第1行、第2位后面def insert_end(): var = e.get() t.insert(tk.END, var) # 插入到最后面# 点击此按钮，把Entry的内容插入到Text光标位置b1 = tk.Button( window, text='insert_point', command=insert_point)b1.pack()# 点击此按钮，把Entry的内容插入到Text最后面b2 = tk.Button( window, text='insert_end', command=insert_end)b2.pack()window.mainloop()执行代码，具体效果如下：","link":"/2018/06/17/Python-tkinter-Entry-and-Text/"},{"title":"Python图形化界面Tkinter(一)-Frame","text":"最近新学Python接触到了Python的图形化界面开发库Tkinter因为以前也有用过其他语言的图形开发库比如：C的MFC、Java的Swing、以及Qt现在，一起记录一下Tkinter是这么用的吧！这里首先要介绍的是Frame的用法具体的代码以及注释如下：开发环境说明Python：3.6.3IDE:Pycharm123456789101112131415161718192021222324252627282930313233#!/usr/bin/python# -*- coding: UTF-8 -*-import tkinter as tk # 2.x版本的Python用:Tkinter# 创建窗体window = tk.Tk()# 窗口属性设置window.title('Tk Demo') # 设置窗口的标题window.geometry('350x500') # 窗口的大小（宽x高）# window.config(bg=&quot;CadetBlue&quot;) # 背景色# window.attributes(&quot;-alpha&quot;, 0.5) # 透明度# 新建一个文本框控件Labeltk.Label(window, text='on the window').pack()# 在window上新建Frame控件frm = tk.Frame(window).pack()# 在frm上新建Frame控件frm_l = tk.Frame(frm)frm_r = tk.Frame(frm)frm_l.pack(side='left')frm_r.pack(side='right')tk.Label(frm_l, text='on the frm_l1').pack()tk.Label(frm_l, text='on the frm_l2').pack()tk.Label(frm_r, text='on the frm_r').pack()# 进入主循环，显示窗口window.mainloop()执行代码，具体效果如下：","link":"/2018/06/09/Python-tkinter-Frame/"},{"title":"Python图形化界面Tkinter(七)-MenuBar","text":"在上一篇里面简单的介绍了Tkinter中ComboBox的使用接下来一起看看MenuBar的用法代码以及注释如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#!/usr/bin/python# -*- coding: UTF-8 -*-import tkinter as tk# 创建窗体window = tk.Tk()window.title('Tk Demo')window.geometry('350x500')# 用于显示计数值的Labell = tk.Label( window, bg='yellow', width=4,)l.pack()count = 0# 设置一个函数，只要点击了菜单栏，计数加一def do_job(): global count l.config(text=str(count)) count += 1 pass# 创建一个菜单栏menubar = tk.Menu(window)filemenu = tk.Menu(menubar, tearoff=0)# 给菜单栏添加一个名为‘File’的菜单项menubar.add_cascade(label='File', menu=filemenu)# 往‘File’的菜单项里面添加子选项filemenu.add_command(label='New', command=do_job)filemenu.add_command(label='Open', command=do_job)filemenu.add_command(label='Save', command=do_job)# 添加分割线filemenu.add_separator()# 创建子菜单submenu = tk.Menu(filemenu)filemenu.add_cascade(label='Import', menu=submenu)submenu.add_command(label='submenu', command=do_job)# 退出filemenu.add_separator()filemenu.add_command(label='Exit', command=window.quit)window.config(menu=menubar)window.mainloop()执行代码，具体效果如下：","link":"/2018/06/16/Python-tkinter-MenuBar/"},{"title":"Python图形化界面Tkinter(五)-ListBox","text":"在上一篇里面简单的介绍了Tkinter中RadioButton的使用接下来一起看看ListBox的用法代码以及注释如下：123456789101112131415161718192021222324252627282930313233343536#!/usr/bin/python# -*- coding: UTF-8 -*-import tkinter as tk# 创建窗体window = tk.Tk()window.title('Tk Demo')window.geometry('350x300')# 用来显示选中值的Labelvar1 = tk.StringVar()label = tk.Label(window, bg='yellow', width=4, textvariable=var1)label.pack()# 获取Listbox选中值，并显示在Label上def print_selection(): value = lb.get(lb.curselection()) var1.set(value)b1 = tk.Button(window, text='print_selection', command=print_selection)b1.pack()var2 = tk.StringVar()# Listbox的值var2.set((11, 22, 33, 44)) # 初始化一个Listbox,模式为单选模式lb = tk.Listbox(window, listvariable=var2, selectmode=tk.SINGLE)# 默认选中第一个，选中第0个到第0个,即第一个。lb.select_set(0, 0) lb.pack()window.mainloop()执行代码，具体效果如下：加强练习通过选择不同的RadioButton按钮展示不同的List列表内容123456789101112131415161718# 在上一段代码的 22行跟24行中间加入下面这段代码即可# 定义两个函数，用来改变Listbox的值def f1(): global var2 var2.set((11, 22, 33, 44))def f2(): global var2 var2.set((1, 2, 3, 4))# 定义两个单选框，根据选择的不同来触发f1()根f2()两个事件var = tk.StringVar()var.set(&quot;A&quot;)r1 = tk.Radiobutton(window, text='option A', variable=var, value='A', command=f1)r1.pack()r2 = tk.Radiobutton(window, text='option B', variable=var, value='B', command=f2)r2.pack()执行代码，具体效果如下：当ListBox里面的数据量多的时候可以使用Scrollbar做个滚动123456789101112131415161718#!/usr/bin/python# -*- coding: UTF-8 -*-import tkinter as tkwindow = tk.Tk()sb = tk.Scrollbar(window)sb.pack(side=tk.RIGHT, fill=tk.Y)lb = tk.Listbox(window, yscrollcommand=sb.set)for item in range(1, 20): lb.insert(tk.END, item)lb.pack()sb.config(command=lb.yview)window.mainloop()执行代码，具体效果如下：","link":"/2018/06/14/Python-tkinter-ListBox/"},{"title":"Python图形化界面Tkinter(九)-MessageBox","text":"在上一篇里面简单的介绍了Tkinter中Entry&amp;Text的使用接下来一起看看消息提示MessageBox的用法Tkinter的MessageBox有八种类型具体有那八种下面代码中会一一介绍1234567891011121314151617181920212223242526272829303132333435363738#!/usr/bin/python# -*- coding: UTF-8 -*-import tkinter as tkfrom tkinter import messagebox# 创建窗体window = tk.Tk()window.title('Tk Demo')window.geometry('350x500')def click(): # 三种级别的消息提示框 messagebox.showinfo(title='info', message='info') messagebox.showerror(title='error', message='error') messagebox.showwarning(title='warning', message='warning') # 五种带选择项的消息提示框 result1 = messagebox.askokcancel(title='ask', message='ok or cancel ?') print(result1) # 返回值为： True、False result2 = messagebox.askquestion(title='question', message='yes or no ?') print(result2) # 返回值为： yes、no result3 = messagebox.askyesno(title='yesno', message='yes or no ?') print(result3) # 返回值为： True、False result4 = messagebox.askretrycancel(title='ask', message='retry or cancel') print(result4) # 返回值为： True、False result5 = messagebox.askyesnocancel(title='ask', message='yes no or cancel') print(result5) # 返回值为： True、False、None# 用于触发MessageBox的按钮tk.Button(window, text=&quot;click&quot;, command=click).pack()# 进入消息主循环window.mainloop()执行代码，具体效果如下：","link":"/2018/06/17/Python-tkinter-MessageBox/"},{"title":"Python图形化界面Tkinter(四)-RadioButton","text":"在上一篇里面简单的介绍了Tkinter中CheckButton的使用接下来一起看看RadioButton的用法代码以及注释如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354#!/usr/bin/python# -*- coding: UTF-8 -*-import tkinter as tk# 创建窗体window = tk.Tk()window.title('Tk Demo')window.geometry('350x500')# 定义Label对象，用于显示RadioButton选中值var = tk.StringVar()l = tk.Label( window, bg='yellow', width=4, textvariable=var)l.pack()# RadioButton点击事件，改变Label文本内容def print_selection(): l.config(text='you have select' + var.get())# 默认值，默认选中:Avar.set(&quot;A&quot;)r1 = tk.Radiobutton( window, text='option A', variable=var, value='A', command=print_selection)r1.pack()r1 = tk.Radiobutton( window, text='option B', variable=var, value='B', command=print_selection)r1.pack()r1 = tk.Radiobutton( window, text='option C', variable=var, value='C', command=print_selection)r1.pack()window.mainloop()执行代码，具体效果如下：","link":"/2018/06/11/Python-tkinter-RadioButton/"},{"title":"Python图形化界面Tkinter(十)-实战应用","text":"在这篇文章之前一共花了九篇文章的篇幅通过一些简单的示例分别对Tkinter的一些常用的控件进行了介绍接下来的这篇文章会通过实际应用的方式，对前面的内容做一个总结对于软件应用的需求，大部分都是来源于生活这篇实战，也是从我工作内容中产生的灵感假如你在开发的过程中，需要维护多个项目然后每个项目都要对应不同的环境进行打包发布等操作而这些操作往往都是一些重复性的工作所以我就想，为什么不利用Python写一个自动化的过程呢？利用一个可视化的界面，我只需要在上面选择好我需要打包或者发布的项目接着在选择打包或发布到那个环境下，点击执行，然后就自动的帮你完成了之后的一系列动作。PS: 此处只展示界面部分代码，完整的自动化代码如下：自动化的项目代码所以接下来，我就要开始设计这么一个可视化的操作界面需要包含：环境的选择、项目的选择、开始执行的按钮等等…那么，现在开始：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091# ====== start 窗口布局 =========window = tk.Tk()window.title('开发利器之超好用又神奇的自动化工具 - Beta.1.0')x, y = 600, 460 # 定义窗口的宽高scr_x, scr_y = window.winfo_screenwidth(), window.winfo_screenheight() # 获取屏幕大小window.geometry(&quot;%dx%d+%d+%d&quot; % (x, y, (scr_x-x)/2, (scr_y-y)/2)) # 窗口居中显示window.resizable(0, 0) # 窗口大小固定，不能缩放# ======= Frame 整体框架搭建 ======# 创建三个不同背景颜色的Frame, 用来区别不同的内容frm_1 = tk.Frame(window, width=600, height=230, bg='CadetBlue').pack()frm_2 = tk.Frame(window, width=600, height=230, bg='DarkSeaGreen').pack()frm_3 = tk.Frame(window, width=155, height=600, bg='Beige').place(x=275, y=0, anchor=tk.NW)# 新建一个字体样式ft = font.Font(family='Courier New', size=14, weight=font.BOLD)# 创建三个Label,作用于之前的三个Frame中，给每个Frame命名lb1 = tk.Label(frm_1, text='Jenkins打包发布', font=ft, bg='CadetBlue')lb2 = tk.Label(frm_1, text='GitLab新增TAG', font=ft, bg='DarkSeaGreen')lb3 = tk.Label(frm_1, text='项目名称', font=ft, bg='Beige')# 绝对定位，这里面大部分控件都是用的绝对定位的方式lb1.place(x=5, y=5, anchor=tk.NW)lb2.place(x=5, y=245, anchor=tk.NW)lb3.place(x=280, y=5, anchor=tk.NW)# ======= Jenkins 上半部分布局 ======# 用于记录选中值的变量，默认选中J_PKG_DEVradio_var1 = tk.StringVar()radio_var1.set(Constant.J_PKG_DEV)# 定义了6个Radiobuttom，用于选择具体的发布环境dev_package = \\ tk.Radiobutton(frm_1, text='打包-Dev', variable=radio_var1, value=Constant.J_PKG_DEV, width=10, bg='CadetBlue')rc_package = \\ tk.Radiobutton(frm_1, text='打包-RC ', variable=radio_var1, value=Constant.J_PKG_RC, width=10, bg='CadetBlue')prd_package = \\ tk.Radiobutton(frm_1, text='打包-PRD', variable=radio_var1, value=Constant.J_PKG_PRD, width=10, bg='CadetBlue')dev_deploy = \\ tk.Radiobutton(frm_1, text='发布-Dev', variable=radio_var1, value=Constant.J_DEP_DEV, width=10, bg='CadetBlue')rc_deploy = \\ tk.Radiobutton(frm_1, text='发布-RC ', variable=radio_var1, value=Constant.J_DEP_RC, width=10, bg='CadetBlue')prd_deploy = \\ tk.Radiobutton(frm_1, text='发布-PRD', variable=radio_var1, value=Constant.J_DEP_PRD, width=10, bg='CadetBlue')# Radiobuttom位置分布dev_package.place(x=10, y=50, anchor=tk.NW)rc_package.place(x=10, y=85, anchor=tk.NW)prd_package.place(x=10, y=120, anchor=tk.NW)dev_deploy.place(x=100, y=50, anchor=tk.NW)rc_deploy.place(x=100, y=85, anchor=tk.NW)prd_deploy.place(x=100, y=120, anchor=tk.NW)# ===== Gitlab 下半部分布局 ======# 用于记录选中值的变量，默认选中RC_TAGradio_var2 = tk.StringVar()radio_var2.set(Constant.RC_TAG)rc_tag = \\ tk.Radiobutton(frm_2, text='Tag-RC ', variable=radio_var2, value=Constant.RC_TAG, width=10, bg='DarkSeaGreen')prd_tag = \\ tk.Radiobutton(frm_2, text='Tag-PRD', variable=radio_var2, value=Constant.PRD_TAG, width=10, bg='DarkSeaGreen')rc_tag.place(x=10, y=300, anchor=tk.NW)prd_tag.place(x=10, y=335, anchor=tk.NW)# ===== Project List 中间部分布局 ======# 定义了一个ListBox控件，用来展示项目列表pro_name = tk.StringVar()pro_list = tk.Listbox(frm_3, listvariable=pro_name, bg='Beige', width=21, height=300, exportselection=False)pro_list.place(x=275, y=50, anchor=tk.NW)# 获取项目列表，逐条插入for item in Constant.get_project_list(): pro_list.insert(tk.END, item)# ===== Button =======# 两个立即执行按钮btn_J = tk.Button(frm_1, width=10, height=1, text='开始执行', command=btn_j_click, bg='DarkSeaGreen')btn_G = tk.Button(frm_2, width=10, height=1, text='开始执行', command=btn_g_click, bg='CadetBlue')btn_J.place(x=500, y=120, anchor=tk.NW)btn_G.place(x=500, y=320, anchor=tk.NW)# 显示窗体window.mainloop()至此，整个窗口的布局就完成了执行代码，具体效果如下：","link":"/2018/06/17/Python-tkinter-pracetice/"},{"title":"Kafka的几个命令","text":"在《ELK安装以及配置》一文中，有介绍kafka的安装，此文记录几个kafka命令查看集群描述1bin/kafka-topics.sh --describe --zookeeper 127.0.0.1:2181Topic列表查询1bin/kafka-topics.sh --zookeeper 127.0.0.1:2181 --list消费者列表查询1bin/kafka-consumer-groups.sh --bootstrap-server node1:9092 --list显示某个消费组的消费详情1bin/kafka-consumer-groups.sh --bootstrap-server node1:9092 --describe --group test-consumer-group删除Topic12345[root@test-1 kafka_2.12-2.3.0]# bin/kafka-topics.sh --zookeeper 127.0.0.1:2181 --delete --topic test1Topic logs.lottery-service is marked for deletion.Note: This will have no impact if delete.topic.enable is not set to true.## 这条命令其实并不执行删除动作，仅仅是在zookeeper上标记该topic要被删除而已## 同时也提醒用户一定要提前打开delete.topic.enable开关，否则删除动作是不会执行的生产者1bin/kafka-console-producer.sh --broker-list node1:9092 --topic test消费者1bin/kafka-console-consumer.sh --bootstrap-server node1:9092 --topic test","link":"/2019/10/26/a-few-kafka-command/"},{"title":"关于博客园自定义样式","text":"导读众所周知博客园有一个自由开放的功能那就是自定义样式本篇内容不讲述如何调样式等技术知识只是在此提供一个我是如何去自定义我的博客园样式的思路供大家参考！ 欢迎拍砖~思路以及步骤我在做这个样式自定义的时候，首先的想法是把别人做的好的，直接拿过来用，但是发现总是达不到别人的那种效果，也许是扒代码水平有限，没有拿到关键部分。好吧，最后我只能自己一点点调，下面是我的整体的一个步骤：首先选一个自己喜欢的主题，或者说是容易改的主题吧，我这里选的是“darkgreentrip”这个主题然后把这个主题的主要的那部分css扒拉下来，我记得我这个主题好像是“darkgreentrip.css”和“darkgreentrip-mobile.css”把这两个文件上传到博客园后台，然后在后台设置“页首Html代码”这个区域放入引用代码接下来在禁用掉模板默认CSS，点击保存，观察效果如果跟之前主题效果是一样的，那么，我们现在就可以开始在这个基础上调整css样式了最后把调整后的css上传，保存，那么，就算大功告成了这里要说明一下的是，虽然步骤很简单，但是你会发现，你需要话大量的时间做倒数第二步的工作，用浏览器一点点选中样式，然后调css是一个很繁琐的过程，至少我是这么觉得的。但是最后完成后是相当开心的！如何使用我这个样式？如果你觉的我这个博客的样式还不错哟，那么请别忘了点赞丢硬币丢香蕉~~哈哈哈！回到主题，你可以按照下面的方法去使用它。首先，你需要选择我使用的主题：darkgreentrip然后，通过浏览器的调试模式或是其他的方式，拿到我所使用的css文件：trainoo--web.css、trainoo-mobile.css接着，把这两个文件上传到你的博客园后台最后，在设置那个模块需要加上如下代码段（有些地方需要做修改，改成自己的内容即可）博客侧边栏公告（支持HTML代码）（支持JS代码）1234567891011121314151617&lt;!--- 自定义侧边栏 ---&gt;&lt;div class=&quot;mySideBar&quot;&gt; &lt;p class=&quot;nickName&quot;&gt;昵称：&lt;a href=&quot;http://www.cnblogs.com/Trainoo/&quot;&gt;Trainoo&lt;/a&gt;&lt;/p&gt; &lt;p&gt;园龄：大概也就一百年吧~&lt;/p&gt; &lt;p&gt;粉丝：999999+&lt;/p&gt; &lt;p&gt;关注：999999+&lt;/p&gt; &lt;p&gt;邮箱：trainoo@163.com&lt;/p&gt; &lt;p&gt;代码库： &lt;a target=&quot;_blank&quot; href=&quot;https://gitee.com/trainoo&quot; class=&quot;glyphicon glyphicon-fire&quot;&gt;码云&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/jj-trainoo&quot; class=&quot;glyphicon glyphicon-tint&quot;&gt;GitHub&lt;/a&gt; &lt;/p&gt; &lt;p id=&quot;p_b_follow&quot;&gt;&lt;a href=&quot;javascript:void(0);&quot; onclick=&quot;follow('ca5022e9-4171-4a38-e168-08d4ef52ecb5')&quot;&gt;+加关注&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;!--- 导入js库 ---&gt;&lt;script src=&quot;//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js&quot;&gt;&lt;canvas id=&quot;c_n4&quot; width=&quot;860&quot; height=&quot;958&quot; style=&quot;position: fixed; top: 0px; left: 0px; z-index: -1; opacity: 0.5;&quot;&gt;&lt;/canvas&gt;页首Html代码12345678&lt;!-- 链接过来的 css 样式要放在 首页Html代码 里面 才会生效 --&gt;&lt;link type=&quot;text/css&quot; rel=&quot;stylesheet&quot; href=&quot;http://cdn.bootcss.com/bootstrap/3.3.5/css/bootstrap.min.css&quot;/&gt;&lt;link type=&quot;text/css&quot; rel=&quot;stylesheet&quot; href=&quot;https://files.cnblogs.com/files/Trainoo/trainoo-web.css&quot; /&gt;&lt;link type=&quot;text/css&quot; rel=&quot;stylesheet&quot; href=&quot;https://files.cnblogs.com/files/Trainoo/trainoo-mobile.css&quot; id=&quot;mobile-style&quot; media=&quot;only screen and (max-width: 767px)&quot; /&gt;&lt;a id=&quot;back-to-top&quot; style=&quot;display: inline;&quot; href=&quot;javascript:;&quot;&gt; &lt;i class=&quot;glyphicon glyphicon-arrow-up&quot;&gt;&lt;/i&gt;&lt;/a&gt;页脚Html代码12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;script&gt;$(function(){ changeIndReadCommentStyle(); //changeCatReadCommentStyle(); //返回顶部 $('#back-to-top').click(function(e){ $('html,body').animate({scrollTop:0}, 500) }); //滑稽~ $('#ad_t2').remove(); $('#under_post_news').remove(); $('#under_post_kb').remove(); $('.c_ad_block').remove(); $('.c_ad_block').remove(); $('#blog-calendar').remove(); $('#sidebar_search').remove(); $('title').html($('title').html())});// 修改首页 阅读、评论样式function changeIndReadCommentStyle(){ var count = $('.postDesc').length; var pattern = new RegExp(&quot;阅读(.*?)&lt;a&quot;); for (var i=0; i &lt; count; i++){ var html = &quot;&quot;; var txt = pattern.exec($('.postDesc').eq(i).html()); html += &quot;&lt;span class=\\&quot;glyphicon glyphicon-eye-open\\&quot;&gt;&lt;/span&gt;&quot;; html += &quot; &quot; + txt; $('.postDesc').eq(i).html(html); }}// 修改分类页 阅读、评论样式function changeCatReadCommentStyle(){ var count = $('.entrylistItemPostDesc').length; var pattern1 = new RegExp(&quot;阅读(.*?)&quot;); for (var i=0; i &lt; count; i++){ var html = &quot;&quot;; var txt = pattern1.exec($('.entrylistItemPostDesc').eq(i).html()); html += &quot;&lt;span class=\\&quot;glyphicon glyphicon-eye-open\\&quot;&gt;&lt;/span&gt;&quot;; html += &quot; &quot; + txt + &quot;&lt;\\/a&gt;&quot;; $('.entrylistItemPostDesc').eq(i).html(html); }}&lt;/script&gt;最后点击保存即可！最后，再来个总结总结什么呢？第一次用markdown正式编辑博客内容，所以也踩了很多坑，这里记录一个最大的坑！markdown代码段的标记一般使用的是这个符号：`有些编辑器也可以用:甚至我还百度了说可以用这个的：でも，我在尝试这些之后，发现根本没有办法正常嵌入html代码，html在显示的时候会被转义！所以在尝试N遍之后，终于发现，只需要在贴入的代码前敲两次table缩进一下就好了~~，好吧，再次暴露了我的markdown水平太低。。。最后的最后，我是使用 MarkdownPad2 这个编辑器在本地编辑好了在贴到博客园发布的~","link":"/2017/12/16/about-cnblogs-css/"},{"title":"记Icarus博客主题升级","text":"后知后觉，前几天才发现icarus主题已经更新到3.0版本了。本着能不升级就觉不升级的原则，点进了主题作者的博客看了下升级内容。嗯，真香！虽然没学过react，但是程序员嘛，照着抄还是没什么难度…升级开始！其实在样式上，本博客更新前后的区别并不大，主要更新内容如下：icarus主题从v2升级到v3（这部分主要是主题源码上的升级，v3版本jsx代码看起来比v2的ejs清爽。）新增了黑夜模式主题切换（参考：Icarus 夜间模式支持 3.0 了）新增了友情链接（参考：博客源码分享）模块化了APlayer插件（v2版本时，我是直接把APlayer直接加在Link模块上的，现在独立了）其他细节改动（包括：还原本博客在v2时的一些改动。参考：hexo-theme-amazing）以下自己做的一些小小的改动说明下，博客修改过的主题没有单独抽出来一个库（因为我并不擅长这个，都是在前人的基础上改的）但是在博客备份中可以获取到，仓库下有几个分支，都是以前用过的主题，最新的分支是icarus-v3模块化APlayer插件文件目录结构说明1234567891011121314151617# 新增(修改)了以下文件，文件所在目录如下：# 如果有遗漏，那可能是我真忘记改过什么了...但是聪明的你们，肯定能自己搞定！# 其实有些样式文件没在这里列出来，实在是感觉没必要吧-themes/icarus |-include | |-schema | |-widget | | |-aplayer.json | |-config.json |-layout | |-widget | |-aplayer.jsx |-source | |-music | |-* |-_config.yml |-_config.post.ymlaplayer.jsx1234567891011121314151617181920212223const { Component } = require('inferno');const { cacheComponent } = require('hexo-component-inferno/lib/util/cache');class APlayer extends Component { render() { const {APlayerCssUrl, APlayerJsUrl, musicJsUrl } = this.props; return &lt;div class=\"card widget\"&gt; &lt;link href={APlayerCssUrl}/&gt; &lt;div id=\"aplayer\" style=\"margin: 0 auto;\"/&gt; &lt;script src={APlayerJsUrl}/&gt; &lt;script src={musicJsUrl}/&gt; &lt;/div&gt;; }}module.exports = cacheComponent(APlayer, 'widget.links', props =&gt; { const { helper } = props; return { APlayerCssUrl: helper.url_for('/music/APlayer.min.css'), APlayerJsUrl: helper.url_for('/music/APlayer.min.js'), musicJsUrl: helper.url_for('/music/APlayer_Music.js'), };});aplayer.json | json其实照着其他widget抄就好了123456789101112131415{ \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"$id\": \"/widget/aplayer.json\", \"description\": \"aplayer music\", \"type\": \"object\", \"properties\": { \"type\": { \"type\": \"string\", \"const\": \"aplayer\" } }, \"required\": [ \"type\" ]}_config.yml123456# widget配置新增如下内容：widget: # APlayer music - position: left type: aplayer鼠标点击特效文件目录结构说明123456789101112131415# 目录结构其实跟APlayer差不多，改动思路也一样，这次是加在plugin下面-themes/icarus |-include | |-schema | |-plugin | | |-fireworks.json | |-config.json |-layout | |-plugin | |-fireworks.jsx |-source | |-js | |-anime.min.js | |-fireworks.js |-_config.ymlfireworks.jsx1234567891011121314151617181920212223242526272829const { Component, Fragment } = require('inferno');const { cacheComponent } = require('hexo-component-inferno/lib/util/cache');class FireWorks extends Component { render() { const { animJsUrl, fireworksJsUrl } = this.props; return &lt;Fragment&gt; &lt;canvas className=\"fireworks\" width=\"100%\" height=\"100%\" style=\"position: fixed; left: 0; top: 0; z-index: 99999999; pointer-events: none;\"/&gt; &lt;script src={animJsUrl} defer={true}/&gt; &lt;script src={fireworksJsUrl} defer={true}/&gt; &lt;/Fragment&gt;; }}FireWorks.Cacheable = cacheComponent(FireWorks, 'plugin.fireworks', props =&gt; { const { helper, head } = props; if (head) { return null; } return { animJsUrl: helper.url_for('/js/anime.min.js'), fireworksJsUrl: helper.url_for('/js/fireworks.js') };});module.exports = FireWorks;fireworks.json | 感觉没必要放出来，算了，还是放吧1234567{ \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"$id\": \"/plugin/fireworks.json\", \"description\": \"click to show fireworks\", \"type\": \"boolean\", \"default\": true}_config.yml123# plugins新增如下内容：plugins: fireworks: true关于CND加速之前我的博客都是把一些google-font之类的下载到本地引用的，因为某些原因，这些样式可能加载不出来或者特别慢。v3版的icarus新增了多个cdn支持，可以自由选择cdn，还是很值的点赞的。但是有时候吧，感觉还是慢了些，所以折腾着又把样式下载到了本地。因为icarus好多东西都被抽到了hexo-component-inferno中，更改起来还是挺麻烦的。这里提供个思路：断网，把所有经过cdn的js,css等文件记录下来；然后联网，下载到本地；修改CND.js，引用本地资源source/cdn/cdn.js | 这里只展示了部分内容，并非完整的CDN.js123456789101112131415161718192021222324/** * 1. 修改此js, 替换到 hexo-component-inferno 模块中, 路径：lib/hexo/helper/cdn.js * 2. 提前把cdn加载的 js、css、icon 等文件下载保存到当前目录[theme/icarus/source/cdn/]下 (很麻烦的~~) * 3. 本地引用，_config.yml 中 CDN provider settings 修改成 my_xxx */const PROVIDERS = { LIBRARY: { cdnjs: '[cdnjs]https://cdnjs.cloudflare.com/ajax/libs/${ package }/${ version }/${ filename }', loli: '[cdnjs]https://cdnjs.loli.net/ajax/libs/${ package }/${ version }/${ filename }', jsdelivr: 'https://cdn.jsdelivr.net/npm/${ package }@${ version }/${ filename }', unpkg: 'https://unpkg.com/${ package }@${ version }/${ filename }', my_lib: '/cdn/js/${ filename }' }, FONT: { google: 'https://fonts.googleapis.com/${ type }?family=${ fontname }', loli: 'https://fonts.loli.net/${ type }?family=${ fontname }', my_font: '/cdn/css/css2.css' }, ICON: { loli: 'https://cdnjs.loli.net/ajax/libs/font-awesome/5.12.0/css/all.min.css', fontawesome: 'https://use.fontawesome.com/releases/v5.12.0/css/all.css', my_icon: '/cdn/css/fontawesome.all.css' }};_config.yml12345# CDN provider settingsproviders: cdn: my_lib fontcdn: my_font iconcdn: my_icon后续可能会继续优化博客的加载速度，什么时候优化就不一定了，再会~","link":"/2020/05/31/blog-theme-upgrade/"},{"title":"把博客部署到nginx服务器","text":"假如，你跟我一样使用hexo+github搭建了一个博客然后想把自己的博客部署在自己的服务器上的话那么请往下看此文记录了我一步步部署下来的步骤导语盆友们，如果你还不知到怎么搭建这么一个博客我这里也找了一个搭建博客的教程，供大家参考使用Hexo+Github一步步搭建属于自己的博客（基础）使用Hexo+Github一步步搭建属于自己的博客（进阶）这里，我们假设你已经拥有了自己的小博客那么，请往下看首先，我们进入/usr/local目录下面新建一个文件夹名为nginx12[root@trainoozhou sbin]# cd /usr/local[root@trainoozhou sbin]# mkdir nginx进入nginx目录下，从官网下载nginx安装包(请根据自己的情况安装所需版本)12[root@trainoozhou sbin]# cd nginx[root@trainoozhou sbin]# wget http://nginx.org/download/nginx-1.10.3.tar.gz下载完毕之后，解压并检查配置信息12[root@trainoozhou sbin]# tar -xzvf nginx-1.10.3.tar.gz[root@trainoozhou sbin]# ./configure --prefix=/usr/local/nginx --with-http_stub_status_module --with-http_ssl_moduleps:执行上面的命令时候，可能会出现下面的error1234./configure: error: the HTTP rewrite module requires the PCRE library.You can either disable the module by using --without-http_rewrite_moduleoption, or install the PCRE library into the system, or build the PCRE librarystatically from the source with nginx by using --with-pcre=&lt;path&gt; option.如果上面的error出现了的话，可以看出是缺少PCRE模块，可以通过下面命令安装：12345678910# 安装编译工具及库文件yum -y install make zlib zlib-devel gcc-c++ libtool openssl openssl-devel# 安装PCRE(请根据自己的情况安装所需版本)[root@trainoozhou sbin]# wget http://downloads.sourceforge.net/project/pcre/pcre/8.35/pcre-8.35.tar.gz[root@trainoozhou sbin]# tar zxvf pcre-8.35.tar.gz[root@trainoozhou sbin]# cd pcre-8.35[root@trainoozhou sbin]# ./configure[root@trainoozhou sbin]# make &amp;&amp; make install[root@trainoozhou sbin]# pcre-config --version如果没有出现上面的错误，则执行 make &amp; make install 安装nginx12[root@trainoozhou sbin]# make[root@trainoozhou sbin]# make install安装成功后，可以查看nginx版本1/usr/local/nginx/sbin/nginx -v至此，nginx安装完毕，接下来就是把生成的静态页面文件上传到服务器上我的博客文件结构如下图所示：需要用到ftp工具(比如：SecureFX、XFtp等)把上图所示整个目录结构拷贝到/usr/local/nginx/html/下，操作后目录结构如下：(PS: 如果有自动化部署的方法请告知)1234567891011121314151617[root@trainoozhou sbin]# ll ../htmltotal 5252drwxr-xr-x 3 root root 4096 Jun 23 22:24 2017drwxr-xr-x 6 root root 4096 Jun 23 22:24 2018-rw-r--r-- 1 root root 537 Jun 23 22:14 50x.htmldrwxr-xr-x 4 root root 4096 Jun 23 22:24 archives-rw-r--r-- 1 root root 5652 Jun 23 22:24 content.jsondrwxr-xr-x 2 root root 4096 Jun 23 22:24 fontsdrwxr-xr-x 2 root root 4096 Jun 23 22:24 img-rw-r--r-- 1 root root 142222 Jun 23 22:24 index.html-rw-r--r-- 1 root root 60610 Jun 23 22:24 main.0cf68a.css-rw-r--r-- 1 root root 70642 Jun 23 22:24 main.0cf68a.js-rw-r--r-- 1 root root 106827 Jun 23 22:24 mobile.992cbe.jsdrwxr-xr-x 4 root root 4096 Jun 23 22:24 pagedrwxr-xr-x 2 root root 4096 Jun 23 22:24 picture-rw-r--r-- 1 root root 53399 Jun 23 22:24 slider.e37972.jsdrwxr-xr-x 17 root root 4096 Jun 23 22:24 tags然后启动nginx即可：1234[root@trainoozhou sbin]# pwd/usr/local/nginx/sbin[root@trainoozhou sbin]# ./nginx[root@trainoozhou sbin]#访问服务器地址，效果如下(请忽略直接使用ip访问，穷~)：当然，如果你需要配置端口啥的，请到conf目录下修改配置文件12345678910111213141516171819[root@trainoozhou sbin]# cd ../conf/[root@trainoozhou conf]# lltotal 60-rw-r--r-- 1 root root 1077 Jun 23 22:14 fastcgi.conf-rw-r--r-- 1 root root 1077 Jun 23 22:14 fastcgi.conf.default-rw-r--r-- 1 root root 1007 Jun 23 22:14 fastcgi_params-rw-r--r-- 1 root root 1007 Jun 23 22:14 fastcgi_params.default-rw-r--r-- 1 root root 2837 Jun 23 22:14 koi-utf-rw-r--r-- 1 root root 2223 Jun 23 22:14 koi-win-rw-r--r-- 1 root root 3957 Jun 23 22:14 mime.types-rw-r--r-- 1 root root 3957 Jun 23 22:14 mime.types.default-rw-r--r-- 1 root root 618 Jun 23 23:37 nginx.conf-rw-r--r-- 1 root root 2656 Jun 23 22:14 nginx.conf.default-rw-r--r-- 1 root root 636 Jun 23 22:14 scgi_params-rw-r--r-- 1 root root 636 Jun 23 22:14 scgi_params.default-rw-r--r-- 1 root root 664 Jun 23 22:14 uwsgi_params-rw-r--r-- 1 root root 664 Jun 23 22:14 uwsgi_params.default-rw-r--r-- 1 root root 3610 Jun 23 22:14 win-utf[root@trainoozhou conf]# vim nginx.conf提供一个最简洁的配置参考,如下：123456789101112131415161718192021222324252627#user nobody;worker_processes 1;#pid logs/nginx.pid;events { worker_connections 1024;}http { include mime.types; default_type application/octet-stream; sendfile on; server { listen 80; server_name localhost; charset utf-8; location / { root html; index index.html; } error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } }}","link":"/2018/06/26/deploy-blog-to-nginx/"},{"title":"Docker容器入门-基本命令的使用","text":"目前容器技术使用相当广泛不会或者没有使用过容器感觉都不像是个搞技术的所以，我也就docker相关内容做一个整理只有不断的学习，才能保持自己的竞争力什么是容器？容器是一种轻量级、可移植、自包含的软件打包技术，使应用程序可以在几乎任何地方以相同的方式运行。为什么使用容器？容器使软件具备了超强的可移植能力怎样使用容器？容器常用的基本操作：123456789101112131415docker stop\\start\\restart [container_id\\container_name] // 停止、启动、重启容器docker kill [container_id\\container_name] // 强制停止docker pause\\unpause [container_id\\container_name] // 暂停、取消暂停docker rm [container_id\\container_name] // 删除容器docker rmi [image_id\\image_name] // 删除镜像// 按条件查找容器id, -a 所有 -q 只显示id -f filter过滤docker ps -aq -f status=runningdocker ps -aq -f status=exiteddocker ps -aq -f status=created// 查看容器日志docker logs -f &lt;container&gt;// 进入shelldocker exec -it &lt;container&gt; sh// 进入bashdocker exec -it &lt;container&gt; /bin/bash限制容器内存使用：-m 或 –memory 设置内存的使用限额、–memory-swap 设置内存+swap的使用限额1docker run -m 200M --memory-swap=300M ubuntu限制容器CPU使用：-c 或 –cpu-shares 设置权重、 –cpu 设置工作线程数量1docker run -it -c 1024 progrium/stress --cpu 1限制容器IO的使用：–blkio-weight 设置block IO的优先级1docker run -it --name my_ubuntu --blkio-weight 600 ubuntu创建自定义IP网段的容器网络：1docker network create --driver bridge --subnet 172.22.22.0/24 --gateway 172.22.22.1 my_net启动时给容器指定一个静态ip：只有使用 –subnet 创建的网络才能指定静态ip1docker run -it --network=my_net --ip 172.22.22.22 busybox查看容器网络：1docker network ls共享网络栈：使用 –network=container:web1 指定 jointed 容器为 web1将主机上的目录或者文件挂载到容器：使用 -v:将其 mount 到容器12docker run -d -p 80:80 -v ~/htdocs:/usr/local/apache2/htdocs httpddocker run -d -p 80:80 -v ~/htdocs:/usr/local/apache2/htdocs:ro httpd // ro设置只读权限，容器不能对该文件做修改使用volume container共享容器数据：通过 –volumes-from 使用 vc_data 这个 volume container123451.创建一个vc：docker create --name vc_data -v ~/htdocs:/usr/local/apache2/htdocs -v /other/useful/tools busybox2.共享vc：docker run --name web1 -d -p 80 --volumes-from vc_data httpddocker run --name web2 -d -p 80 --volumes-from vc_data httpddocker删除bind mount：只能由host负责删除docker删除docker managed volume：删除容器时加上 -v 可以删除容器依赖的volume如果删除容易时，没有加-v删除依赖volume，也可以用：docker volume rm如何安装？详情见官方安装文档","link":"/2019/06/22/docker-command/"},{"title":"Dockerfile极简入门与实践","text":"前文中，罗列了docker使用中用到的基本命令此文，将会对怎样使用Dockerfile去创建一个镜像做简单的介绍Dockerfile命令要开始编写Dockerfile，首先要对相关的命令有个清晰的认识下面列出了部分Dockerfile命令的功能以及使用方法，供参考：1. FROMDockerfile的第一条指定必须是FROM，用于指定基础镜像。用法：FROM [image]:[tag]2. MAINTAINER用于指定此Dockerfile维护者信息。用法：MAINTAINER &lt;name&gt; &lt;email&gt;3. ADD复制指定内容到镜像中，指定内容可以是一个相对或绝对路径，也可以是一个url(此时相当于wget)，如果添加的文件是个tar压缩文件，文件在复制的时候会自动解压。用法：ADD &lt;src&gt; &lt;dest&gt;4. COPY与ADD命令用法相同，区别是COPY只能复制本地文件用法：COPY &lt;src&gt; &lt;dest&gt;5. RUN构建镜像时运行指定命令，建议多个命令尽量写在同一个RUN中，用&amp;&amp;分割或使用\\换行。用法：RUN &lt;command&gt;RUN [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;]前者在shell终端上运行，后者使用exec运行。6. CMD容器启动时运行指定命令，每个容器只能执行一条CMD命令，多个CMD命令时，只最后一条被执行。用法：CMD [&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;]CMD [&quot;param1&quot;,&quot;param2&quot;]CMD &lt;command&gt; &lt;param1&gt; &lt;param2&gt;7. ENV指定一个环境变量，可以被RUN,WORKDIR命令使用，并在容器运行时保持。用法:ENV &lt;key&gt; &lt;value&gt;ENV &lt;key1&gt;=&lt;value1&gt; &lt;k2&gt;=&lt;v2&gt; &lt;k3&gt;=&lt;v3&gt; ...8. ENTRYPOINT配置容器启动后执行的命令，并且不可被 docker run 提供的参数覆盖，每个Dockerfile中只能有一个 ENTRYPOINT ，当指定多个时，只有最后一个起效。用法：ENTRYPOINT [“executable”, “param1”, “param2”]ENTRYPOINT &lt;command&gt; &lt;param1&gt; &lt;param2&gt;9. WORKDIR设置工作目录，对RUN,CMD,ENTRYPOINT,COPY,ADD生效。如果不存在则会创建。用法：WORKDIR &lt;path&gt;10. EXPOSE功能为暴漏容器运行时的监听端口给外部用法：EXPOSE &lt;port&gt;Dockerfile实践通读过上面的Dockerfile命令，相信对编写一个Dockerfile有了一个初步的认识接着，我们来通过一个具体的需求，来看一个完整的镜像是怎么通过Dockerfile生成的1. 需求使用32位的jre环境运行一个dubbo服务的jar包2. 编写Dockerfile首先，我们需要一个32位的jre环境，你可以从镜像仓库找一个，但此处，我们选择通过Dockerfile自己创建123456789101112# 指定基础镜像FROM i386/centos:6# 作者信息MAINTAINER trainoo &quot;trainoo@163.com&quot;# 添加jre环境，add会自动解压ADD jre-8u211-linux-i586.tar.gz /opt/docker/java/jre8# 设置java环境变量ENV JAVA_HOME=/opt/docker/java/jre8/jre1.8.0_211 \\ CLASSPATH=$JAVA_HOME/bin \\ PATH=.:$JAVA_HOME/bin:$PATH# 容器启动后执行，显示java版本号，可以查看环境是否安装成功CMD [&quot;java&quot;,&quot;-version&quot;]问：为什么使用 i386/centos:6 作为基础镜像？答：因为32位的jre当然是使用32位的环境运行比较方便如果使用64位的环境运行32位jre也是可以的，但是需要安装如下依赖：RUN yum update &amp;&amp; yum -y install glibc.i686 zlib.i686 libstdc++.i686如果打包的是64位的jre，那么基础镜像可以换成：frolvlad/alpine-glibc问：jre-8u211-linux-i586.tar.gz 这个包从哪下载？答：你可以从官网下载，当然，你看到此文章时，可能网址已经变化。3. 构建如上，我们写好了一个Dockerfile，只需把jre包跟Dockerfile放在同一路径即可开始构建，命令如下：docker build -t jre8-64:second .ps: 此处应该贴32位的运行过程的，但是64位的跟32位没太大区别，所以就这样吧12345678910111213141516171819202122232425262728293031[root@xxx jre8-x32]# lltotal 89060-rw-r--r--. 1 root root 369 Jun 27 18:38 Dockerfile-rw-r--r--. 1 root root 91192891 Jun 26 14:52 jre-8u211-linux-i586.tar.gz[root@xxx jre8-x64]# docker build -t jre8-64:second .Sending build context to Docker daemon 87.86MBStep 1/5 : FROM frolvlad/alpine-glibc:alpine-3.10 ---&gt; 74b43ef19206Step 2/5 : MAINTAINER trainoo &quot;trainoo@163.com&quot; ---&gt; Using cache ---&gt; 1257f5f17f2aStep 3/5 : ADD jre-8u211-linux-x64.tar.gz /opt/docker/java/jre8 ---&gt; Using cache ---&gt; 10692b79be49Step 4/5 : ENV JAVA_HOME=/opt/docker/java/jre8/jre1.8.0_211 CLASSPATH=$JAVA_HOME/bin PATH=.:$JAVA_HOME/bin:$PATH ---&gt; Running in 1710cc8fd3aaRemoving intermediate container 1710cc8fd3aa ---&gt; 5dd2f0ae922cStep 5/5 : CMD [&quot;java&quot;,&quot;-version&quot;] ---&gt; Running in 368238c0940bRemoving intermediate container 368238c0940b ---&gt; e6e9cf729e37Successfully built e6e9cf729e37Successfully tagged jre8-64:second[root@xxx jre8-x64]# docker images -f reference=jre8*REPOSITORY TAG IMAGE ID CREATED SIZEjre8-64 second e6e9cf729e37 53 seconds ago 251MBjre8-32 base 9035f0dcd0ed 20 hours ago 433MBjre8-64 base ce0823b7fdc3 47 hours ago 251MB由上面的构建步骤可以看出，每运行一个命令，都会产生一个临时镜像，所以为了避免产生多余的临时镜像，我们要尽量的把多个相同指令的的构建步骤，写在同一行里。4. 运行项目假设我们把项目打包好了，打包好的jar包为：my-service-1.0.jar。123456789FROM jre8-32:baseMAINTAINER trainoo &quot;trainoo@163.com&quot;COPY ./jar/ /opt/dubbo-server/RUN cd /opt/dubbo-server/ &amp;&amp; mv $(ls | grep jar) app.jarWORKDIR /opt/dubbo-server/CMD [&quot;java&quot;,&quot;-Xms512M&quot;,&quot;-Xmx512M&quot;,&quot;-jar&quot;,&quot;app.jar&quot;]// 为了通用性，这里把jar文件(如果不是springboot项目，还有lib等依赖包)放在jar目录下，COPY时一起复制过去// 同样目的，使用 mv $(ls | grep jar) app.jar 将需要被执行的jar文件统一命名成 app.jar1234567# 构建镜像[root@xxx jre8-x64]# docker build -t myservice:v1 ......此处省略部分.....# 启动容器[root@xxx jre8-x64]# docker run -d --name myservice myservice:v1# 查看容器[root@xxx jre8-x64]# docker ps后续总结事情总是不会这么顺利，中途总是会有一些小插曲，所以下面是可能遇到的问题的解决方案docker 批量删除产生的缓存镜像123456789# 第一种风格docker ps -a | grep &quot;Exited&quot; | awk '{print $1 }'|xargs docker stopdocker ps -a | grep &quot;Exited&quot; | awk '{print $1 }'|xargs docker rmdocker images | grep none | awk '{print $3}' | xargs docker rmi# 第二种风格docker rm $(docker ps -aq -f exited=137)docker rm $(docker ps -aq -f status=exited)docker rmi $(docker images -qa -f reference=*:v1)container 时区跟 host 不一致12345# Dockerfile中添加RUN echo &quot;Asia/Shanghai&quot; &gt; /etc/timezone# 启动时添加：-v /etc/localtime:/etc/localtime:rodocker run -d -v /etc/localtime:/etc/localtime:ro --net mynet --name myservice myservice:v1docker运行项目，日志中文显示???12345# Dockerfile中添加，指定语言环境RUN localedef -i en_US -f UTF-8 en_US.UTF-8ENV LANG en_US.UTF-8 ENV LANGUAGE en_US:en ENV LC_ALL en_US.UTF-8","link":"/2019/06/28/docker-dockerfile/"},{"title":"Docker Machine 学习笔记","text":"仅以此文，记录我学习docker-machine的过程环境：3台cenos7系统的linux虚拟机，分别为 trainoo-1、trainoo-2、trainoo-3目的：在 trainoo-1 安装 docker-machine 环境，然后通过 docker-machine 在trainoo-2\\3 中安装 docker首先在 trainoo-1 上安装 docker-machine 环境步骤不赘述，详情参见官方文档创建machine之前，要保证几台主机之间ssh能够免密登录12# 首先现在几台机器上生成ssh-key，使用 ssh-keygen -t rsa 命令生成# 使用 ssh-copy-id root@192.168.209.102 复制SSH密钥到目标主机，开启无密码SSH登录创建machine，此步骤可能会非常的漫长…123456789101112131415[root@trainoo-1 ~]# docker-machine create --driver generic --generic-ip-address=192.168.209.102 trainoo-2Running pre-create checks...Creating machine...(trainoo-2) No SSH key specified. Assuming an existing key at the default location.Waiting for machine to be running, this may take a few minutes...Detecting operating system of created instance...Waiting for SSH to be available...Detecting the provisioner...Provisioning with centos...Copying certs to the local machine directory...Copying certs to the remote machine...Setting Docker configuration on the remote daemon...Checking connection to Docker...Docker is up and running!To see how to connect your Docker Client to the Docker Engine running on this virtual machine, run: docker-machine env trainoo-2此过程中，也许会遇到下面这个问题：1234567891011121314[root@trainoo-1 ~]# docker-machine create --driver generic --generic-ip-address=192.168.209.103 trainoo-3Running pre-create checks...Creating machine...(trainoo-3) No SSH key specified. Assuming an existing key at the default location.Waiting for machine to be running, this may take a few minutes...Detecting operating system of created instance...Waiting for SSH to be available...Detecting the provisioner...Provisioning with centos...Copying certs to the local machine directory...Copying certs to the remote machine...Setting Docker configuration on the remote daemon...Checking connection to Docker...Error creating machine: Error checking the host: Error checking and/or regenerating the certs: There was an error validating certificates for host &quot;192.168.209.103:2376&quot;: dial tcp 192.168.209.103:2376: connect: no route to host解决办法就是，重要的事情说三遍：记得关闭防火墙！记得关闭防火墙！记得关闭防火墙！或者开放端口(不如关闭防火墙来的利索)。123456789101112[root@trainoo-3 ~]# systemctl stop firewalld[root@trainoo-3 ~]# systemctl status firewalld● firewalld.service - firewalld - dynamic firewall daemon Loaded: loaded (/usr/lib/systemd/system/firewalld.service; enabled; vendor preset: enabled) Active: inactive (dead) since Sun 2019-07-07 08:03:50 CST; 5s ago Docs: man:firewalld(1) Process: 675 ExecStart=/usr/sbin/firewalld --nofork --nopid $FIREWALLD_ARGS (code=exited, status=0/SUCCESS) Main PID: 675 (code=exited, status=0/SUCCESS)[root@trainoo-3 ~]# systemctl disable firewalldRemoved symlink /etc/systemd/system/multi-user.target.wants/firewalld.service.Removed symlink /etc/systemd/system/dbus-org.fedoraproject.FirewallD1.service.最后，查看machine是否安装成功1234[root@trainoo-1 ~]# docker-machine lsNAME ACTIVE DRIVER STATE URL SWARM DOCKER ERRORStrainoo-2 - generic Running tcp://192.168.209.102:2376 v18.09.7 trainoo-3 - generic Running tcp://192.168.209.103:2376 v18.09.7查看 machine 的环境变量1234567[root@trainoo-1 ~]# docker-machine env trainoo-2export DOCKER_TLS_VERIFY=&quot;1&quot;export DOCKER_HOST=&quot;tcp://192.168.209.102:2376&quot;export DOCKER_CERT_PATH=&quot;/root/.docker/machine/machines/trainoo-2&quot;export DOCKER_MACHINE_NAME=&quot;trainoo-2&quot;# Run this command to configure your shell: # eval $(docker-machine env trainoo-2)尝试连接到 trainoo-2 主机12345678910111213141516171819202122[root@trainoo-1 ~]# eval $(docker-machine env trainoo-2)[root@trainoo-1 ~ [trainoo-2]]# # 题外话，此处显示 [trainoo-2] 表示连接成功# 之所以会显示是因为安装了docker-machine的bash脚本# 安装方法如下，执行一下shell命令：base=https://raw.githubusercontent.com/docker/machine/v0.14.0for i in docker-machine-prompt.bash docker-machine-wrapper.bash docker-machine.bashdo sudo wget &quot;$base/contrib/completion/bash/${i}&quot; -P /etc/bash_completion.ddone# 之后在 ~/.bashrc 中添加如下内容：source /etc/bash_completion.d/docker-machine-wrapper.bashsource /etc/bash_completion.d/docker-machine-prompt.bashsource /etc/bash_completion.d/docker-machine.bashPS1='[\\u@\\h \\W$(__docker_machine_ps1)]\\$ '# 执行 source ~/.bashrc 使之生效# 注意，此时执行的 docker 命令就是在 trainoo-2 主机上执行的# 需要退出的话，重启shell终端至此，所有主机都安装好了 docker，你可以 docker 的进行统一管理了12345678# 批量更新 machine 上面的 docker 版本：docker-machine upgrade trainoo-2 trainoo-3# 在不同 machine 之间拷贝文件：docker-machine scp trainoo-2:/path trainoo-3:/path# 关于 stop/start/restart 命令：# 这几个命令都是对host生效的，而不是针对host上面的docker daemon。","link":"/2019/07/07/docker-machine/"},{"title":"晚安，二零一七","text":"即将过去的2017像猫你看着它甜美温柔地靠近你在你打盹的那一瞬间这货就鬼鬼祟祟地溜了留下一脸懵逼的你咦？发生什么了？2017年并没有太多值得记忆的事思来想去可能也就3件事对我来说值得纪念壹7月份换了一份工作一份到现在来说也不算是太满意的工作但对工作（也可以说是生活中的各种事吧）这件事来说从来就没有满意一说人的天性如此，对任何事都不会轻易满足好在工作也算是轻松互联网这个行业的码农没有加过一次班也算是很少见的了也该学会满足了貳追过一个女孩儿10月份后却渐渐少了联系你若是问我为什么会变成这样我也很无奈，程序员注定找不到女朋友吗？苦笑，暂时将其归咎为异地恋吧多年后，我也可以这么感慨：那些年，我也追过一个女孩叁农村房屋改建初中时代就已经对这个印象深刻毕竟，如果追究下去在我出生的前一年农村房屋改建已经开始萌芽“历史遗留问题”在此暂且不表我所关心的无非就是家里老房子拆了我该住哪的问题终于在2017年的11月份，我等来了这个答案废话说了这么多总之，明年要为盖房钱愁上好久好久了生活不易，如今开始深有体会2018年过了今晚，就到了2018年需要回顾过去，展望未来?不存在的..该怎么过还是怎么过当然，还是要让每一天都过的精彩~结语晚安，2017~你好，2018!PS： 今天发生了一些小插曲，本来打算约上去年还在一起嗨皮的小伙伴们出来聚聚，但响应的人缺寥寥无几。是的，我们长大了，都在为了各自的生活奋斗着，以后能聚在一起的时间估计也少有了。好好珍惜身边还关心牵挂着自己的人吧。","link":"/2017/12/31/good-night-2017/"},{"title":"浏览器野史","text":"闲来无事本准备改一改博客的样式但是由于有些博客实在是吸引人于是就瞧一瞧吧看完《浏览器野史 UserAgent列传》在感慨作者文笔幽默风趣的同时也在感叹原来浏览器也有这么好玩的一段历史。如果你也有兴趣一睹浏览器兴衰史那你不妨也去看看以下是原文章链接：《浏览器野史 UserAgent列传（上）》《浏览器野史 UserAgent列传（下）》此文作者也是我这个博客主题的开发者，同时在此感谢Litten大神","link":"/2017/12/28/history-of-browser-useragent/"},{"title":"晚安，二零一八","text":"时间滴答滴答就消逝了…犹记得一年前的今天同样是一个人坐在出租屋里同样是面对着电脑同样的敲击着键盘，感慨着一年过的真快晚上炒了一个自己爱吃的菜端着碗，坐在电脑面前看着综艺感觉自己过上了退休老人的生活[手动捂脸]哦，不我就一宅男，这就是宅男正常的生活2018，工作上还算顺利虽然上半年发生了些不愉快的事但是目前来说，工作一切顺利期待明年更好2018，依旧单身还记得去年过年回家一群亲戚朋友就开始问：有没有女朋友啊？诸如此类的问题母上大人也说：虽然你年纪还不算大，但是遇到合适的，你也应该找一个了但是这一年下来，确实没有找个女朋友的想法也许是想着一个人过也挺好，也许是还没遇见那个她吧2018，实现了一个小目标年初，家里的新房子开始动工在我的远程指挥，爹妈的辛苦劳动下（其实我啥也没干..就十一回去搬了两块砖）总算是盖好了基本的框架，感谢爹妈！2019，我还有小目标工作顺利，挣钱养家其次，家里的装修搞好还有，那个她，你在哪呢？","link":"/2018/12/31/good-night-2018/"},{"title":"Hello World","text":"2017年12月搭建好了一个小博客拥有了一片属于自己的领地年末将至虽才刚刚起航却愿能在未来的日子里能驶向一片属于我的星辰大海几乎所有学程序的在学习一门新语言的时候第一个学的一定是打印输出：Hello World所以此时我也要来一句：Hello World你好 世界 ~晚安 世界 ~","link":"/2017/12/14/hello-world/"},{"title":"记一次dubbo问题的排查过程","text":"项目上遇到了一个问题排查了相当长的时间，终于在同事的帮助下解决在此记录下排查过程，希望以后不会遇到此类问题了先介绍项目环境和背景原项目：dubbo-2.5.3, 未使用fst序列化升级到：dubbo-2.8.4, 使用fst序列化第一节同事在赶一个项目，由于时间紧迫，我也就一起参与了进去一切都有条不紊的进行着：gitlab获取代码、编译、运行接着，dubbo服务调用失败（同事那边可以运行成功）……部分错误日志如下（点击查看完整错误日志）：123456789101112....前面省略...Caused by: java.lang.NullPointerException: Class is null at de.ruedigermoeller.serialization.FSTClazzInfoRegistry.getCLInfo(FSTClazzInfoRegistry.java:127) at de.ruedigermoeller.serialization.FSTObjectInput.getClazzInfo(FSTObjectInput.java:299) at de.ruedigermoeller.serialization.FSTObjectInput.readObjectWithHeader(FSTObjectInput.java:249) at de.ruedigermoeller.serialization.FSTObjectInput.readObjectInternal(FSTObjectInput.java:230) at de.ruedigermoeller.serialization.FSTObjectInput$2.readObjectOverride(FSTObjectInput.java:1131) at java.io.ObjectInputStream.readObject(ObjectInputStream.java:364) at de.ruedigermoeller.serialization.FSTObjectInput$MyObjectStream.readObjectOverride(FSTObjectInput.java:1437) at java.io.ObjectInputStream.readObject(ObjectInputStream.java:364) at java.util.ArrayList.readObject(ArrayList.java:771) ... 39 more此处问题是fst类找不到(插一句：fst是序列化用的库，因为我们用到了PageList做分页，如果没有fst在序列化时不能序列化List，分页就会失败)查看maven依赖树(mvn dependency:tree)发现包是存在的，并且类也是有的经过前辈们的指点，于是对比一下双方打的包有什么区别使用工具比较了一下，发现文件个数都是对的上的当然，这里不能单单只比较文件个数，还要对比文件大小最重要的还是要对比引入的jar版本是否一致（尤其关心内部打的jar包，因为版本号可能都是1.0.0啥的，第三方包因为带版本很容易看出来）最后，排查的结果是，双方引用的一个xx-api.jar不一致导致的问题也就是启动本地服务，跟服务器部署的服务所使用的api版本不一致（服务器上是之前部署的，没有及时更新，而我本地是用的最新的代码mvn install的）于是，把服务器上的api替换掉我本地的api,dubbo服务成功调用第二节虽然是成功的调用了dubbo的服务，但是我们是不太希望降版本实现的所以我接着就把测试服务器上dubbo服务依赖的xx-api.jar版本升级成跟我本地一致也就是把服务器上的dubbo服务重新打包部署了一遍然后：启动-OK，调用-超时心累，继续排查尝试使用telnet连接dubbo并调用成功123456789101112131415161718192021222324252627282930Type `help' to learn how to use Xshell prompt.[D:\\~]$ telnet 123.123.456.46 20937Connecting to 123.123.456.46 20937...Connection established.To escape to local shell, press 'Ctrl+Alt+]'.dubbo&gt;helpPlease input &quot;help [command]&quot; show detail. log level - Change log level or show log pwd - Print working default service. trace [service] [method] [times] - Trace the service. clear [lines] - Clear screen. exit - Exit the telnet. help [command] - Show help. ls [-l] [service] - List services and methods. invoke [service.]method(args) - Invoke the service method. ps [-l] [port] - Print server ports and connections. cd [service] - Change default service. status [-l] - Show status.dubbo&gt;lscom.xxx.SaleStatisticsServiceFacadecom.xxx.OrderServiceFacadecom.xxx.OrderQryServiceFacadedubbo&gt;invoke com.xxx.OrderQryServiceFacade.getOrder(&quot;1&quot;){&quot;content&quot;:null,&quot;resCode&quot;:&quot;0&quot;,&quot;resMsg&quot;:&quot;操作成功&quot;}elapsed: 7 ms.dubbo&gt;为什么使用telnet本地调用能成功，但是在我的开发电脑上远程调用就超时呢？？又是经过指点：可能本地跟远程调用使用的序列化方式不一样，可能还是fst的问题去标准输出里面查看dubbo服务的启动日志，找到这么一段:12345678910111213141516171819202018-09-14 20:23:05.462 [DUBBO] Decode rpc invocation failed: /usr/java/jdk-7u67-i586/jre/lib/i386/xawt/libmawt.so: libXext.so.6: cannot open shared object file: No such file or directory, dubbo version: 2.8.4, current host: 127.0.0.1java.lang.UnsatisfiedLinkError: /usr/java/jdk-7u67-i586/jre/lib/i386/xawt/libmawt.so: libXext.so.6: cannot open shared object file: No such file or directory at java.lang.ClassLoader$NativeLibrary.load(Native Method) at java.lang.ClassLoader.loadLibrary1(ClassLoader.java:1965) at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1890) at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1851) at java.lang.Runtime.load0(Runtime.java:795) at java.lang.System.load(System.java:1062) ...省略部分...2018-09-14 20:23:05.466 [DUBBO] Skip input stream 246, dubbo version: 2.8.4, current host: 127.0.0.12018-09-14 20:23:05.478 [DUBBO] Fail to encode response: Response [id=167458, version=2.0.0, status=40, event=false, error=Fail to decode request due to: RpcInvocation [methodName=null, parameterTypes=null, arguments=null, attachments={input=262}], result=null], send bad_response info instead, cause: Could not initialize class com.alibaba.dubbo.common.serialize.support.fst.FstFactory, dubbo version: 2.8.4, current host: 127.0.0.1java.lang.NoClassDefFoundError: Could not initialize class com.alibaba.dubbo.common.serialize.support.fst.FstFactory at com.alibaba.dubbo.common.serialize.support.fst.FstObjectOutput.&lt;init&gt;(FstObjectOutput.java:32) at com.alibaba.dubbo.common.serialize.support.fst.FstSerialization.serialize(FstSerialization.java:41) at com.alibaba.dubbo.remoting.exchange.codec.ExchangeCodec.encodeResponse(ExchangeCodec.java:286) at com.alibaba.dubbo.remoting.exchange.codec.ExchangeCodec.encode(ExchangeCodec.java:78) at com.alibaba.dubbo.rpc.protocol.dubbo.DubboCountCodec.encode(DubboCountCodec.java:39) ...省略部分...果然，还是fst导致的，但是源头是找不到文件/usr/java/jdk-7u67-i586/jre/lib/i386/xawt/libmawt.so: libXext.so.6那就继续查看文件目录，是不是真的没有这个文件12345[root@wifiA ~]# cd /usr/java/jdk-7u67-i586/jre/lib/i386/xawt[root@wifiA xawt]# lltotal 372-rwxr-xr-x 1 uucp 143 380612 Jul 26 2014 libmawt.so[root@wifiA xawt]#好吧，文件存在，问题又出现在哪呢？再仔细看jdk-7u67-i586,32位jdk？？？看看dubbo启动脚本使用的jdk版本是不是32位的123456789101112131415161718192021222324252627282930313233343536373839404142// 默认的jdk版本[root@wifiA bin]# java -versionjava version &quot;1.7.0_67&quot;Java(TM) SE Runtime Environment (build 1.7.0_67-b01)Java HotSpot(TM) Server VM (build 24.65-b04, mixed mode)// 我们还有个64位的jdk[root@wifiA bin]# /usr/java/jdk1.7.0_71/bin/java -versionjava version &quot;1.7.0_71&quot;Java(TM) SE Runtime Environment (build 1.7.0_71-b14)Java HotSpot(TM) 64-Bit Server VM (build 24.71-b01, mixed mode)// dubbo启动脚本[root@wifiA bin]# cat start.sh #!/bin/shset -mbase_path='/opt/snp/snp-order-service'project_name='snp-order-service'project_version='1.0.0'if [ ! -f &quot;${base_path}/logs/${project_name}.pid&quot; ];then echo 'dubbo进程PID文件不存在,请重新运行命令！' touch ${base_path}/logs/${project_name}.pid exit 0fiPID=$(cat ${base_path}/logs/${project_name}.pid)if [ -n &quot;$PID&quot; ];then echo 'dubbo服务已启动，请先停止' exit 0fijava -Xms512M -Xmx512M -jar ${base_path}/jar/${project_name}-${project_version}.jar &gt;&gt; ${base_path}/logs/${project_name}.log 2&gt;&amp;1 &amp; echo &quot;启动进程的PID为$!&quot;if [ $? -eq 0 ];then echo $! &gt; ${base_path}/logs/${project_name}.pid echo 'jar包运行成功！'else echo &quot;jar包运行不成功!&quot;fi果然，启动脚本使用的是java-32位启动的，换成64位jdk重启服务，终于搞定1/usr/java/jdk1.7.0_71/bin/java -Xms512M -Xmx512M -jar ${base_path}/jar/${project_name}-${project_version}.jar &gt;&gt; ${base_path}/logs/${project_name}.log 2&gt;&amp;1 &amp;后记讲真，在工作中，我最怕遇到的问题不是代码的问题恰恰就是这种，在别人的环境下可以运行，但是在自己的环境里就运行不了的这种奇怪问题如果真是碰到了这种问题，就由不得你要脑壳疼一阵子了…上面的排查过程，虽然此处记下了各种问题的原因，以及解决方案但是，在这个寻找问题原因的过程中的艰辛，不经历过的，估计是不能体会的虽然记录下了此问题，但真心希望以后在也别遇到了就这样吧，脑壳现在还疼着呢…","link":"/2018/09/14/how-i-solve-a-dubbo-problem/"},{"title":"ELK安装以及配置","text":"ELK是Elasticsearch、Logstash、Kibana的简称，这三者是核心套件，但并非全部。关于这三者的具体介绍可以移步官方网站查看详情，此文介绍如何安装ELK一、部署环境CentOS-6.xJava-1.8ELK-7.4.0系统部署如下图二、ELK安装 - 使用yum方式ps:此方式安装请使用centos6以上版本下载并安装公共签名密钥1rpm --import https://artifacts.elastic.co/GPG-KEY-elasticsearch在/etc/yum.repos.d/目录新建elastic.repo文件并添加以下内容12345678[elastic-7.x]name=Elastic repository for 7.x packagesbaseurl=https://artifacts.elastic.co/packages/7.x/yumgpgcheck=1gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearchenabled=1autorefresh=1type=rpm-md执行yum命令，安装elasticsearch、logstash、kibana、filebeat1234sudo yum install elasticsearchsudo yum install logstashsudo yum install kibanasudo yum install filebeat其他安装方式（详见官方文档）Elasticsearch官方安装文档Logstash官方安装文档Kibana官方安装文档Filebeat官方安装文档三、安装 kafka（QuickStart）下载安装12345678910# 版本更新换代，最新版本见官网wget http://mirrors.tuna.tsinghua.edu.cn/apache/kafka/2.3.0/kafka_2.12-2.3.0.tgz# 解压tar -xzf kafka_2.12-2.3.0.tgzcd kafka_2.12-2.3.0# 配置[vim config/server.properties]（该配置不能是0.0.0.0或127.0.0.1或localhost,需为具体地址）############################# Socket Server Settings #############################listeners=PLAINTEXT://192.168.0.102:9092启动、停止服务12345678910111213# kafka需要依赖Zookeeper，所以必须先启动一个zookeeper服务。# 如果你没有安装ZK，那么kafka自带了一个，你只需要执行以下命令启动一个ZK实例bin/zookeeper-server-start.sh config/zookeeper.properties# 如果你有自己的ZK的话，那么你需要修改`config/server.properties`文件中如下内容############################# Zookeeper #############################zookeeper.connect=localhost:2181# 以下命令守护进程方式启动kafkabin/kafka-server-start.sh -daemon config/server.properties# 停止kafkabin/kafka-server-stop.sh版本(kafka_2.12-2.3.0)需要jdk-1.8，所以如果本地jdk版本小于1.8，启动会出现如下错误1Unsupported major.minor version 52.0如果你不想（能）更换默认的jdk版本，那么你只需要下载另一个jdk，然后修改启动配置文件此时要修改文件bin/kafka-run-class.sh并添加上JAVA_HOME=your_path_here1234567# Which java to useif [ -z &quot;$JAVA_HOME&quot; ]; then JAVA=&quot;java&quot;else JAVA_HOME=&quot;/usr/local/java/jdk1.8.0_191-x64&quot; #此处换成另一个jdk路径 JAVA=&quot;$JAVA_HOME/bin/java&quot;fi四、配置\\启动 Filebeat配置。众所周知，filebeat需要配置一个input跟output，编辑文件/etc/filebeat/filebeat.yml123456789101112131415161718192021#=========================== Filebeat inputs =============================filebeat.inputs:- type: log enabled: true paths: - /usr/logs/test/*.log fields: topic: test-log - type: log enabled: true paths: - /opt/tomcat/logs/catalina.out fields: topic: tomcat-log#================================ Outputs =====================================#----------------------------- Kafka output --------------------------------output.kafka: hosts: [&quot;192.168.0.102:9092&quot;] # kafka listeners address topic: '%{[fields][topic]}'启动1service filebeat start五、配置\\启动 Logstash众所周知，配置logstash是最麻烦的，我们先说它的启动方式。1234567891011121314151617181920# 虽然同样是用yum方式安装的，但是logstash并没有被安装成一个服务。# 我目前也不知道为什么，可能是因为它的启动方式有关？# 所以这里我只能到它的安装目录去启动cd /usr/share/logstash# Logstash启动方式有两种，个人建议使用B方式，把不同的日志处理放在不同配置里# A. 单文件启动方式bin/logstash -f /etc/logstash/conf.d/logstash.conf --path.settings /etc/logstash/# B. 多配置文件的启动bin/logstash -f /etc/logstash/conf.d/ --path.settings /etc/logstash/# logstash的停止没有提供相关的命令，目前发现只能 kill -9# 所以logstash配置文件自动加载这个功能我觉得还是开启比较方便，省了很多事vim /etc/logstash/logstash.yml# 如下配置，配置文件就会每隔5秒重新加载，这样修改了配置文件就不用重启logstash了# ------------ Pipeline Configuration Settings --------------config.reload.automatic: trueconfig.reload.interval: 5s配置，同样logstash也是有input跟output的配置项，同时还有个filter用来过滤日志123456789101112131415161718192021222324252627282930313233343536373839404142# 新建一个配置文件，如 test-log.conf 用来处理 filebeat 中的 test-logvim /etc/logstash/conf.d/test-log.conf# test-log.conf 中配置内容如下：input { kafka { bootstrap_servers =&gt; &quot;192.168.0.102:9092&quot; client_id =&gt; &quot;logstash-test-log&quot; topics =&gt; [&quot;test-log&quot;] type =&gt; &quot;test-log&quot; }}filter { if [type] == &quot;test-log&quot; { grok { match =&gt; {&quot;message&quot; =&gt; &quot;\\&quot;message\\&quot;:\\&quot;(?&lt;message&gt;.*?[^\\\\])\\&quot;&quot;} overwrite =&gt; [&quot;message&quot;] } grok { match =&gt; [&quot;message&quot;, &quot;%{TIMESTAMP_ISO8601:logdate}&quot;] } date { match =&gt; [&quot;logdate&quot;, &quot;ISO8601&quot;] target =&gt; &quot;@timestamp&quot; } mutate { remove_field =&gt; [&quot;@version&quot;, &quot;logdate&quot;] } }}output { if [type] == &quot;test-log&quot; { elasticsearch { hosts =&gt; [&quot;http://localhost:9200&quot;] index =&gt; &quot;test-log-%{+YYYY.MM.dd}&quot; #user =&gt; &quot;${ES_USER}&quot; #password =&gt; &quot;${ES_PWD}&quot; } }}同理，可以创建tomcat-log.conf来处理tomcat的日志信息使用if [type] == &quot;test-log&quot; 可以很好的区分不同的日志，针对不同的日志使用不同的处理方式，或输出到不同的index里Logstash最佳实践六、启动 Elasticsearch1service elasticsearch start七、配置\\启动 Kibana配置123456789vim /etc/kibana/kibana.yml# 配置kibana的访问地址跟端口号，以及elasticsearch的访问地址server.port: 5601server.host: 0.0.0.0elasticsearch.hosts: [&quot;http://localhost:9200&quot;]# 可选配置，kibana日志输出#logging.dest: /tmp/kibana.log启动1service kibana start八、如何使用日志处理工具访问 Kibana1http://localhost:5601创建 Index Pattern1访问kibana &gt;&gt;&gt; Management &gt;&gt;&gt; Index Patterns &gt;&gt;&gt; Create Index Pattern查询日志1访问kibana &gt;&gt;&gt; Discover &gt;&gt;&gt; Search","link":"/2019/10/25/how-to-install-elk/"},{"title":"CentOS6.10下安装mysql-5.7.24","text":"最近，公司购买了台测试服务器需要在上面安装许多项目管理软件以及开发部署工具所以就顺便整理一下相关的安装文档下面，开始安装MySQL卸载原有mysql因为mysql数据库在Linux上实在是太流行了所以目前下载的主流Linux系统版本基本上都集成了mysql数据库在里面我们可以通过如下命令来查看我们的操作系统上是否已经安装了mysql数据库1rpm -qa | grep mysql // 这个命令就会查看该操作系统上是否已经安装了mysql数据库有的话，我们就通过 rpm -e 命令 或者 rpm -e –nodeps 命令来卸载掉1234// 普通删除模式 rpm -e mysql-libs-5.1.73-3.el6_5.x86_64 // 强力删除模式，如果使用上面命令删除时，提示有依赖的其它文件，则用该命令rpm -e --nodeps mysql-libs-5.1.73-3.el6_5.x86_64安装Mysql首先，我们可以使用yum命令来安装，参考资料官方安装文档：123456789101112131415方式1（不建议使用）：yum install -y mysql-server mysql mysql-devel方式2（建议使用此方法）：wget http://dev.mysql.com/get/mysql57-community-release-el6-8.noarch.rpm //从官网获取yum源yum -y install mysql57-community-release-el6-8.noarch.rpm //安装yum源yum -y install mysql-community-server //安装mysql服务注意：因为安装了Yum Repository，以后每次yum操作都会自动更新，需要把这个卸载掉yum -y remove mysql57-community-release-el6-8.noarch## 方式3：2019-12-28更新，方式2链接好像访问不了啦wget http://repo.mysql.com/mysql57-community-release-el7-8.noarch.rpmrpm -ivh mysql57-community-release-el7-8.noarch.rpmyum install mysql-server -y其次，我们还可以使用离线安装的方式安装mysql12345678910111213141516171819// 使用wget命令从mysql官网下载离线包(地址可能不一定是下面这个，请自行更改)wget https://cdn.mysql.com//Downloads/MySQL-5.7/mysql-5.7.24-1.el6.x86_64.rpm-bundle.tar// 解压tar -xvf mysql-5.7.24-1.el6.x86_64.rpm-bundle.tar// 安装工具包以及兼容性相关包rpm -ivh mysql-community-common-5.7.24-1.el6.x86_64.rpmrpm -ivh mysql-community-libs-5.7.24-1.el6.x86_64.rpmrpm -ivh mysql-community-libs-compat-5.7.24-1.el6.x86_64.rpm// 安装mysql服务端rpm -ivh mysql-community-server-5.7.24-1.el6.x86_64.rpm// 安装mysql客户端rpm -ivh mysql-community-client-5.7.24-1.el6.x86_64.rpm// 启动mysqlservice mysqld start至此，mysql安装完毕配置mysqlmysql安装完毕之后，还需要做一些基本配置，如下：123456789101112131415161718192021222324// 创建配置文件cp /usr/share/mysql/my-default.cnf /etc/my.cnf// 修改配置文件/etc/my.cnf，最后一行加上lower_case_table_names=1 #表名不区分大小写// 由于mysql5.7有弱密码限制，可以在配置文件中加上下面内容，关闭限制// ---方法1[mysqld]validate_password=off// ---方法2set global validate_password_length=1;set global validate_password_policy=0;// 查看root用户初始密码并修改root密码grep 'temporary password' /data/mysql/error.log set password = password('your_password');// 使用yum安装的目录有点变化grep 'temporary password' /var/log/mysqld.logalter user 'root'@'localhost' identified by 'AAbb123@#$';// 创建用户并授权grant all on *.* to name@'%' identified by &quot;password&quot; with grant option;flush privileges;编码格式以及其他查看字符集用 show variables like 'character%';查看数据库支持的字符集123show character set; 或者：show char set;最简单的完美修改方法，修改mysql的 /etc/my.cnf 文件中的字符集键值123// 在[mysqld]字段里加入character-set-server=utf8，如下： [mysqld] character-set-server=utf8查看MySQL当前状态：status修改character_set_connection、character_set_client、character_set_results三值12345set names utf8;相当于：SET character_set_client = charset_name; SET character_set_results = charset_name; SET character_set_connection = charset_name;查看数据库表的字符集设置：12show full columns from tablename;show create table [表名];查看数据库编码：show create database [库名];创建时指定字符集：1234CREATE DATABASE [库名] DEFAULT CHARACTER SET utf8;如果不指定默认的字符集，则系统会根据character_set_database的值进行设置CREATE TABLE [库名].[表名] (id VARCHAR(20) NOT NULL,name VARCHAR(20) ) ENGINE=InnoDB DEFAULT CHARSET=utf8;CREATE TABLE [库名].[表名] (id varchar(20) NOT NULL,name varchar(20) CHARACTER SET utf8 );修改字符集：123ALTER DATABASE [库名] CHARACTER SET [字符集];ALTER TABLE [表名] CHARACTER SET [字符集];ALTER TABLE [表名] MODIFY [列名] VARCHAR(5) CHARACTER SET [字符集];其他：12345// mysql可以有：select 1;// 这样的语法，而且不会报错，等同于：select 1 from dual;// mysql里面也有虚拟表dual，但是select时不写也行","link":"/2018/11/18/how-to-install-mysql-on-centos/"},{"title":"如何在Linux下优雅的查询日志","text":"做为一名合格的Java后台开发经常需要查询线上的日志，定位线上问题所以熟练掌握日志查询的命令可以使你更加迅速的定位错误日志位置，及时解决问题在此，我将介绍几个自己工作中经常使用到的日志查询命令大家一起学习讨论，让我们都能更优雅的操作日志假设你有一个日志文件demo.log，里面的内容如下所示，我们将使用这个文件，来演示如何优雅的查询日志文件、定位文件内容。12345678910line1 123456 aaline2 123456 bbline3 123456 ccline4 123456 ddline5 654321 aaline6 654321 bbline7 12line8 34line9 56line0 78tail 命令用于输出文件中的尾部内容，实际应用如下：123456789// 显示文件倒数2行数据，并实时刷新新日志tail -2f demo.log // 执行效果如下：line9 56line0 78// 如果你需要停止，按Ctrl+C退出// 假如查看的日志，实时刷新的日志量非常多的话，慎用!cat 命令命令用于连接文件并打印到标准输出设备上12345678910111213141516// 显示文件全部内容cat demo.log // 执行结果：line1 123456 aaline2 123456 bbline3 123456 ccline4 123456 ddline5 654321 aaline6 654321 bbline7 12line8 34line9 56line0 78// 由于会显示整个文件的内容，所以如果文件大的话，慎用！more 命令类似cat，不过会以一页一页的形式显示，按空白键space就往下一页显示，按b键就会往回一页显示1234567more demo.log// 执行结果(文件内容少的话，会直接显示全部，效果跟cat一样)：line1 123456 aaline2 123456 bbline3 123456 cc--More--(15%)less 命令less与more类似,但使用less可以随意浏览文件(使用键盘上的上下箭头),而且less在查看之前不会加载整个文件1234567891011121314less demo.log// 执行结果(文件内容少的话，会直接显示全部，效果如下)：line1 123456 aaline2 123456 bbline3 123456 ccline4 123456 ddline5 654321 aaline6 654321 bbline7 12line8 34line9 56line0 78demo.log (END)grep 命令grep指令用于查找内容包含指定的范本样式的文件，如果发现某文件的内容符合所指定的范本样式，grep指令会把含有范本样式的那一列显示出来12345678// 查询包含关键字`123456`的日志内容grep &quot;123456&quot; demo.log// 执行结果line1 123456 aaline2 123456 bbline3 123456 ccline4 123456 dd12345// 查询包含关键字`123456`且包含`aa`的日志内容grep &quot;123456&quot; demo.log | grep &quot;aa&quot;// 执行结果line1 123456 aa123456789101112// 查询不包含`aa`的日志内容grep -v &quot;aa&quot; demo.log// 执行结果line2 123456 bbline3 123456 ccline4 123456 ddline6 654321 bbline7 12line8 34line9 56line0 781234567// 查询包含关键字`123456`但不包含`aa`的日志内容grep &quot;123456&quot; demo.log | grep -v &quot;aa&quot;// 执行结果line2 123456 bbline3 123456 ccline4 123456 dd1234567891011// 查询包含关键字`123456`或`aa`的日志内容grep &quot;123456\\|aa&quot; demo.log或者grep -E &quot;123456|aa&quot; demo.log// 执行结果line1 123456 aaline2 123456 bbline3 123456 ccline4 123456 ddline5 654321 aa总结当你通过grep查找关键字，但是还是有非常多匹配的结果时，可以组合前面的less或more实现分页显示，示例如下:12345grep &quot;123456&quot; demo.log | lessgrep &quot;123456&quot; demo.log | moregrep &quot;123456\\|aa&quot; demo.log | lessgrep &quot;123456&quot; demo.log | grep -v &quot;aa&quot; | less通过以上介绍的几个命令，相信应该足够应付大部分的查找日志的场景。好了，剩下的就是勤加练习了。当然，如果你有更好的方式可以更加优雅的查询日志，也希望你能与我一起分享2018-09-05补充：当使用less命令查看日志时，还可以对关键字进行查找。命令如下：1234567// 使用斜杠（/）加关键字的形式，向后查找关键字，如查找关键字：123456/123456 // 使用问号（?）加关键字的形式，向前查找关键字，如查找关键字：line3?line3// PS：跳转到后一个关键字快捷键: N; 跳转到前一个关键字：shift + N关于cat命令，还有一个与之类似但写法相反的命令：tac。写法就是cat反过来写功能也是相反的，是从后往前显示内容。示例如下：12345678910111213tac demo.log// 执行结果：line0 78line9 56line8 34line7 12line6 654321 bbline5 654321 aaline4 123456 ddline3 123456 ccline2 123456 bbline1 123456 aa","link":"/2018/06/23/how-to-search-log-in-linux/"},{"title":"五一湘西之旅[图集]","text":"世界这么大，我想去看看！5月1号[天问台、玻璃栈道、矮寨大桥、苗寨] 5月2号[凤凰] 5月3号[奇梁洞]","link":"/2019/05/04/international-workers-day-travel/"},{"title":"JVM及Java监控原理与实践","text":"简介主要是介绍一下对运行Java程序的一些跟踪，以及对JVM内存等方面进行运维的一些方法。反解析class文件的工具使用一般使用jd-gui工具进行反编译class文件有些jd-gui无法反编译的class，可以使用luyten工具进行反编译Java进程分析命令介绍JPS用于获取所有的JVM进程信息，类似于linux的ps命令12345678//输出进程号与执行的主类名（jar包名）jps -l 结果如下：3035220708 sun.tools.jps.Jps6876 mtex-config-0.0.1-SNAPSHOT.jarjstat用于监控java进程内部各类运行状态信息的工具，可以监控本地或远程虚拟机类装载、内存、垃圾回收等信息1234567891011121314151617181920212223242526272829303132//监控GC情况 间隔1000毫秒执行1次 执行5次jstat -gc 6876 1000 5执行结果如下：C:\\Users\\dell&gt;jstat -gc 6876 1000 5 S0C S1C S0U S1U EC EU OC OU MC MU CCSC CCSU YGC YGCT FGC FGCT GCT13824.0 15872.0 13804.6 0.0 140288.0 129170.6 102400.0 19730.9 54528.0 52078.9 7168.0 6684.3 10 0.143 2 0.172 0.31513824.0 15872.0 13804.6 0.0 140288.0 129170.6 102400.0 19730.9 54528.0 52078.9 7168.0 6684.3 10 0.143 2 0.172 0.31513824.0 15872.0 13804.6 0.0 140288.0 129170.6 102400.0 19730.9 54528.0 52078.9 7168.0 6684.3 10 0.143 2 0.172 0.31513824.0 15872.0 13804.6 0.0 140288.0 129170.6 102400.0 19730.9 54528.0 52078.9 7168.0 6684.3 10 0.143 2 0.172 0.31513824.0 15872.0 13804.6 0.0 140288.0 129170.6 102400.0 19730.9 54528.0 52078.9 7168.0 6684.3 10 0.143 2 0.172 0.315结果说明：S0C 年轻代s0区容量S1C 年轻代s1区容量S0U 年轻代s0区使用量S1U 年轻代s1区使用量EC 年轻代eden区容量EU 年轻代eden区容量OC 老年代容量OU 老年代使用量MC 元空间容量MU 元空间使用量CCSC 压缩类空间容量CCSU 压缩类空间使用大小YGC 从应用程序启动到采样时年轻代中gc次数YGCT 从应用程序启动到采样时年轻代中gc时间FGC 从应用程序启动到采样时全gc次数FGCT 从应用程序启动到采样时全gc时间GCT 从应用程序启动到采样时gc用的总时间(s)s0和s1中必然有一个的使用空间为0，用于复制交换JDK 1.8以下MC/MU指标为PC/PU。（jdk1.8使用元空间替换了永久代）通过参数的不同，可以进行某些方面的重点信息关注选项作用-class监视类装载、卸载数量、总空间以及类装载所耗费的时间-gc监视Java堆状况，包括Eden区、两个survivor区、老年代、元空间的容量、已用空间、GC时间合计等信息-gccapacity监视内容与-gc基本相同，但输出主要关注Java堆各个区域使用到的最大、最小空间-gcutil监视内容与-gc基本相同，但输出主要关注已使用空间占总空间的百分比-gccause与-gcutil功能一样，但是会额外输出导致上一次GC产生的原因-gcnew监视新生代GC状况-gcnewcapacity监视内容与-gcnew基本相同，输出主要关注使用到的最大、最小空间-gcold监视老年代状况-gcoldcapacity监视内容与-gcold基本相同，输出主要关注用到的最大、最小空间-gcmetacapacity输出元数据用到的最大、最小空间-compiler输出JIT编译器编译过的方法、耗时等信息-printcompilation输出已经被JIT编译的方法jmap可以用来查询堆中的实例或者进行堆dump等。1234567891011121314151617181920212223242526//显示堆中对象统计信息，包括类、实例数、合计占用量jmap -histo 6876 &gt; a.txt num #instances #bytes class name---------------------------------------------- 1: 652896 67501960 [B 2: 493614 47624832 [C 3: 54335 17164304 [I 4: 126862 3044688 java.lang.String 5: 28292 2489696 java.lang.reflect.Method 6: 27951 1786648 [Ljava.lang.Object; 7: 21992 1334608 [Lorg.springframework.boot.context.properties.source.ConfigurationPropertyName$ElementType; 8: 18122 1311816 [Ljava.util.HashMap$Node; 9: 32653 1306120 java.util.LinkedHashMap$Entry 10: 10985 1219992 java.lang.Class 11: 35321 1130272 java.util.concurrent.ConcurrentHashMap$Node 12: 17251 966056 java.util.LinkedHashMap 13: 29707 950624 java.util.HashMap$Node 14: 45305 908512 [Ljava.lang.Class; 15: 512 724368 [Ljava.util.concurrent.ConcurrentHashMap$Node; 16: 13340 640320 java.util.HashMap 17: 7763 604160 [S 18: 7641 550152 java.lang.reflect.Field ...执行此命令需要将输出重定向到文件里，否则会有几千上万行12// 生成堆快照信息, 搬运者注：dump类操作，在生产环境慎用，STW警告jmap -dump:format=b,file=heap.hprof 6876jstack用于生成java的线程快照信息12345678910111213141516171819202122232425jstack -l 6876 &gt; threadDump.txt执行结果：2020-03-23 16:51:55Full thread dump Java HotSpot(TM) 64-Bit Server VM (25.65-b01 mixed mode):&quot;DestroyJavaVM&quot; #58 prio=5 os_prio=0 tid=0x0000000060c4a000 nid=0x6618 waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE Locked ownable synchronizers: - None&quot;http-nio-8601-Acceptor&quot; #32 daemon prio=5 os_prio=0 tid=0x0000000060c49800 nid=0x824 runnable [0x00000000648de000] java.lang.Thread.State: RUNNABLE at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method) at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422) at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250) - locked &lt;0x00000000e0c3b670&gt; (a java.lang.Object) at org.apache.tomcat.util.net.NioEndpoint.serverSocketAccept(NioEndpoint.java:463) at org.apache.tomcat.util.net.NioEndpoint.serverSocketAccept(NioEndpoint.java:73) at org.apache.tomcat.util.net.Acceptor.run(Acceptor.java:95) at java.lang.Thread.run(Thread.java:745) ...此命令也最好可以重定向到文件，输出结果较多Java VisualVM工具介绍VisualVM是目前为止JDK发布功能最强大的运行监控故障处理程序。工具路径在jdk路径的bin目录下，jvisualvm.exe监控本地项目双击工具，进入主界面，左侧即可看到本地的java进程，双击即可在右侧查看内容。监控远程项目123// 执行java -jar启动命令时候加入以下参数，hostname为远程的主机名，port使用一个没被占用的端口-Djava.rmi.server.hostname=xxxxxx -Dcom.sun.management.jmxremote.port=1099 -Dcom.sun.management.jmxremote=true -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.managementote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false整体情况监控线程监控对象情况监控Eclipse Memory Analyzer工具安装使用1、安装eclipse –&gt;help –&gt; eclipse marketplace，输入memory，搜索出具体的插件，进行安装。2、使用使用jmap命令或者通过vusal工具dump下内存快照，拖进eclipse即可。 常用的JVM配置参数参数名称含义默认值-Xms初始堆大小物理内存的1/64-Xmx最大堆大小物理内存的1/4-XX:NewSize年轻代的初始大小-XX:MaxNewSize年轻代的最大值-Xmn年轻代的大小,如果通过-Xmn来配置新生代的内存大小，那么-XX:newSize = -XX:MaxNewSize = -Xmn-XX:NewRatio年轻代与老年代的比例 4 表示 年轻代与老年代比例为 1:4-XX:SurvivorRatio两个Survivor区与eden的比例 8 表示两个survivor：eden为 2:8查看本机默认参数命令1java -XX:+PrintFlagsFinal &gt; E:\\ab.txt如何查看高CPU占用的线程1、找到java的进程12345C:\\Users\\dell&gt;jps -l24352 cn.mastercom.MtexConfigApplication3035243508 sun.tools.jps.Jps2、对具体进程进行线程dump1C:\\Users\\dell\\Desktop&gt;jstack -l 24352 &gt; thread.txt3、使用工具查看占用高的线程IDlinux通过top 命令进程查询1234567891011121314151617181920top -H -p 24352top - 16:44:36 up 74 days, 1:22, 1 user, load average: 0.52, 0.39, 0.39Threads: 30 total, 0 running, 30 sleeping, 0 stopped, 0 zombie%Cpu(s): 0.3 us, 0.3 sy, 0.0 ni, 99.0 id, 0.3 wa, 0.0 hi, 0.0 si, 0.0 stKiB Mem : 1882752 total, 92228 free, 980456 used, 810068 buff/cacheKiB Swap: 0 total, 0 free, 0 used. 706556 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 17063 root 20 0 2525764 138224 12788 S 0.0 7.3 0:00.00 java 17065 root 20 0 2525764 138224 12788 S 0.0 7.3 0:02.62 java 17067 root 20 0 2525764 138224 12788 S 0.0 7.3 0:05.73 java 17068 root 20 0 2525764 138224 12788 S 0.0 7.3 0:00.00 java 17069 root 20 0 2525764 138224 12788 S 0.0 7.3 0:00.00 java 17070 root 20 0 2525764 138224 12788 S 0.0 7.3 0:00.00 java 17071 root 20 0 2525764 138224 12788 S 0.0 7.3 0:07.06 java 17072 root 20 0 2525764 138224 12788 S 0.0 7.3 0:01.59 java 17073 root 20 0 2525764 138224 12788 S 0.0 7.3 0:00.00 java 可以看到CPU占用高的百分比windwos可以使用ProcessExplorer软件进行查看4、将线程ID转为16进制，因为线程dump的线程ID是使用16进制的。12343404 --&gt; A98C// 搬运者注：Linux下，通过`printf&quot;%x\\n&quot; tid`命令转换从十六进制5、去之前dump的线程映像中查看对应线程12345678910111213141516&quot;Catalina-utility-1&quot; #17 prio=1 os_prio=-2 tid=0x000000006130b000 nid=0xa98c waiting on condition [0x000000005e7be000] java.lang.Thread.State: WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for &lt;0x00000000e358e9a0&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject) at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175) at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039) at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088) at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809) at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:745) Locked ownable synchronizers: - None如果是自己写的代码，可以从上面查看到具体的问题。转载自: https://juejin.im/post/5e7eb285f265da79710a293d作者：头疼梨侵删","link":"/2020/03/28/jvm-monitor-practice/"},{"title":"Nginx禁止某个IP或者IP段访问的方法","text":"近日，在亚马逊云上部署了一个自己的项目使用的是nginx进行转发刚部署上线一天就发现被好多的恶意软件扫描了于是我就把所有的ip给封了，只留下我自己的IP段可以访问具体配置如下：nginx配置访问ip需要修改nginx.conf文件，只需要在server中添加allow跟deny的ip即可，如下：1234567891011121314151617181920212223242526upstream novel { server 127.0.0.1:8080;}server { listen 80; server_name localhost; charset utf8; allow 112.97.0.0/16; deny all; location / { proxy_pass http://novel; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } error_page 500 502 503 504 /50x.html; location = /50x.html { root html; }}ps: 上面的配置中allow必须在deny的前面配置，不然allow不生效。下面是具体的配置nginx中允许或者拒绝某个ip访问是这么写的：12allow 192.168.0.1;deny 192.168.0.2;如果你需要对整个ip段设置不允许访问，可以这么写：1234567deny 123.0.0.0/8; // 封 123.0.0.1~123.255.255.254 这个段的ipdeny 123.1.0.0/16; // 封 123.1.0.1~123.1.255.254 这个段的ipdeny 123.1.1.0/24; // 封 123.1.1.1~123.1.1.254 这个段的ipdeny all; // 封所有ipps: allow跟deny配置相同，如果需要开放某个IP段，只需要把上面的deny改成allow如果你有很多的ip需要配置的话，那么你也可以新建一个文件，如：allow_deny_ip.conf然后把需要配置的ip单独写在这个文件上面，最后在nginx中引用这个文件即可，如下：12345server { ... include allow_deny_ip.conf ...}","link":"/2018/09/04/nginx-allow-and-deny-ip/"},{"title":"《赘婿》摘录","text":".cc{color:#940225;padding:15px;margin:15px;border-style:solid;border-color:gray;border-width:1px;border-radius:10px}.tt{text-align:right}在我们的人生里，有时候会遇上一个人，她如同闪电般出现，就那样的，改变了我们的一辈子。——愤怒的香蕉《赘婿》如果将来有一天，走的太快，你要记得你现在的心情，该停就停，该退就退，不要勉强，免得到最后反倒舍本逐末，忘了自己要什么。握不住的沙，随手扬了它。即便回到现在，你也没有失去什么......——愤怒的香蕉《赘婿》天风卷动春日的韶光，卷动夏日的雷雨，卷动秋日的黄叶，卷动冬天的冰雪，滚滚而来，滚滚而逝。一个旧的时代就要过去了，而在新时代到来之前，人们还要经历无数的战乱与冲突，无数的悲恸与苍凉。只因天地如炉。 而万物为铜。——愤怒的香蕉《赘婿》所谓历史，与故事有其共通之处，只是由于历史真实发生过，于他人的说服力便更强一些。但归根结底，历史也好故事也罢，真正有用的，是它蕴含的教训，是寄托于前人而又反照自身的一个过程。但在后世浮躁的社会上，毫无辨别与思考能力的人比比皆是，他们有时折服于所谓历史的真实，却从不以任何真实的历史来反照自身，大部分人只以真实来对照他人，获取些许的优越感，却从未发现自身所行与历史上众多愚蠢事例如出一辙。——愤怒的香蕉《赘婿》我们大家的本质都是一样的，但面对的处境不一样，一个强大的有智慧的人，就要学会看懂现实，承认现实，然后去改变现实。——愤怒的香蕉《赘婿》秩序已经破碎，自此之后，便只有铁与血的峥嵘、直面刀锋的勇气、灵魂最深处的抗争和呐喊能让人们勉强在这片海雨天风中站立不屈，直至一方死尽、直至人老苍河，不死、不休。——愤怒的香蕉《赘婿》人生之中，总会有一些事情，不会随着时间的流逝而褪色或是被遗忘，它只是会不断地在心里沉淀下来，化为与当初不同却更为沉重的一些东西。如同那样的痛楚，它会像是跗骨之蛆一般的往身体的每一处钻，从外向内的将人撕裂，再从内向外的将人掏空。当人们开始习惯的时候，整个人也已经变得空空荡荡，只余下那些痛楚与空虚结合在一起，填充原本拥有的一切。——愤怒的香蕉《赘婿》丧家野犬，天下无敌——愤怒的香蕉《赘婿》正确从来不是和错误对等的一半，正确是一万条路中的一条，而其余的都是错的。——愤怒的香蕉《赘婿》“有的时候，就是这样……”书生一字一顿，“踏错一步，你就死了。”——愤怒的香蕉《赘婿》“说爱国,说死节,死到临头了,却没有人愿意去,那儒者,不就成了看不见摸不着的东西了吗?立恒啊,这样说起来可能有些太过务实了,但我辈儒者,每年都该死几个人,死几个……有名字的人,死在屠刀之下,死在金銮殿上,死在这千万人的眼前,真到该死之时不能退,如此才能提醒世人,这儒家之道是真的,为不平之事而死,我辈才算为往圣继绝学。我死在这杭州城,也是要提醒大家,确实有些人抵抗过的,免得他们想要说起的时候,热血之时,找不到可以说的名字……”——钱希文——愤怒的香蕉《赘婿》你知道吗，有一些人啊，他活着的时候，你看他不顺眼，不爽他。但是有一天忽然听到他死了，你又觉得他不该这么去死的。这种人啊，是真正活了一辈子的。——愤怒的香蕉《赘婿》成年的雄鹰离开了，雏鹰便只能自己学会飞翔。曾经的秦嗣源或许是从更高大的背影中接下名为责任的担子，秦嗣源离开后，后辈们以新的方式接下天下的重担。十四年的光阴过去了，曾经第一次出现在我们面前还是孩子的年轻人，也只能用仍旧稚嫩的肩膀，试图扛起那压下来的重量。他们的肩膀自然会碎，人们也只能期待，当那肩膀碎后，会变得更为坚固和结实。——愤怒的香蕉《赘婿》天地不仁，然万物有灵。……所以每一个人，都在为自己认为正确的方向，做出努力。——愤怒的香蕉《赘婿》世间万事万物，不过就是一场遇见、而又分离的过程。——愤怒的香蕉《赘婿》世间艰难愁苦之事，难以言语形容万一，尤其是在经历过那些黑暗绝望之后，一夕轻松下来，复杂的心情更是难以言喻。——愤怒的香蕉《赘婿》人们的相遇相聚基于缘分，缘分也终有尽头，因为这样的遗憾，彼此的手，才能够紧紧地牵在一起。——愤怒的香蕉《赘婿》","link":"/2021/04/07/novel-zhuixu/"},{"title":"西宁之旅-01","text":"跟几个狐朋狗友商榷，今年国庆准备去哪玩？去西宁怎么样？还没去过西北！行呗，那就走起！一段旅途就这样开启了…拉脊山、青海湖","link":"/2019/09/29/pictures-in-xining-01/"},{"title":"西宁之旅-02","text":"茶卡盐湖、翡翠湖","link":"/2019/09/30/pictures-in-xining-02/"},{"title":"西宁之旅-03","text":"雅丹地貌、石油小镇","link":"/2019/10/01/pictures-in-xining-03/"},{"title":"西宁之旅-04","text":"葡萄、沙漠、落日、星空","link":"/2019/10/02/pictures-in-xining-04/"},{"title":"西宁之旅-05","text":"莫高窟、沙漠骆驼、月牙泉","link":"/2019/10/03/pictures-in-xining-05/"},{"title":"西宁之旅-06","text":"悬臂长城、七彩丹霞、雪山","link":"/2019/10/04/pictures-in-xining-06/"},{"title":"生活了二十多年的土地","text":"故乡不管过了多久它都是一个神圣的地方因为它承载了我们最美好的童年记忆回顾历史，这是2013年3月份的样子家门口的水井1家门口的水井2家门和房间门巷子和水沟1巷子和水沟2巷子和水沟3巷子和水沟4已经被拆掉的屋子1已经被拆掉的屋子2已经被拆掉的屋子3马路旁接下来，这是2018年4月份的样子不敢想象，居然在这个环境下又继续住了5年但是，终于要彻底拆除了2018年鸟瞰图村子正门正门操场全景操场右侧榕树部分被拆除的巷子废弃的二楼1废弃的二楼2村子左侧全景2018年6月，新房子终于盖起来了新房子全景楼顶焊接钢筋","link":"/2018/04/23/pictures-of-my-hometown/"},{"title":"常用Git命令","text":"由于工作需要，必须同时照顾Java跟C#两边的代码，Java的IDE不用说，Intellij面的Git插件相当给力。但是C#的Visual Studio 2015就不太行了，不支持ssh方式的远程仓库链接，所以操作得用命令行。因此，记录一下这些自己使用到的，但是有时又会忘记的git命令，闲余时候看看，指不定就能记住了呢~常用克隆一个仓库： git clone [url]选中一个分支： git checkout [brachName]从远程分支拉取最新的数据，不会合并到当前分支： git fetch从远程分支拉取最新的数据，自动合并到当前分支： git pull查看当前工作区状态： git status把文件加入到暂存区： git add [fileName]从暂存区把文件移除： git reset HEAD [fileName]提交暂存区文件： git commit -m &quot;[commit message]&quot;把工作区的更新推送到远程分支： git push把远程分支合并到本地分支: git merge [origin/branchName]偶尔用列出最近的commit记录： git log \\ git log --pretty=oneline列出历史操作记录： git reflog回退到某个版本： git reset --hard [commitId]丢弃工作区中fileName文件的修改： git checkout -- [fileName]把文件从git版本库中移除(不删除文件)： git rm --cached [fileName]把文件从git版本库中移除(删除文件)： git rm --f [fileName]Branch列出本地分支： git branch \\ git branch --list列出远程分支： git branch -r列出所有分支： git branch -a基于当前分支创建名为branchName的分支： git branch [branchName]基于branchName2创建名为branchName1的分支： git branch [branchName1] [branchName2]删除名为branchName的分支： git branch -d [branchName]Tag列出现有的Tag列表： git tag \\ git tag --list新加一个名为tagName的Tag: git tag [tagName]推送一个Tag到远程： git push [tagName]推送所有的Tag到远程： git push --tags \\ git push origin --tags删除本地tag： git tag -d [tagName]删除远程tag： git push origin :refs/tags/&lt;tagname&gt;Remote显示远程仓库地址： git remote -v新增一个名为name的远程仓库地址： git remote add [name] [url]当有多个远程地址时，可以选择一个仓库拉取数据： git fecth [remoteName]把当前分支推送到远程的某个分支上： git push [remoteName] [branchName]显示一个远程仓库状态： git remote show [remoteName]重命名远程仓库： git remote rename [oldName] [newName]删除远程仓库： git remote rm [remoteName]删除本地存在但远程不存在的分支： git remote prune [remoteName] eg: git remote prune originCommit修改前一次commit(比如commit message写错了)： git commit --amend如果需要修改的commit不是后面还有其他的commit, 需要如下操作：git checkout -b [branchName] [fixedCommitId]git cherry-pick [fixedCommitId]git commit --amendgit cherry-pick [依次填入fixedCommitId后面的commitId]ps:修改后的内容只能在新的分支上，原分支内容是修改不了的了","link":"/2018/01/10/popular-used-cmd-of-git/"},{"title":"使用小乌龟clone项目小记","text":"昨日在用小乌龟拉项目代码的时候遇到一个问题因为之前也有碰到过，却无奈一时想不起来怎么解决所以，趁周末记录下因为使用的是ssh的方式获取所以，需要在本地生成sshKey，并且在gitlab上配置生成的publicKey这里插一句：生成sshKey的命令是ssh-keygen -t rsa -C 'xxx@xxx.com'一切配置妥善，使用TortoiseGit-&gt;鼠标右键-&gt;Git Clone接着就报错了，报错内容如下：什么原因呢？估计你也不想知道，那就直接宣布怎么解决吧！！！方式一：最简单的解决办法使用命令行操作，如：1234git clone ssh://yoursite:port/xxx.git// 如果是第一次连接，会出现是否接受ssh，输入yes即可// 然后一路回车，搞定方式二：配置PuttyKey使用小乌龟自带的工具：PuTTYgen，然后根据以下步骤，利用已经存在的id_rsa文件生成一个xx.ppk打开-&gt;选择Conversions-&gt;Import Key-&gt;导入私钥文件id_rsa-&gt;Save private key-&gt;操作完成接着-Git Clone-导入刚才生成的ppk文件-点击OK获取代码PS：SourceTree使用ssh连接的操作是一样的：生成ppk，然后打开pageant-&gt;Add Key即可","link":"/2018/09/15/problems-in-use-tortoisegit-clone/"},{"title":"记一次Ribbon重试配置不生效问题","text":"问题发生：生产环境发现一个交易订单对应两个支付订单记录（按实际业务应该一对一）问题排查：业务服务在调用支付服务时候是使用Feign来调用接口的（只接收post请求），配置中有重试相关配置（配置如下），由于网络原因，支付服务在10s后没有返回响应，触发了重试机制，导致出现了两个支付订单的情况。Ribbon重试配置1234567spring.cloud.loadbalancer.retry.enabled = trueribbon.ReadTimeout = 10000ribbon.ConnectTimeout = 10000ribbon.MaxAutoRetries = 1ribbon.MaxAutoRetriesNextServer = 1ribbon.OkToRetryOnAllOperations = false问题模拟：retry.enabledMaxAutoRetriesMaxAutoRetriesOkToRetryOnAllOperations实验结果false11true重试4次后，抛出SocketTimeoutException异常false11false重试4次后，抛出SocketTimeoutException异常true21false重试6次后，抛出SocketTimeoutException异常true22false重试9次后，抛出SocketTimeoutException异常true11true重试4次后，抛出SocketTimeoutException异常问题分析从上面的模拟结果可以看两点问题（第3点没在表格列出来）：1、spring.cloud.loadbalancer.retry.enabled 跟 ribbon.OkToRetryOnAllOperations 两个参数不管配置成 true 还是 false。都会进行重试。2、ribbon.MaxAutoRetries 跟 ribbon.MaxAutoRetriesNextServer 参数改变，会改变重试的次数。3、ribbon.ReadTimeout 的改变会影响重试间隔时间（这个没在表格中列出来，但是确实会影响）。问题解决：查阅了一些资料，以及在网上找了很多博客对spring cloud重试机制的讲解，发现配置并没有问题，所以问题应该不在配置上。又经过一番对比，发现很多文章包括spring官方文档都有说到，需要引入spring-retry依赖，于是查看项目依赖，果然没有引入该依赖，把依赖引入后问题得到解决。总结与思考许多问题的解决方法往往就在眼前，但是时常会被忽略。同时也具有一定的迷惑性，在解决这个问题的过程中，首先因为配置的关系，部分配置是生效的，另一部分没生效，所以会让人搞不清楚是哪里出现的问题。另外，网上找了些文章，里面有说道spring.cloud.loadbalancer.retry.enabled配置默认是关闭的，也就是false，但是我在查阅源码的时候发现，源码（源码如下）里面默认是true，这也让我有点迷惑。所以一开始对引入spring-retry依赖的问题也就忽略了，想着是不是版本更新后这个默认就不需要引入了，也因此陷入了这样一个误区，在兜兜转转一圈后才发现问题所在。LoadBalancerRetryProperties源码123456789101112131415@ConfigurationProperties(\"spring.cloud.loadbalancer.retry\")public class LoadBalancerRetryProperties { private boolean enabled = true; public LoadBalancerRetryProperties() { } public boolean isEnabled() { return this.enabled; } public void setEnabled(boolean enabled) { this.enabled = enabled; }}参考资料1、https://cloud.spring.io/spring-cloud-netflix/multi/multi_retrying-failed-requests.html2、https://blog.didispace.com/spring-cloud-ribbon-failed-retry/3、https://www.liujiajia.me/2019/1/22/feign-retry4、https://xiefayang.com/2019/04/26/Ribbon——超时与重试/5、http://www.itmuch.com/spring-cloud-sum/spring-cloud-retry/6、http://www.itmuch.com/spring-cloud-sum/spring-cloud-timeout/","link":"/2021/04/09/ribbon-retry-problem/"},{"title":"Elasticsearch启动异常处理","text":"最近在使用zipkin, 遇到如下问题，于是就网上搜了一下解决方案并记录了下来使用tar.gz安装包解压安装的方式使用./bin/elasticsearch方式启动elasticsearch使用java -DSTORAGE_TYPE=elasticsearch -DES_HOSTS=http://ip:9200 -jar zipkin.jar命令启动zipkinZipkin启动报错如下：123456789101112131415161718192021222324252627282930java.util.concurrent.RejectedExecutionException: finishConnect(..) failed: Connection refused: 10.13.0.92/10.13.0.92:9200 at zipkin2.elasticsearch.internal.client.HttpCall.lambda$sendRequest$3(HttpCall.java:235) ~[zipkin-storage-elasticsearch-2.19.1.jar!/:?] at java.util.concurrent.CompletableFuture.uniExceptionally(CompletableFuture.java:870) ~[?:1.8.0_212] at java.util.concurrent.CompletableFuture$UniExceptionally.tryFire(CompletableFuture.java:852) ~[?:1.8.0_212] at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:474) ~[?:1.8.0_212] at java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:1977) ~[?:1.8.0_212] at com.linecorp.armeria.common.HttpMessageAggregator.fail(HttpMessageAggregator.java:146) ~[armeria-0.95.0.jar!/:?] at com.linecorp.armeria.common.HttpMessageAggregator.onError(HttpMessageAggregator.java:60) ~[armeria-0.95.0.jar!/:?] at com.linecorp.armeria.common.stream.FilteredStreamMessage$FilteringSubscriber.onError(FilteredStreamMessage.java:277) ~[armeria-0.95.0.jar!/:?] at com.linecorp.armeria.common.stream.AbstractStreamMessage$CloseEvent.notifySubscriber(AbstractStreamMessage.java:370) ~[armeria-0.95.0.jar!/:?] at com.linecorp.armeria.common.stream.DefaultStreamMessage.notifySubscriberOfCloseEvent(DefaultStreamMessage.java:195) ~[armeria-0.95.0.jar!/:?] at com.linecorp.armeria.common.stream.DefaultStreamMessage.handleCloseEvent(DefaultStreamMessage.java:365) ~[armeria-0.95.0.jar!/:?] at com.linecorp.armeria.common.stream.DefaultStreamMessage.notifySubscriber0(DefaultStreamMessage.java:308) ~[armeria-0.95.0.jar!/:?] at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163) ~[netty-common-4.1.43.Final.jar!/:4.1.43.Final] at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:510) ~[netty-common-4.1.43.Final.jar!/:4.1.43.Final] at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:413) ~[netty-transport-native-epoll-4.1.43.Final-linux-x86_64.jar!/:4.1.43.Final] at io.netty.util.concurrent.SingleThreadEventExecutor$6.run(SingleThreadEventExecutor.java:1050) ~[netty-common-4.1.43.Final.jar!/:4.1.43.Final] at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) ~[netty-common-4.1.43.Final.jar!/:4.1.43.Final] at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) [netty-common-4.1.43.Final.jar!/:4.1.43.Final] at java.lang.Thread.run(Thread.java:748) [?:1.8.0_212]Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: finishConnect(..) failed: Connection refused: 10.13.0.92/10.13.0.92:9200Caused by: java.net.ConnectException: finishConnect(..) failed: Connection refused at io.netty.channel.unix.Errors.throwConnectException(Errors.java:124) ~[netty-transport-native-unix-common-4.1.43.Final.jar!/:4.1.43.Final] at io.netty.channel.unix.Socket.finishConnect(Socket.java:243) ~[netty-transport-native-unix-common-4.1.43.Final.jar!/:4.1.43.Final] at io.netty.channel.epoll.AbstractEpollChannel$AbstractEpollUnsafe.doFinishConnect(AbstractEpollChannel.java:660) ~[netty-transport-native-epoll-4.1.43.Final-linux-x86_64.jar!/:4.1.43.Final] at io.netty.channel.epoll.AbstractEpollChannel$AbstractEpollUnsafe.finishConnect(AbstractEpollChannel.java:637) ~[netty-transport-native-epoll-4.1.43.Final-linux-x86_64.jar!/:4.1.43.Final] at io.netty.channel.epoll.AbstractEpollChannel$AbstractEpollUnsafe.epollOutReady(AbstractEpollChannel.java:524) ~[netty-transport-native-epoll-4.1.43.Final-linux-x86_64.jar!/:4.1.43.Final] at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:492) ~[netty-transport-native-epoll-4.1.43.Final-linux-x86_64.jar!/:4.1.43.Final] at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:407) ~[netty-transport-native-epoll-4.1.43.Final-linux-x86_64.jar!/:4.1.43.Final] ... 4 more解决方法：修改config/elasticsearch.yml配置项network.host: 0.0.0.0重启ElasticSearch，ElasticSearch启动报错如下：1234567891011[2019-11-19T14:51:10,811][ERROR][o.e.b.Bootstrap ] [test] node validation exception[5] bootstrap checks failed[1]: max file descriptors [4096] for elasticsearch process is too low, increase to at least [65535][2]: max number of threads [1024] for user [elsearch] is too low, increase to at least [4096][3]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144][4]: system call filters failed to install; check the logs and fix your configuration or disable system call filters at your own risk[5]: the default discovery settings are unsuitable for production use; at least one of [discovery.seed_hosts, discovery.seed_providers, cluster.initial_master_nodes] must be configured[2019-11-19T14:51:10,814][INFO ][o.e.n.Node ] [test] stopping ...[2019-11-19T14:51:10,833][INFO ][o.e.n.Node ] [test] stopped[2019-11-19T14:51:10,833][INFO ][o.e.n.Node ] [test] closing ...[2019-11-19T14:51:10,852][INFO ][o.e.n.Node ] [test] closed[1]: max file descriptors [4096] for elasticsearch process is too low, increase to at least [65535]切换root用户vi /etc/security/limits.conf文件末尾添加如下内容12* soft nofile 65536* hard nofile 65536wq保存[2]: max number of threads [1024] for user [elsearch] is too low, increase to at least [4096]vi /etc/security/limits.d/90-nproc.conf修改* soft nproc 1024为* soft nproc 4096wq保存[3]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]vi /etc/sysctl.conf末尾添加vm.max_map_count=262144wq保存sysctl -p 重新加载系统参数[4]: system call filters failed to install; check the logs and fix your configuration or disable system call filters at your own riskvi ELS_HOME/config/elasticsearch.yml修改配置项为bootstrap.system_call_filter: false[5]: the default discovery settings are unsuitable for production use; at least one of [discovery.seed_hosts, discovery.seed_providers, cluster.initial_master_nodes] must be configuredvi ELS_HOME/config/elasticsearch.yml修改配置项为cluster.initial_master_nodes: [&quot;node-1&quot;]wq保存重启elasticsearch","link":"/2019/11/26/solve-es-startup-error/"},{"title":"SpringMvc项目改造成springboot+web项目踩坑指南","text":"此前有个项目采用的springMvc框架实现的，每次启动都要依赖tomcat。觉得比较麻烦，就准备改成springboot+web的方式。磕磕碰碰，遇到了几个问题，记录过程如下:项目改动前后结构对比改动内容如下：新增StartupApplication.java作为启动类123456@SpringBootApplicationpublic class StartupApplication { public static void main(String[] args) { SpringApplication.run(StartupApplication.class, args); }}新增RouteController.java用于首页跳转1234567@Controllerpublic class RouteController { @GetMapping(&quot;/&quot;) public String index(){ return &quot;index&quot;; }}将webapp/static下pages目录移动到WEB-INF下并重命名为views将index.html改成index.jsp并移动到views目录将webapp/static目录移动到src/main/resources目录下将novel.properties文件重命名为application.properties并新增如下内容12345678server.port=18888# log配置文件logging.config=classpath:logback.xml# jsp配置spring.mvc.view.prefix=/WEB-INF/views/spring.mvc.view.suffix=.jsp# 静态文件配置spring.mvc.static-path-pattern=/static/**删除pom.xml中spring-web-mvc相关依赖，并加如下内容12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.tomcat.embed&lt;/groupId&gt; &lt;artifactId&gt;tomcat-embed-jasper&lt;/artifactId&gt;&lt;/dependency&gt;删除applicationContext.xml，servlet-context.xml，web.xml三个文件至此，项目结构上基本改造完成遇到的问题Springboot项目编译正常启动Unable to start embedded Tomcat报错1234567仔细查看错误日志： Caused by: java.lang.NoSuchMethodError: javax.servlet.ServletContext.getVirtualServerName()Ljava/lang/String;通过依赖关系，你可以查到servlet-api.jar包，并发现低版本2.4的servlet-api.jar中没有getVirtualServerName()方法可尝试通过引入高版本(javax.servlet-api-3.1.0.jar)解决ps &gt;&gt; 本项目的解决方法是删除了该依赖jar包idea下启动正常访问，使用java -jar方式启动时，jsp页面报40412345678910111213141516171819202122232425262728293031需要在pom.xml中加入如下内容：&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.4.0.RELEASE&lt;/version&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/**&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/webapp&lt;/directory&gt; &lt;!--这里必须是META-INF/resources--&gt; &lt;targetPath&gt;META-INF/resources&lt;/targetPath&gt; &lt;includes&gt; &lt;include&gt;**/**&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt;&lt;/build&gt;a. 网上说spring-boot-maven-plugin插件的版本必须小于1.4.2，一开始使用的1.5.x版本会报404b. 使用resource把webapp目录下的文件打包到META-INF/resources下，使用jar方式启动必须要这么处理，war方式不需要静态资源文件访问报404错误123a. 静态文件目录需要放在 src/main/resources 目录下，尝试过放在webapp跟webapp/WEB-INF下均无法正常访问b. application.properties文件中需要配置静态资源文件的路径格式，如下： spring.mvc.static-path-pattern=/static/**","link":"/2019/12/18/springmvc-to-springboot-web/"},{"title":"Shell脚本实现Linux错误日志监控告警","text":"前文有讲到，最近部署了一个服务但是老是被恶意的扫描虽然利用nginx禁止了些IP但我还是想在被恶意扫描时候收到一个通知信息让我能知道我的服务器又被访问了于是乎，就有了这篇文章此文目的是为了记录自己的操作步骤既给自己一个复习的机会，同时也能服务看到此文的读者好了，话不多说接下来开始正文内容整体的思路如下：既然是监控，比较方便的方式就是利用Linux的cron定时任务来定时去执行一个操作既然是要能被定时任务执行的操作，那么我们就需要写一个shell脚本shell脚本需要做什么呢？我们可以去匹配某个时间段，在时间段内是否有新的内容添加进去（日志文件肯定有记录时间的），如果有的话，则把这段内容单独取出来，并发送邮件通知上面又涉及到了发邮件，发邮件比较好的方式是写个Python脚本（因为我的服务器自带了python环境，而且python运行起来也简单）所以，总结下来我们需要两个文件（假定都存放在/opt/mysh/目录）：一个是可执行的shell脚本；一个是发邮件的python脚本文件。并设定一个cron定时任务。接下来就是开始写个shell脚本，如下(文件名：monitor_nginx_log.sh)：1234567891011121314151617181920212223#!/bin/bash#日志文件路径logfile=/var/log/nginx#当天日期,年月日cur_date=`date +&quot;%Y/%m/%d&quot;`#开始时间（3分钟前）,时分秒start_time=`date -d&quot;3 minutes ago&quot; +&quot;%H:%M:%S&quot;`#结束时间,时分秒stop_time=`date +&quot;%H:%M:%S&quot;`#把新增的错误日志写到new_error_log中tac $logfile/error.log | awk -v st=&quot;$start_time&quot; -v et=&quot;$stop_time&quot; -v dt=&quot;$cur_date&quot; '{t=$2;t1=$1; if(dt==t1 &amp;&amp; t&gt;=st &amp;&amp; t&lt;=et) {print $0}}' &gt; $logfile/new_error_log.txtfile_size=`du $logfile/new_error_log.txt | awk '{print $1}'`#new_error_log文件大小不为0，发送邮件通知if [[ $file_size -gt 0 ]];then echo `date +'%Y/%m/%d %H:%M:%S'`&quot; there are new errors in nginx error.log&quot; | cat &gt;&gt; /opt/mysh/monitor.log /usr/bin/python2.7 /opt/mysh/send_mail.py | tee -a /opt/mysh/monitor.logfips: 上面的脚本有好几个命令，如果有疑问的话，请往下看，会有解释的然后呢，我们还要有一个邮件发送脚本（send_mail.py），如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# -*- coding: utf-8 -*-import osimport smtplibfrom email.header import Headerfrom email.mime.application import MIMEApplicationfrom email.mime.multipart import MIMEMultipartfrom email.mime.text import MIMETextfrom email.utils import parseaddr, formataddrdef _format_addr(s): name, addr = parseaddr(s) return formataddr((Header(name, 'utf-8').encode(), addr))# 邮箱定义smtp_server = 'smtp.163.com'smtp_port = 25from_addr = 'from_addr@163.com'password = os.environ.get('MAIL_PASSWD')to_addr = 'to_addr@163.com'# 邮件对象msg = MIMEMultipart()msg['From'] = _format_addr('发件人 &lt;%s&gt;' % from_addr)msg['To'] = _format_addr('收件人 &lt;%s&gt;' % to_addr)msg['Subject'] = Header('【Support】发现错误', 'utf-8').encode()# 邮件正文是MIMEText:html = &quot;&lt;html&gt;&lt;body&gt;&lt;h4&gt;检测有错误发生，详情见附件！&lt;/h4&gt;&lt;/body&gt;&lt;/html&gt;&quot;msg.attach(MIMEText(html, 'html', 'utf-8'))# 添加附件file_path = &quot;/var/log/nginx/new_error_log.txt&quot;attachment = MIMEApplication(open(r'file_path', 'rb').read())attachment.add_header('Content-Disposition', 'attachment', filename=&quot;new_error_log.txt&quot;)msg.attach(attachment)# 发送邮件print('开始发送邮件&gt;&gt;&gt;')try: server = smtplib.SMTP(smtp_server, smtp_port) server.login(from_addr, password) server.sendmail(from_addr, to_addr, msg.as_string()) server.quit()except Exception, e: print &quot;邮件发送异常：&quot; + efinally: print('结束邮件发送&lt;&lt;&lt;')ps1: 上面的代码中使用了os.environ.get('MAIL_PASSWD')获取环境变量，可以使用export MAIL_PASS=xxxx进行设置（只对当前shell有效，需要永久生效请修改/etc/profile）ps2: 163的邮箱老是会退信，因为发送的次数多，而且内容相似，会被当成垃圾邮件。好烦~最后我们需要做的就是在定时任务中添加一个任务123root@ubuntu:/opt/mysh# crontab -e# 监控nginx错误日志,每3分钟执行一次*/3 * * * * /opt/mysh/monitor_nginx_log.shps：查看定时任务使用crontab -l至此，我们的监控就已经完成了。参考文章：Nginx日志实现访问异常报警详解上面的shell脚本里面有几个命令，这里简单的解释一下。datedate命令用来获取机器当前时间，如果需要格式化时间，可以加号（+）传参，如下：12345678910111213141516date +'%Y-%m-%d %H:%M:%S'// 输出格式为：2018-09-05 08:15:02%Y表示年%m表示月%d表示天%H表示小时（表示的时间是00-23）%M表示分钟%S表示秒%s（表示unix时间戳的秒数）-d&lt;字符串&gt;：显示字符串所指的日期与时间。字符串前后必须加上双引号； -s&lt;字符串&gt;：根据字符串来设置日期与时间。字符串前后必须加上双引号； -u：显示GMT； --help：在线帮助； --version：显示版本信息。tactac命令其实就是cat的反转的形式，tac是从最后一行往前读取内容，因为我们是判断是否有新增错误日志，所以需要从后往前遍历，故使用tac。awkawk是行处理器，可以依次对每一行进行处理，-v是定义变量var=value, ‘’里面内容是引用代码块, $1是指第一部分内容（空格分隔）我们使用例子说明一下：123456789101112// 假定日志文件格式是这样的：2018/09/05 06:32:50 [error] 26217#26217: *597 access forbidden by rule, client: 123.123.456.456, server: localhost, request: &quot;GET / HTTP/1.1&quot;2018/09/05 06:32:52 [error] 26217#26217: *597 access forbidden by rule, client: 123.123.456.456, server: localhost, request: &quot;GET / HTTP/1.1&quot;2018/09/05 06:32:52 [error] 26217#26217: *597 access forbidden by rule, client: 123.123.456.456, server: localhost, request: &quot;GET /favicon.ico HTTP/1.1&quot;// 命令如下：awk -v st=&quot;$start_time&quot; -v et=&quot;$stop_time&quot; -v dt=&quot;$cur_date&quot; '{t=$2;t1=$1; if(dt==t1 &amp;&amp; t&gt;=st &amp;&amp; t&lt;=et) {print $0}}'// 其中 -v st=&quot;$start_time&quot; 是赋值命令，因为后续有用到比较：t&gt;=st// '{t=$2;t1=$1; if(dt==t1 &amp;&amp; t&gt;=st &amp;&amp; t&lt;=et) {print $0}}' 是引用代码块,此处表示匹配当前时间段内的内容// t=$2;t1=$1; 里面的 $2 是 06:32:50 这部分内容，$1 是 2018/09/05 这部分内容. // 因为 $ 是从1开始的，所以 $0 指的是整行的内容。&gt;&gt;文件内容追加使用该命令12345// 如：把123456追加到test.log的文件末尾，因为是追加，所以原有内容还在echo &quot;123456&quot; | cat &gt;&gt; test.log// 注意：单个&gt;是会覆盖文件的，如果执行下面命令则会覆盖test.log原有内容echo &quot;123456&quot; | cat &gt; test.logtee读取标准输入的数据,并将其内容输出成文件123456789101112131415// 输出到标准输出的同时，保存到文件file中。如果文件不存在，则创建；如果已经存在，则覆盖tee file// 输出到标准输出的同时，追加到文件file中tee -a file// 输出到标准输出两次tee -// 上面tee进去的monitor.log是这样的：2018/09/07 03:27:01 there are new errors in nginx error.log2018/09/07 03:26:57 [error] 1254#1254: *109 access forbidden by rule, client: 220.181.132.194, server: localhost, request: &quot;GET /favicon.ico HTTP/1.1&quot;, host: &quot;123.123.123.123&quot;2018/09/07 03:26:56 [error] 1254#1254: *109 access forbidden by rule, client: 220.181.132.194, server: localhost, request: &quot;GET / HTTP/1.1&quot;, host: &quot;123.123.123.123&quot;开始发送邮件&gt;&gt;&gt;结束邮件发送&lt;&lt;&lt;再补充2个命令：sort | uniq12345678910111213// 命令如下：cat /var/log/nginx/error.log | awk '{print $11}' | uniq -cd | sort -nr// 执行结果如下：179 103.25.110.106,178 50.63.160.242, 58 47.96.12.198, 2 194.126.182.88, 2 14.154.29.140,// 命令解释（统计error.log中被禁止访问的ip出现次数）：uniq 用于去重，-c 统计重复次数， -d 只显示重复的数据sort 用于排序，-n 排序后输出， -r 逆序排列","link":"/2018/09/05/use-linux-shell-monitor-error-log/"},{"title":"Window命令之attrib","text":"作为一个IT从业者熟悉windows命令可以说是我们必备的一项技能之一这里我简单记录了一下attrib的使用之所以会接触到这个命令原因是我突然有个需求要改我本地的host文件然而我找到这个目录C:\\Windows\\System32\\drivers\\etc发现并没有看到hosts这个东西没有就新建一个呗然后就是这样…什么鬼？上网、百度一下然后找到了这么一个方法：12341. 按住windows键（就是小旗子小窗口键）+R，打开运行；2. 在输入框中输入 cmd并回车；3. 紧接着在dos窗口中输入“CD \\WINDOWS\\SYSTEM32\\DRIVERS\\ETC”（不含引号），回车；4. 再次输入“ATTRIB -S -H -R HOSTS”（不含引号），回车。好吧，我再次看到了它(hosts)的存在言归正传正式介绍一下attrib这个命令：英文”attrib”,译为”属性”,是DOS下不常用的命令。它是显示、设置，或删除指派给文件或目录的属性attrib指令的格式和常用参数为：12345678910111213ATTRIB [+R|-R] [+A|-A] [+S|-S] [+H|-H] [[drive:] [path] filename] [/S [/D]]+ 意为增加属性- 意为删除属性R 只读文件属性A 存档文件属性S 系统文件属性H 隐藏文件属性[drive:][path][filename] 磁盘 路径 文件名/S 处理当前文件夹及其子文件夹中的匹配文件。/D 处理文件夹。可以看出ATTRIB -S -H -R HOSTS命令就是删除hosts文件的只读、隐藏、系统文件权限接着就可以尽情的编辑它了好了今天的分享就到此我们下次再见~","link":"/2018/05/17/windows-cmd-attrib/"},{"title":"JAVA与模式之责任链模式","text":"转载自java_my_life的博客作者： java_my_life原文地址：http://www.cnblogs.com/java-my-life/archive/2012/05/28/2516865.html在阎宏博士的《JAVA与模式》一书中开头是这样描述责任链（Chain of Responsibility）模式的：责任链模式是一种对象的行为模式。在责任链模式里，很多对象由每一个对象对其下家的引用而连接起来形成一条链。请求在这个链上传递，直到链上的某一个对象决定处理此请求。发出这个请求的客户端并不知道链上的哪一个对象最终处理这个请求，这使得系统可以在不影响客户端的情况下动态地重新组织和分配责任。从击鼓传花谈起.击鼓传花是一种热闹而又紧张的饮酒游戏。在酒宴上宾客依次坐定位置，由一人击鼓，击鼓的地方与传花的地方是分开的，以示公正。开始击鼓时，花束就开始依次传递，鼓声一落，如果花束在某人手中，则该人就得饮酒。比如说，贾母、贾赦、贾政、贾宝玉和贾环是五个参加击鼓传花游戏的传花者，他们组成一个环链。击鼓者将花传给贾母，开始传花游戏。花由贾母传给贾赦，由贾赦传给贾政，由贾政传给贾宝玉，又贾宝玉传给贾环，由贾环传回给贾母，如此往复，如下图所示。当鼓声停止时，手中有花的人就得执行酒令。 击鼓传花便是责任链模式的应用。责任链可能是一条直线、一个环链或者一个树结构的一部分。责任链模式的结构下面使用了一个责任链模式的最简单的实现。责任链模式涉及到的角色如下所示：- 抽象处理者(Handler)角色： 定义出一个处理请求的接口。如果需要，接口可以定义 出一个方法以设定和返回对下家的引用。这个角色通常由一个Java抽象类或者Java接口实现。上图中Handler类的聚合关系给出了具体子类对下家的引用，抽象方法handleRequest()规范了子类处理请求的操作。- 具体处理者(ConcreteHandler)角色： 具体处理者接到请求后，可以选择将请求处理掉，或者将请求传给下家。由于具体处理者持有对下家的引用，因此，如果需要，具体处理者可以访问下家。源代码抽象处理者角色12345678910111213141516171819202122232425public abstract class Handler { /** * 持有后继的责任对象 */ protected Handler successor; /** * 示意处理请求的方法，虽然这个示意方法是没有传入参数的 * 但实际是可以传入参数的，根据具体需要来选择是否传递参数 */ public abstract void handleRequest(); /** * 取值方法 */ public Handler getSuccessor() { return successor; } /** * 赋值方法，设置后继的责任对象 */ public void setSuccessor(Handler successor) { this.successor = successor; } }具体处理者角色12345678910111213141516171819202122public class ConcreteHandler extends Handler { /** * 处理方法，调用此方法处理请求 */ @Override public void handleRequest() { /** * 判断是否有后继的责任对象 * 如果有，就转发请求给后继的责任对象 * 如果没有，则处理请求 */ if(getSuccessor() != null) { System.out.println(&quot;放过请求&quot;); getSuccessor().handleRequest(); }else { System.out.println(&quot;处理请求&quot;); } }}客户端类123456789101112public class Client { public static void main(String[] args) { //组装责任链 Handler handler1 = new ConcreteHandler(); Handler handler2 = new ConcreteHandler(); handler1.setSuccessor(handler2); //提交请求 handler1.handleRequest(); }}可以看出，客户端创建了两个处理者对象，并指定第一个处理者对象的下家是第二个处理者对象，而第二个处理者对象没有下家。然后客户端将请求传递给第一个处理者对象。由于本示例的传递逻辑非常简单：只要有下家，就传给下家处理；如果没有下家，就自行处理。因此，第一个处理者对象接到请求后，会将请求传递给第二个处理者对象。由于第二个处理者对象没有下家，于是自行处理请求。活动时序图如下所示。使用场景来考虑这样一个功能:申请聚餐费用的管理。 很多公司都是这样的福利，就是项目组或者是部门可以向公司申请一些聚餐费用，用于组织项目组成员或者是部门成员进行聚餐活动。 申请聚餐费用的大致流程一般是：由申请人先填写申请单，然后交给领导审批，如果申请批准下来，领导会通知申请人审批通过，然后申请人去财务领取费用，如果没有批准下来，领导会通知申请人审批未通过，此事也就此作罢。 不同级别的领导，对于审批的额度是不一样的，比如，项目经理只能审批500元以内的申请；部门经理能审批1000元以内的申请；而总经理可以审核任意额度的申请。 也就是说，当某人提出聚餐费用申请的请求后，该请求会经由项目经理、部门经理、总经理之中的某一位领导来进行相应的处理，但是提出申请的人并不知道最终会由谁来处理他的请求，一般申请人是把自己的申请提交给项目经理，或许最后是由总经理来处理他的请求。 可以使用责任链模式来实现上述功能：当某人提出聚餐费用申请的请求后，该请求会在 项目经理—〉部门经理—〉总经理 这样一条领导处理链上进行传递，发出请求的人并不知道谁会来处理他的请求，每个领导会根据自己的职责范围，来判断是处理请求还是把请求交给更高级别的领导，只要有领导处理了，传递就结束了。 需要把每位领导的处理独立出来，实现成单独的职责处理对象，然后为它们提供一个公共的、抽象的父职责对象，这样就可以在客户端来动态地组合职责链，实现不同的功能要求了。源代码抽象处理者角色类12345678910111213141516171819202122232425public abstract class Handler { /** * 持有下一个处理请求的对象 */ protected Handler successor = null; /** * 取值方法 */ public Handler getSuccessor() { return successor; } /** * 设置下一个处理请求的对象 */ public void setSuccessor(Handler successor) { this.successor = successor; } /** * 处理聚餐费用的申请 * @param user 申请人 * @param fee 申请的钱数 * @return 成功或失败的具体通知 */ public abstract String handleFeeRequest(String user , double fee);}具体处理者角色123456789101112131415161718192021222324252627282930public class ProjectManager extends Handler { @Override public String handleFeeRequest(String user, double fee) { String str = &quot;&quot;; //项目经理权限比较小，只能在500以内 if(fee &lt; 500) { //为了测试，简单点，只同意张三的请求 if(&quot;张三&quot;.equals(user)) { str = &quot;成功：项目经理同意【&quot; + user + &quot;】的聚餐费用，金额为&quot; + fee + &quot;元&quot;; }else { //其他人一律不同意 str = &quot;失败：项目经理不同意【&quot; + user + &quot;】的聚餐费用，金额为&quot; + fee + &quot;元&quot;; } }else { //超过500，继续传递给级别更高的人处理 if(getSuccessor() != null) { return getSuccessor().handleFeeRequest(user, fee); } } return str; }}123456789101112131415161718192021222324252627282930public class DeptManager extends Handler { @Override public String handleFeeRequest(String user, double fee) { String str = &quot;&quot;; //部门经理的权限只能在1000以内 if(fee &lt; 1000) { //为了测试，简单点，只同意张三的请求 if(&quot;张三&quot;.equals(user)) { str = &quot;成功：部门经理同意【&quot; + user + &quot;】的聚餐费用，金额为&quot; + fee + &quot;元&quot;; }else { //其他人一律不同意 str = &quot;失败：部门经理不同意【&quot; + user + &quot;】的聚餐费用，金额为&quot; + fee + &quot;元&quot;; } }else { //超过1000，继续传递给级别更高的人处理 if(getSuccessor() != null) { return getSuccessor().handleFeeRequest(user, fee); } } return str; }}123456789101112131415161718192021222324252627282930public class GeneralManager extends Handler { @Override public String handleFeeRequest(String user, double fee) { String str = &quot;&quot;; //总经理的权限很大，只要请求到了这里，他都可以处理 if(fee &gt;= 1000) { //为了测试，简单点，只同意张三的请求 if(&quot;张三&quot;.equals(user)) { str = &quot;成功：总经理同意【&quot; + user + &quot;】的聚餐费用，金额为&quot; + fee + &quot;元&quot;; }else { //其他人一律不同意 str = &quot;失败：总经理不同意【&quot; + user + &quot;】的聚餐费用，金额为&quot; + fee + &quot;元&quot;; } }else { //如果还有后继的处理对象，继续传递 if(getSuccessor() != null) { return getSuccessor().handleFeeRequest(user, fee); } } return str; }}客户端类123456789101112131415161718192021222324252627282930public class Client { public static void main(String[] args) { //先要组装责任链 Handler h1 = new GeneralManager(); Handler h2 = new DeptManager(); Handler h3 = new ProjectManager(); h3.setSuccessor(h2); h2.setSuccessor(h1); //开始测试 String test1 = h3.handleFeeRequest(&quot;张三&quot;, 300); System.out.println(&quot;test1 = &quot; + test1); String test2 = h3.handleFeeRequest(&quot;李四&quot;, 300); System.out.println(&quot;test2 = &quot; + test2); System.out.println(&quot;---------------------------------------&quot;); String test3 = h3.handleFeeRequest(&quot;张三&quot;, 700); System.out.println(&quot;test3 = &quot; + test3); String test4 = h3.handleFeeRequest(&quot;李四&quot;, 700); System.out.println(&quot;test4 = &quot; + test4); System.out.println(&quot;---------------------------------------&quot;); String test5 = h3.handleFeeRequest(&quot;张三&quot;, 1500); System.out.println(&quot;test5 = &quot; + test5); String test6 = h3.handleFeeRequest(&quot;李四&quot;, 1500); System.out.println(&quot;test6 = &quot; + test6); }}运行结果如下所示：纯的与不纯的责任链模式 一个纯的责任链模式要求一个具体的处理者对象只能在两个行为中选择一个：一是承担责任，而是把责任推给下家。不允许出现某一个具体处理者对象在承担了一部分责任后又 把责任向下传的情况。 在一个纯的责任链模式里面，一个请求必须被某一个处理者对象所接收；在一个不纯的责任链模式里面，一个请求可以最终不被任何接收端对象所接收。 纯的责任链模式的实际例子很难找到，一般看到的例子均是不纯的责任链模式的实现。有些人认为不纯的责任链根本不是责任链模式，这也许是有道理的。但是在实际的系统里，纯的责任链很难找到。如果坚持责任链不纯便不是责任链模式，那么责任链模式便不会有太大意义了。责任链模式在Tomcat中的应用众所周知Tomcat中的Filter就是使用了责任链模式，创建一个Filter除了要在web.xml文件中做相应配置外，还需要实现javax.servlet.Filter接口。123456789101112131415public class TestFilter implements Filter{ public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException { chain.doFilter(request, response); } public void destroy() { } public void init(FilterConfig filterConfig) throws ServletException { }}使用DEBUG模式所看到的结果如下:其实在真正执行到TestFilter类之前，会经过很多Tomcat内部的类。顺带提一下其实Tomcat的容器设置也是责任链模式，注意被红色方框所圈中的类，从Engine到Host再到Context一直到Wrapper都是通过一个链传递请求。被绿色方框所圈中的地方有一个名为ApplicationFilterChain的类，ApplicationFilterChain类所扮演的就是抽象处理者角色，而具体处理者角色由各个Filter扮演。第一个疑问是ApplicationFilterChain将所有的Filter存放在哪里？答案是保存在ApplicationFilterChain类中的一个ApplicationFilterConfig对象的数组中。1234/** * Filters. */ private ApplicationFilterConfig[] filters = new ApplicationFilterConfig[0];那ApplicationFilterConfig对象又是什么呢？12345678/** * Implementation of a &lt;code&gt;javax.servlet.FilterConfig&lt;/code&gt; useful in * managing the filter instances instantiated when a web application * is first started. * * @author Craig R. McClanahan * @version $Id: ApplicationFilterConfig.java 1201569 2011-11-14 01:36:07Z kkolinko $ */当一个web应用首次启动时ApplicationFilterConfig会自动实例化，它会从该web应用的web.xml文件中读取配置的Filter的信息，然后装进该容器。刚刚看到在ApplicationFilterChain类中所创建的ApplicationFilterConfig数组长度为零，那它是在什么时候被重新赋值的呢？是在调用ApplicationFilterChain类的addFilter()方法时。123456789101112131415161718192021 /** * The int which gives the current number of filters in the chain. */ private int n = 0;public static final int INCREMENT = 10;void addFilter(ApplicationFilterConfig filterConfig) { // Prevent the same filter being added multiple times for(ApplicationFilterConfig filter:filters) if(filter==filterConfig) return; if (n == filters.length) { ApplicationFilterConfig[] newFilters = new ApplicationFilterConfig[n + INCREMENT]; System.arraycopy(filters, 0, newFilters, 0, n); filters = newFilters; } filters[n++] = filterConfig; } 变量n用来记录当前过滤器链里面拥有的过滤器数目，默认情况下n等于0，ApplicationFilterConfig对象数组的长度也等于0，所以当第一次调用addFilter()方法时，if (n == filters.length)的条件成立，ApplicationFilterConfig数组长度被改变。之后filters[n++] = filterConfig;将变量filterConfig放入ApplicationFilterConfig数组中并将当前过滤器链里面拥有的过滤器数目+1。那ApplicationFilterChain的addFilter()方法又是在什么地方被调用的呢？是在ApplicationFilterFactory类的createFilterChain()方法中。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123public ApplicationFilterChain createFilterChain(ServletRequest request, Wrapper wrapper, Servlet servlet) { // get the dispatcher type DispatcherType dispatcher = null; if (request.getAttribute(DISPATCHER_TYPE_ATTR) != null) { dispatcher = (DispatcherType) request.getAttribute(DISPATCHER_TYPE_ATTR); } String requestPath = null; Object attribute = request.getAttribute(DISPATCHER_REQUEST_PATH_ATTR); if (attribute != null){ requestPath = attribute.toString(); } // If there is no servlet to execute, return null if (servlet == null) return (null); boolean comet = false; // Create and initialize a filter chain object ApplicationFilterChain filterChain = null; if (request instanceof Request) { Request req = (Request) request; comet = req.isComet(); if (Globals.IS_SECURITY_ENABLED) { // Security: Do not recycle filterChain = new ApplicationFilterChain(); if (comet) { req.setFilterChain(filterChain); } } else { filterChain = (ApplicationFilterChain) req.getFilterChain(); if (filterChain == null) { filterChain = new ApplicationFilterChain(); req.setFilterChain(filterChain); } } } else { // Request dispatcher in use filterChain = new ApplicationFilterChain(); } filterChain.setServlet(servlet); filterChain.setSupport (((StandardWrapper)wrapper).getInstanceSupport()); // Acquire the filter mappings for this Context StandardContext context = (StandardContext) wrapper.getParent(); FilterMap filterMaps[] = context.findFilterMaps(); // If there are no filter mappings, we are done if ((filterMaps == null) || (filterMaps.length == 0)) return (filterChain); // Acquire the information we will need to match filter mappings String servletName = wrapper.getName(); // Add the relevant path-mapped filters to this filter chain for (int i = 0; i &lt; filterMaps.length; i++) { if (!matchDispatcher(filterMaps[i] ,dispatcher)) { continue; } if (!matchFiltersURL(filterMaps[i], requestPath)) continue; ApplicationFilterConfig filterConfig = (ApplicationFilterConfig) context.findFilterConfig(filterMaps[i].getFilterName()); if (filterConfig == null) { // FIXME - log configuration problem continue; } boolean isCometFilter = false; if (comet) { try { isCometFilter = filterConfig.getFilter() instanceof CometFilter; } catch (Exception e) { // Note: The try catch is there because getFilter has a lot of // declared exceptions. However, the filter is allocated much // earlier Throwable t = ExceptionUtils.unwrapInvocationTargetException(e); ExceptionUtils.handleThrowable(t); } if (isCometFilter) { filterChain.addFilter(filterConfig); } } else { filterChain.addFilter(filterConfig); } } // Add filters that match on servlet name second for (int i = 0; i &lt; filterMaps.length; i++) { if (!matchDispatcher(filterMaps[i] ,dispatcher)) { continue; } if (!matchFiltersServlet(filterMaps[i], servletName)) continue; ApplicationFilterConfig filterConfig = (ApplicationFilterConfig) context.findFilterConfig(filterMaps[i].getFilterName()); if (filterConfig == null) { // FIXME - log configuration problem continue; } boolean isCometFilter = false; if (comet) { try { isCometFilter = filterConfig.getFilter() instanceof CometFilter; } catch (Exception e) { // Note: The try catch is there because getFilter has a lot of // declared exceptions. However, the filter is allocated much // earlier } if (isCometFilter) { filterChain.addFilter(filterConfig); } } else { filterChain.addFilter(filterConfig); } } // Return the completed filter chain return (filterChain); } 可以将如上代码分为两段，51行之前为第一段，51行之后为第二段。 第一段的主要目的是创建ApplicationFilterChain对象以及一些参数设置。 第二段的主要目的是从上下文中获取所有Filter信息，之后使用for循环遍历并调用filterChain.addFilter(filterConfig);将filterConfig放入ApplicationFilterChain对象的ApplicationFilterConfig数组中。那ApplicationFilterFactory类的createFilterChain()方法又是在什么地方被调用的呢？是在StandardWrapperValue类的invoke()方法中被调用的。由于invoke()方法较长，所以将很多地方省略。123456789public final void invoke(Request request, Response response) throws IOException, ServletException { 省略中间代码.. ApplicationFilterFactory factory = ApplicationFilterFactory.getInstance(); ApplicationFilterChain filterChain = factory.createFilterChain(request, wrapper, servlet); 省略中间代码.. filterChain.doFilter(request.getRequest(), response.getResponse()); 省略中间代码.. } 那正常的流程应该是这样的： 在StandardWrapperValue类的invoke()方法中调用ApplicationFilterChai类的createFilterChain()方法———&gt;在ApplicationFilterChai类的createFilterChain()方法中调用ApplicationFilterChain类的addFilter()方法———&gt;在ApplicationFilterChain类的addFilter()方法中给ApplicationFilterConfig数组赋值。根据上面的代码可以看出StandardWrapperValue类的invoke()方法在执行完createFilterChain()方法后，会继续执行ApplicationFilterChain类的doFilter()方法，然后在doFilter()方法中会调用internalDoFilter()方法。 以下是internalDoFilter()方法的部分代码123456789101112131415161718192021222324// Call the next filter if there is oneif (pos &lt; n) { //拿到下一个Filter，将指针向下移动一位 //pos它来标识当前ApplicationFilterChain（当前过滤器链）执行到哪个过滤器 ApplicationFilterConfig filterConfig = filters[pos++]; Filter filter = null; try { //获取当前指向的Filter的实例 filter = filterConfig.getFilter(); support.fireInstanceEvent(InstanceEvent.BEFORE_FILTER_EVENT, filter, request, response); if (request.isAsyncSupported() &amp;&amp; &quot;false&quot;.equalsIgnoreCase(filterConfig.getFilterDef().getAsyncSupported())) { request.setAttribute(Globals.ASYNC_SUPPORTED_ATTR, Boolean.FALSE); } if( Globals.IS_SECURITY_ENABLED ) { final ServletRequest req = request; final ServletResponse res = response; Principal principal = ((HttpServletRequest) req).getUserPrincipal(); Object[] args = new Object[]{req, res, this}; SecurityUtil.doAsPrivilege(&quot;doFilter&quot;, filter, classType, args, principal); } else { //调用Filter的doFilter()方法 filter.doFilter(request, response, this); } 这里的filter.doFilter(request, response, this);就是调用我们前面创建的TestFilter中的doFilter()方法。而TestFilter中的doFilter()方法会继续调用chain.doFilter(request, response);方法，而这个chain其实就是ApplicationFilterChain,所以调用过程又回到了上面调用dofilter和调用internalDoFilter方法，这样执行直到里面的过滤器全部执行。 如果定义两个过滤器，则Debug结果如下：","link":"/2017/12/24/Java-design-pattern-responsibility-chain/"}],"tags":[{"name":"java","slug":"java","link":"/tags/java/"},{"name":"IDE","slug":"IDE","link":"/tags/IDE/"},{"name":"设计模式","slug":"设计模式","link":"/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"面试","slug":"面试","link":"/tags/%E9%9D%A2%E8%AF%95/"},{"name":"源码","slug":"源码","link":"/tags/%E6%BA%90%E7%A0%81/"},{"name":"线程池","slug":"线程池","link":"/tags/%E7%BA%BF%E7%A8%8B%E6%B1%A0/"},{"name":"转载","slug":"转载","link":"/tags/%E8%BD%AC%E8%BD%BD/"},{"name":"Jenkins","slug":"Jenkins","link":"/tags/Jenkins/"},{"name":"linux","slug":"linux","link":"/tags/linux/"},{"name":"python","slug":"python","link":"/tags/python/"},{"name":"kafka","slug":"kafka","link":"/tags/kafka/"},{"name":"博客","slug":"博客","link":"/tags/%E5%8D%9A%E5%AE%A2/"},{"name":"hexo","slug":"hexo","link":"/tags/hexo/"},{"name":"docker","slug":"docker","link":"/tags/docker/"},{"name":"随笔","slug":"随笔","link":"/tags/%E9%9A%8F%E7%AC%94/"},{"name":"web","slug":"web","link":"/tags/web/"},{"name":"浏览器","slug":"浏览器","link":"/tags/%E6%B5%8F%E8%A7%88%E5%99%A8/"},{"name":"起航","slug":"起航","link":"/tags/%E8%B5%B7%E8%88%AA/"},{"name":"dubbo","slug":"dubbo","link":"/tags/dubbo/"},{"name":"elasticsearch","slug":"elasticsearch","link":"/tags/elasticsearch/"},{"name":"logstash","slug":"logstash","link":"/tags/logstash/"},{"name":"kibana","slug":"kibana","link":"/tags/kibana/"},{"name":"filebeat","slug":"filebeat","link":"/tags/filebeat/"},{"name":"mysql","slug":"mysql","link":"/tags/mysql/"},{"name":"cmd","slug":"cmd","link":"/tags/cmd/"},{"name":"图集","slug":"图集","link":"/tags/%E5%9B%BE%E9%9B%86/"},{"name":"nginx","slug":"nginx","link":"/tags/nginx/"},{"name":"小说","slug":"小说","link":"/tags/%E5%B0%8F%E8%AF%B4/"},{"name":"git","slug":"git","link":"/tags/git/"},{"name":"spring cloud","slug":"spring-cloud","link":"/tags/spring-cloud/"},{"name":"ribbon","slug":"ribbon","link":"/tags/ribbon/"},{"name":"spring","slug":"spring","link":"/tags/spring/"},{"name":"shell","slug":"shell","link":"/tags/shell/"},{"name":"windows","slug":"windows","link":"/tags/windows/"}],"categories":[{"name":"默认","slug":"默认","link":"/categories/%E9%BB%98%E8%AE%A4/"},{"name":"学习","slug":"学习","link":"/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"java","slug":"学习/java","link":"/categories/%E5%AD%A6%E4%B9%A0/java/"},{"name":"环境安装","slug":"学习/环境安装","link":"/categories/%E5%AD%A6%E4%B9%A0/%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/"},{"name":"问题处理","slug":"学习/问题处理","link":"/categories/%E5%AD%A6%E4%B9%A0/%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86/"},{"name":"python","slug":"学习/python","link":"/categories/%E5%AD%A6%E4%B9%A0/python/"},{"name":"脚本命令","slug":"学习/脚本命令","link":"/categories/%E5%AD%A6%E4%B9%A0/%E8%84%9A%E6%9C%AC%E5%91%BD%E4%BB%A4/"},{"name":"docker","slug":"学习/docker","link":"/categories/%E5%AD%A6%E4%B9%A0/docker/"},{"name":"相册","slug":"相册","link":"/categories/%E7%9B%B8%E5%86%8C/"},{"name":"nginx","slug":"学习/nginx","link":"/categories/%E5%AD%A6%E4%B9%A0/nginx/"},{"name":"elastic","slug":"学习/elastic","link":"/categories/%E5%AD%A6%E4%B9%A0/elastic/"},{"name":"spring","slug":"学习/spring","link":"/categories/%E5%AD%A6%E4%B9%A0/spring/"}]}